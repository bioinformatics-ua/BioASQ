{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/home/tiagoalmeida/bioASQ-taskb/\")\n",
    "import sentencepiece as spm\n",
    "import pickle\n",
    "from pubmed_data import pubmed_helper as ph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 50000\n",
    "\n",
    "MODEL_NAME = \"model_bpe_50k\"\n",
    "\n",
    "article_map = lambda article:(article[\"title\"]+\" \"+article[\"abstract\"]).lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Byte Pair Encoding - Pubmed\n",
    "\n",
    "#### Index\n",
    " - [Concatenate all pubmed archives in txt file](#txt)\n",
    " - [Create BPE encoder](#bpe)\n",
    " - [Load BPE encoder](#bpe_encoder)\n",
    " - [Encode pubmed](#pubmed_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='txt'></a>\n",
    "### Convert the pubmed abstract to a unique txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open /backup/pubmed_archive_json/pubmed_ready.tar.gz\n",
      "Creating generator\n",
      "Open the file: pubmed_ready_00000000_to_02776362\n",
      "Returning: 2776363 articles\n",
      "Force garbage collector 0\n",
      "Open the file: pubmed_ready_02776363_to_05519968\n",
      "Returning: 2743606 articles\n",
      "Force garbage collector 0\n",
      "Open the file: pubmed_ready_05519969_to_08241071\n",
      "Returning: 2721103 articles\n",
      "Force garbage collector 0\n",
      "Open the file: pubmed_ready_08241072_to_11124313\n",
      "Returning: 2883242 articles\n",
      "Force garbage collector 0\n",
      "Open the file: pubmed_ready_11124314_to_13996815\n",
      "Returning: 2872502 articles\n",
      "Force garbage collector 0\n",
      "Open the file: pubmed_ready_13996816_to_18824354\n",
      "Returning: 4827539 articles\n",
      "Force garbage collector 0\n"
     ]
    }
   ],
   "source": [
    "txt_file = open(\"/backup/pubmed_archive/txt/archive.txt\",\"w\",encoding = 'utf-8')\n",
    "\n",
    "\n",
    "#Load pubmed\n",
    "#load the articles to the memory\n",
    "articles_generator = ph.create_pubmed_collection_generator()\n",
    "articles = []\n",
    "for docs in articles_generator():\n",
    "    for doc in map(lambda x:article_map(x)+\"\\n\",docs):\n",
    "        txt_file.write(doc)\n",
    "        \n",
    "txt_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='bpe'></a>\n",
    "### Create BPE encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "command: --input=/backup/pubmed_archive/txt/archive.txt --model_prefix=/backup/bpe_model/model_bpe_50k --vocab_size=50000 --model_type=bpe\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def create_bpe_model(input_txt, model_prefix, vocab_size = 50000, model_type=\"bpe\", user_symbols=None):\n",
    "    model_prefix = os.path.join(\"/backup/bpe_model\",model_prefix)\n",
    "    command_str = '--input={} --model_prefix={} --vocab_size={} --model_type={}'.format(input_txt, model_prefix, str(vocab_size), model_type)\n",
    "    if user_symbols is not None:\n",
    "        command_str = command_str+\" --user_defined_symbols=\"+user_symbols\n",
    "    print(\"command:\",command_str)\n",
    "\n",
    "    spm.SentencePieceTrainer.train(command_str)\n",
    "\n",
    "create_bpe_model(\"/backup/pubmed_archive/txt/archive.txt\",MODEL_NAME,VOCAB_SIZE,user_symbols=\"<pad>,<$>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='bpe_encoder'></a>\n",
    "### Load and Test BPE encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpe_model = ph.load_bpe_model(MODEL_NAME)\n",
    "str_test = \"How could iPSCs be used for the treatment of diabetes?\".lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁how', '▁could', '▁ipscs', '▁be', '▁used', '▁for', '▁the', '▁treatment', '▁of', '▁diabetes', '?']\n"
     ]
    }
   ],
   "source": [
    "print(bpe_model.encode_as_pieces(str_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[529, 933, 31168, 121, 491, 78, 14, 362, 23, 1841, 0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe_model.encode_as_ids(str_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'how could ipscs be used for the treatment of diabetes?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe_model.decode_pieces(['▁how', '▁could', '▁ipscs', '▁be', '▁used', '▁for', '▁the', '▁treatment', '▁of', '▁diabetes', '?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'how could ipscs be used for the treatment of diabetes ⁇ '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe_model.decode_ids([529, 933, 31168, 121, 491, 78, 14, 362, 23, 1841, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get dictionary id-subwording\n",
    "id_subword = { _id:bpe_model.id_to_piece(_id) for _id in range(len(bpe_model))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '<unk>',\n",
       " 1: '<s>',\n",
       " 2: '</s>',\n",
       " 3: '<tit_sep>',\n",
       " 4: '▁t',\n",
       " 5: 'in',\n",
       " 6: '▁a',\n",
       " 7: 're',\n",
       " 8: 'on',\n",
       " 9: 'ti',\n",
       " 10: 'he',\n",
       " 11: 'en',\n",
       " 12: '▁o',\n",
       " 13: '▁c',\n",
       " 14: '▁s',\n",
       " 15: '▁the',\n",
       " 16: 'er',\n",
       " 17: '▁p',\n",
       " 18: 'al',\n",
       " 19: 'ed',\n",
       " 20: '▁in',\n",
       " 21: '▁an',\n",
       " 22: 'at',\n",
       " 23: '▁of',\n",
       " 24: '▁w',\n",
       " 25: 'es',\n",
       " 26: 'or',\n",
       " 27: '▁m',\n",
       " 28: 'ro',\n",
       " 29: '▁d',\n",
       " 30: 'an',\n",
       " 31: 'is',\n",
       " 32: 'tion',\n",
       " 33: 'it',\n",
       " 34: '▁f',\n",
       " 35: '▁and',\n",
       " 36: 'as',\n",
       " 37: 'ic',\n",
       " 38: '▁b',\n",
       " 39: 'ar',\n",
       " 40: '▁re',\n",
       " 41: 'ing',\n",
       " 42: 'ent',\n",
       " 43: '▁e',\n",
       " 44: 'le',\n",
       " 45: 'ation',\n",
       " 46: '▁to',\n",
       " 47: 've',\n",
       " 48: 'ec',\n",
       " 49: '▁h',\n",
       " 50: 'ul',\n",
       " 51: 'us',\n",
       " 52: '▁n',\n",
       " 53: 'om',\n",
       " 54: 'ac',\n",
       " 55: 'ly',\n",
       " 56: '▁(',\n",
       " 57: '▁th',\n",
       " 58: 'os',\n",
       " 59: 'et',\n",
       " 60: 'ol',\n",
       " 61: '▁l',\n",
       " 62: 'id',\n",
       " 63: 'ur',\n",
       " 64: '▁g',\n",
       " 65: 'im',\n",
       " 66: 'ith',\n",
       " 67: 'un',\n",
       " 68: '▁with',\n",
       " 69: '▁we',\n",
       " 70: 'ter',\n",
       " 71: 'el',\n",
       " 72: '▁st',\n",
       " 73: 'ati',\n",
       " 74: '▁con',\n",
       " 75: 'ig',\n",
       " 76: 'ce',\n",
       " 77: '▁pro',\n",
       " 78: 'ra',\n",
       " 79: '▁for',\n",
       " 80: 'il',\n",
       " 81: 'res',\n",
       " 82: 'ot',\n",
       " 83: 'uc',\n",
       " 84: 'od',\n",
       " 85: '▁v',\n",
       " 86: 'if',\n",
       " 87: 'ts',\n",
       " 88: 'ut',\n",
       " 89: 'ated',\n",
       " 90: '▁as',\n",
       " 91: 'um',\n",
       " 92: 'oc',\n",
       " 93: '▁was',\n",
       " 94: 'op',\n",
       " 95: 'ow',\n",
       " 96: 'ion',\n",
       " 97: '▁ex',\n",
       " 98: 'tic',\n",
       " 99: 'am',\n",
       " 100: '▁is',\n",
       " 101: '▁res',\n",
       " 102: 'ity',\n",
       " 103: '▁were',\n",
       " 104: 'st',\n",
       " 105: 'em',\n",
       " 106: 'ate',\n",
       " 107: 'ents',\n",
       " 108: '▁r',\n",
       " 109: '▁on',\n",
       " 110: '▁1',\n",
       " 111: 'og',\n",
       " 112: '▁ac',\n",
       " 113: 'ir',\n",
       " 114: '▁com',\n",
       " 115: 'ab',\n",
       " 116: 'di',\n",
       " 117: 'ag',\n",
       " 118: '▁that',\n",
       " 119: '▁by',\n",
       " 120: '▁al',\n",
       " 121: 'rom',\n",
       " 122: '▁be',\n",
       " 123: 'ical',\n",
       " 124: 'ver',\n",
       " 125: 'ri',\n",
       " 126: 'th',\n",
       " 127: 'up',\n",
       " 128: 'ine',\n",
       " 129: 'qu',\n",
       " 130: '▁ch',\n",
       " 131: 'ph',\n",
       " 132: 'ant',\n",
       " 133: 'ell',\n",
       " 134: 'red',\n",
       " 135: 'ren',\n",
       " 136: 'ment',\n",
       " 137: 'ase',\n",
       " 138: '▁de',\n",
       " 139: '▁pati',\n",
       " 140: 'se',\n",
       " 141: 'tive',\n",
       " 142: 'ff',\n",
       " 143: '▁comp',\n",
       " 144: 'ted',\n",
       " 145: 'ud',\n",
       " 146: '▁or',\n",
       " 147: 'her',\n",
       " 148: '▁im',\n",
       " 149: '▁dis',\n",
       " 150: '▁at',\n",
       " 151: 'ess',\n",
       " 152: '▁2',\n",
       " 153: 'ay',\n",
       " 154: 'te',\n",
       " 155: 'ain',\n",
       " 156: 'ad',\n",
       " 157: 'und',\n",
       " 158: '▁us',\n",
       " 159: '▁patients',\n",
       " 160: 'tr',\n",
       " 161: 'ure',\n",
       " 162: 'pl',\n",
       " 163: '▁he',\n",
       " 164: '▁ad',\n",
       " 165: 'pec',\n",
       " 166: 'duc',\n",
       " 167: 'ress',\n",
       " 168: '▁inc',\n",
       " 169: '▁cell',\n",
       " 170: '▁from',\n",
       " 171: 'ib',\n",
       " 172: 'iz',\n",
       " 173: '▁se',\n",
       " 174: '▁are',\n",
       " 175: 'ign',\n",
       " 176: '▁ne',\n",
       " 177: '▁per',\n",
       " 178: 'per',\n",
       " 179: 'ran',\n",
       " 180: '▁this',\n",
       " 181: '0.',\n",
       " 182: 'ub',\n",
       " 183: '▁en',\n",
       " 184: 'vel',\n",
       " 185: 'ug',\n",
       " 186: 'ific',\n",
       " 187: 'ations',\n",
       " 188: '▁wh',\n",
       " 189: 'igh',\n",
       " 190: '▁le',\n",
       " 191: 'tiv',\n",
       " 192: '▁met',\n",
       " 193: 'ous',\n",
       " 194: 'orm',\n",
       " 195: 'por',\n",
       " 196: 'ys',\n",
       " 197: 'ence',\n",
       " 198: 'ore',\n",
       " 199: '▁eff',\n",
       " 200: '▁sh',\n",
       " 201: 'ch',\n",
       " 202: 'tor',\n",
       " 203: 'iv',\n",
       " 204: ').',\n",
       " 205: '▁ass',\n",
       " 206: 'est',\n",
       " 207: '▁sy',\n",
       " 208: 'ia',\n",
       " 209: 'ip',\n",
       " 210: 'ens',\n",
       " 211: '▁cont',\n",
       " 212: '▁gen',\n",
       " 213: 'ge',\n",
       " 214: '▁resul',\n",
       " 215: 'ial',\n",
       " 216: 'ers',\n",
       " 217: '▁pre',\n",
       " 218: 'ary',\n",
       " 219: 'ular',\n",
       " 220: '▁gro',\n",
       " 221: '▁cl',\n",
       " 222: 'lec',\n",
       " 223: '▁inf',\n",
       " 224: '▁di',\n",
       " 225: '▁k',\n",
       " 226: 'fe',\n",
       " 227: 'olog',\n",
       " 228: '▁sign',\n",
       " 229: 'cl',\n",
       " 230: 'ap',\n",
       " 231: 'yp',\n",
       " 232: '▁ap',\n",
       " 233: 'reas',\n",
       " 234: '▁3',\n",
       " 235: 'reat',\n",
       " 236: '),',\n",
       " 237: '▁ph',\n",
       " 238: 'ative',\n",
       " 239: '▁can',\n",
       " 240: '▁dif',\n",
       " 241: '▁co',\n",
       " 242: '▁stud',\n",
       " 243: 'yl',\n",
       " 244: '▁effec',\n",
       " 245: '▁bet',\n",
       " 246: 'feren',\n",
       " 247: '▁study',\n",
       " 248: 'ies',\n",
       " 249: '▁inter',\n",
       " 250: 'rans',\n",
       " 251: 'ance',\n",
       " 252: 'enti',\n",
       " 253: '▁pl',\n",
       " 254: '▁it',\n",
       " 255: '▁not',\n",
       " 256: 'ost',\n",
       " 257: '▁ev',\n",
       " 258: 'we',\n",
       " 259: 'ding',\n",
       " 260: '▁trans',\n",
       " 261: '▁results',\n",
       " 262: '▁par',\n",
       " 263: 'pro',\n",
       " 264: '▁0.',\n",
       " 265: 'tions',\n",
       " 266: 'press',\n",
       " 267: 'ose',\n",
       " 268: '▁ha',\n",
       " 269: 'ear',\n",
       " 270: 'ide',\n",
       " 271: '00',\n",
       " 272: '▁rec',\n",
       " 273: '▁these',\n",
       " 274: 'ist',\n",
       " 275: '▁ob',\n",
       " 276: '▁ab',\n",
       " 277: '▁sub',\n",
       " 278: '▁cells',\n",
       " 279: '▁int',\n",
       " 280: 'ich',\n",
       " 281: '▁sur',\n",
       " 282: 'de',\n",
       " 283: '▁meth',\n",
       " 284: 'ther',\n",
       " 285: '▁me',\n",
       " 286: '▁anal',\n",
       " 287: '▁differen',\n",
       " 288: '▁signific',\n",
       " 289: '▁group',\n",
       " 290: '▁mod',\n",
       " 291: 'ong',\n",
       " 292: 'vi',\n",
       " 293: '▁reg',\n",
       " 294: '▁am',\n",
       " 295: 'ast',\n",
       " 296: '▁af',\n",
       " 297: 'unc',\n",
       " 298: 'rol',\n",
       " 299: 'and',\n",
       " 300: '▁det',\n",
       " 301: 'age',\n",
       " 302: '▁activ',\n",
       " 303: '▁significant',\n",
       " 304: '▁ca',\n",
       " 305: 'ally',\n",
       " 306: 'one',\n",
       " 307: 'ved',\n",
       " 308: '▁y',\n",
       " 309: '▁spec',\n",
       " 310: 'ath',\n",
       " 311: 'oci',\n",
       " 312: '-1',\n",
       " 313: 'tein',\n",
       " 314: 'ween',\n",
       " 315: 'low',\n",
       " 316: '▁between',\n",
       " 317: '▁mic',\n",
       " 318: '▁pres',\n",
       " 319: 'pon',\n",
       " 320: 'able',\n",
       " 321: 'ros',\n",
       " 322: '▁method',\n",
       " 323: '▁sc',\n",
       " 324: 'ari',\n",
       " 325: '▁treat',\n",
       " 326: '▁after',\n",
       " 327: '▁4',\n",
       " 328: 'rap',\n",
       " 329: 'all',\n",
       " 330: 'end',\n",
       " 331: '▁have',\n",
       " 332: '▁5',\n",
       " 333: '▁fo',\n",
       " 334: '▁which',\n",
       " 335: '▁cor',\n",
       " 336: '▁show',\n",
       " 337: 'enc',\n",
       " 338: 'port',\n",
       " 339: 'iti',\n",
       " 340: '▁inv',\n",
       " 341: '▁un',\n",
       " 342: 'usion',\n",
       " 343: 'jec',\n",
       " 344: '▁whe',\n",
       " 345: '▁anti',\n",
       " 346: '▁rel',\n",
       " 347: 'erm',\n",
       " 348: 'ates',\n",
       " 349: '▁no',\n",
       " 350: 'ive',\n",
       " 351: 'alu',\n",
       " 352: '▁car',\n",
       " 353: 'ox',\n",
       " 354: '▁ar',\n",
       " 355: 'na',\n",
       " 356: '▁than',\n",
       " 357: '▁fac',\n",
       " 358: 'ob',\n",
       " 359: 'tim',\n",
       " 360: 'duced',\n",
       " 361: 'ech',\n",
       " 362: '▁tw',\n",
       " 363: 'the',\n",
       " 364: '▁protein',\n",
       " 365: '▁treatment',\n",
       " 366: 'form',\n",
       " 367: 'ight',\n",
       " 368: 'oth',\n",
       " 369: 'ome',\n",
       " 370: 'str',\n",
       " 371: '▁level',\n",
       " 372: 'tal',\n",
       " 373: 'ass',\n",
       " 374: 'ory',\n",
       " 375: '▁high',\n",
       " 376: 'ulation',\n",
       " 377: 'ak',\n",
       " 378: '▁using',\n",
       " 379: '▁ag',\n",
       " 380: '▁cons',\n",
       " 381: 'ill',\n",
       " 382: '▁=',\n",
       " 383: 'ility',\n",
       " 384: '▁und',\n",
       " 385: 'osis',\n",
       " 386: 'pression',\n",
       " 387: 'cep',\n",
       " 388: '▁str',\n",
       " 389: '▁increas',\n",
       " 390: '▁dur',\n",
       " 391: 'entr',\n",
       " 392: '▁associ',\n",
       " 393: '▁po',\n",
       " 394: '▁all',\n",
       " 395: 'ms',\n",
       " 396: 'mun',\n",
       " 397: 'act',\n",
       " 398: '▁bl',\n",
       " 399: '▁ro',\n",
       " 400: '▁med',\n",
       " 401: '▁analys',\n",
       " 402: 'cer',\n",
       " 403: '▁dise',\n",
       " 404: 'velop',\n",
       " 405: '▁under',\n",
       " 406: '▁sp',\n",
       " 407: 'hib',\n",
       " 408: '▁qu',\n",
       " 409: '▁but',\n",
       " 410: '▁bi',\n",
       " 411: 'yt',\n",
       " 412: '▁clin',\n",
       " 413: 'ue',\n",
       " 414: 'ater',\n",
       " 415: 'ree',\n",
       " 416: '▁two',\n",
       " 417: 'ach',\n",
       " 418: 'rib',\n",
       " 419: 'udi',\n",
       " 420: 'ases',\n",
       " 421: 'ugh',\n",
       " 422: '▁has',\n",
       " 423: '▁been',\n",
       " 424: '▁develop',\n",
       " 425: 'ied',\n",
       " 426: 'acter',\n",
       " 427: '▁des',\n",
       " 428: 'unction',\n",
       " 429: '▁pos',\n",
       " 430: '▁pr',\n",
       " 431: 'als',\n",
       " 432: 'ating',\n",
       " 433: 'ang',\n",
       " 434: '▁control',\n",
       " 435: '▁respon',\n",
       " 436: 'ized',\n",
       " 437: '▁6',\n",
       " 438: '▁hy',\n",
       " 439: 'ting',\n",
       " 440: '▁dec',\n",
       " 441: 'lu',\n",
       " 442: 'so',\n",
       " 443: '▁studi',\n",
       " 444: 'gen',\n",
       " 445: '▁low',\n",
       " 446: '▁ser',\n",
       " 447: 'anc',\n",
       " 448: '▁more',\n",
       " 449: 'stem',\n",
       " 450: '▁may',\n",
       " 451: 'ple',\n",
       " 452: '▁ra',\n",
       " 453: 'ors',\n",
       " 454: 'ep',\n",
       " 455: '▁mon',\n",
       " 456: '▁col',\n",
       " 457: '▁both',\n",
       " 458: 'ared',\n",
       " 459: '▁dat',\n",
       " 460: 'rain',\n",
       " 461: 'ogen',\n",
       " 462: 'ures',\n",
       " 463: 'cess',\n",
       " 464: '▁during',\n",
       " 465: 'out',\n",
       " 466: '▁their',\n",
       " 467: 'ological',\n",
       " 468: 'agn',\n",
       " 469: 'pos',\n",
       " 470: 'atic',\n",
       " 471: 'ood',\n",
       " 472: 'iss',\n",
       " 473: '▁vari',\n",
       " 474: '▁system',\n",
       " 475: '▁also',\n",
       " 476: 'ven',\n",
       " 477: '▁factor',\n",
       " 478: 'ection',\n",
       " 479: '▁concl',\n",
       " 480: '▁clinical',\n",
       " 481: '▁man',\n",
       " 482: 'hem',\n",
       " 483: 'ser',\n",
       " 484: '▁sup',\n",
       " 485: '▁fol',\n",
       " 486: 'ined',\n",
       " 487: '▁had',\n",
       " 488: 'ew',\n",
       " 489: 'der',\n",
       " 490: '▁i',\n",
       " 491: '▁used',\n",
       " 492: '▁meas',\n",
       " 493: '▁mo',\n",
       " 494: '▁ind',\n",
       " 495: '▁there',\n",
       " 496: 'ult',\n",
       " 497: '▁id',\n",
       " 498: '▁non',\n",
       " 499: '▁tim',\n",
       " 500: '▁heal',\n",
       " 501: '▁disease',\n",
       " 502: 'inal',\n",
       " 503: '▁out',\n",
       " 504: '▁syn',\n",
       " 505: '▁analysis',\n",
       " 506: 'uld',\n",
       " 507: '▁bas',\n",
       " 508: '▁gene',\n",
       " 509: '▁inhib',\n",
       " 510: '▁data',\n",
       " 511: 'ization',\n",
       " 512: 'inding',\n",
       " 513: 'ium',\n",
       " 514: 'ack',\n",
       " 515: '▁activity',\n",
       " 516: '▁expression',\n",
       " 517: 'ct',\n",
       " 518: '▁present',\n",
       " 519: 'tain',\n",
       " 520: '▁function',\n",
       " 521: '▁methods',\n",
       " 522: '▁model',\n",
       " 523: 'ual',\n",
       " 524: 'rel',\n",
       " 525: '▁sug',\n",
       " 526: '▁em',\n",
       " 527: '▁incl',\n",
       " 528: '▁sim',\n",
       " 529: '▁how',\n",
       " 530: 'ild',\n",
       " 531: '▁gl',\n",
       " 532: 'our',\n",
       " 533: '▁hum',\n",
       " 534: '▁health',\n",
       " 535: 'ds',\n",
       " 536: '▁suc',\n",
       " 537: 'ans',\n",
       " 538: 'll',\n",
       " 539: 'pective',\n",
       " 540: '▁acc',\n",
       " 541: '▁9',\n",
       " 542: '▁over',\n",
       " 543: 'uct',\n",
       " 544: '▁other',\n",
       " 545: '▁use',\n",
       " 546: '▁sugg',\n",
       " 547: '▁comple',\n",
       " 548: '▁conclusion',\n",
       " 549: 'ype',\n",
       " 550: 'ition',\n",
       " 551: '▁sam',\n",
       " 552: '▁year',\n",
       " 553: 'ke',\n",
       " 554: 'mon',\n",
       " 555: 'ogra',\n",
       " 556: '▁associated',\n",
       " 557: 'itive',\n",
       " 558: '▁end',\n",
       " 559: '▁increased',\n",
       " 560: '▁follow',\n",
       " 561: 'entif',\n",
       " 562: 'ici',\n",
       " 563: 'ite',\n",
       " 564: '▁7',\n",
       " 565: 'duction',\n",
       " 566: 'pend',\n",
       " 567: '▁ris',\n",
       " 568: '▁immun',\n",
       " 569: '▁levels',\n",
       " 570: '▁includ',\n",
       " 571: 'pt',\n",
       " 572: 'ays',\n",
       " 573: 'ace',\n",
       " 574: '▁effects',\n",
       " 575: '▁compared',\n",
       " 576: '▁significantly',\n",
       " 577: 'ma',\n",
       " 578: '▁conc',\n",
       " 579: '▁one',\n",
       " 580: '▁evalu',\n",
       " 581: 'vid',\n",
       " 582: 'dition',\n",
       " 583: '▁obser',\n",
       " 584: '▁therap',\n",
       " 585: 'oid',\n",
       " 586: '▁effect',\n",
       " 587: 'ants',\n",
       " 588: '▁found',\n",
       " 589: 'action',\n",
       " 590: 'atory',\n",
       " 591: '▁identif',\n",
       " 592: '▁pot',\n",
       " 593: '▁determ',\n",
       " 594: 'tig',\n",
       " 595: 'ution',\n",
       " 596: '▁tum',\n",
       " 597: 'cc',\n",
       " 598: '▁(1',\n",
       " 599: '▁cancer',\n",
       " 600: '▁exper',\n",
       " 601: '▁j',\n",
       " 602: '▁studies',\n",
       " 603: '▁path',\n",
       " 604: 'ym',\n",
       " 605: '▁perform',\n",
       " 606: 'lym',\n",
       " 607: '▁its',\n",
       " 608: '▁char',\n",
       " 609: 'ments',\n",
       " 610: '▁form',\n",
       " 611: '▁risk',\n",
       " 612: 'ail',\n",
       " 613: '5%',\n",
       " 614: 'ric',\n",
       " 615: 'ry',\n",
       " 616: '▁li',\n",
       " 617: '▁[',\n",
       " 618: 'ination',\n",
       " 619: 'ile',\n",
       " 620: '▁different',\n",
       " 621: '▁op',\n",
       " 622: '▁dem',\n",
       " 623: 'ne',\n",
       " 624: '▁human',\n",
       " 625: '▁rat',\n",
       " 626: '▁8',\n",
       " 627: 'ever',\n",
       " 628: 'emb',\n",
       " 629: '▁hig',\n",
       " 630: '-2',\n",
       " 631: '01',\n",
       " 632: 'ron',\n",
       " 633: '▁time',\n",
       " 634: '▁prog',\n",
       " 635: 'ery',\n",
       " 636: '▁indic',\n",
       " 637: 'ency',\n",
       " 638: '▁diagn',\n",
       " 639: 'tern',\n",
       " 640: '▁appro',\n",
       " 641: 'ograph',\n",
       " 642: '▁showed',\n",
       " 643: '▁up',\n",
       " 644: 'ond',\n",
       " 645: '▁assess',\n",
       " 646: 'ions',\n",
       " 647: 'oma',\n",
       " 648: '▁exam',\n",
       " 649: '▁tr',\n",
       " 650: 'rease',\n",
       " 651: '▁acid',\n",
       " 652: 'estig',\n",
       " 653: '▁mul',\n",
       " 654: 'idence',\n",
       " 655: 'ected',\n",
       " 656: 'lic',\n",
       " 657: '▁ep',\n",
       " 658: '▁investig',\n",
       " 659: '▁concentr',\n",
       " 660: 'ect',\n",
       " 661: 'arg',\n",
       " 662: '▁es',\n",
       " 663: '▁however',\n",
       " 664: '▁partic',\n",
       " 665: 'pa',\n",
       " 666: 'mo',\n",
       " 667: 'onstr',\n",
       " 668: 'ormal',\n",
       " 669: 'tical',\n",
       " 670: 'ology',\n",
       " 671: 'hed',\n",
       " 672: 'ability',\n",
       " 673: '▁ma',\n",
       " 674: 'ceptor',\n",
       " 675: '▁most',\n",
       " 676: 'oph',\n",
       " 677: '▁years',\n",
       " 678: 'ism',\n",
       " 679: '▁inhibit',\n",
       " 680: 'ential',\n",
       " 681: 'erg',\n",
       " 682: 'ute',\n",
       " 683: '▁10',\n",
       " 684: 'urren',\n",
       " 685: 'echan',\n",
       " 686: '▁sec',\n",
       " 687: 'ities',\n",
       " 688: '▁dr',\n",
       " 689: '▁our',\n",
       " 690: '▁into',\n",
       " 691: '▁who',\n",
       " 692: 'par',\n",
       " 693: '▁character',\n",
       " 694: '▁age',\n",
       " 695: '▁new',\n",
       " 696: 'plic',\n",
       " 697: '▁when',\n",
       " 698: 'othe',\n",
       " 699: 'ork',\n",
       " 700: 'cop',\n",
       " 701: 'ard',\n",
       " 702: '▁def',\n",
       " 703: '▁pred',\n",
       " 704: 'ten',\n",
       " 705: '▁mal',\n",
       " 706: '▁child',\n",
       " 707: '▁mechan',\n",
       " 708: '▁only',\n",
       " 709: 'ces',\n",
       " 710: 'ines',\n",
       " 711: 'fer',\n",
       " 712: 'ature',\n",
       " 713: 'hen',\n",
       " 714: 'sis',\n",
       " 715: '▁higher',\n",
       " 716: '▁well',\n",
       " 717: '▁struct',\n",
       " 718: '▁ins',\n",
       " 719: 'med',\n",
       " 720: '▁three',\n",
       " 721: '▁pa',\n",
       " 722: 'umb',\n",
       " 723: '▁micro',\n",
       " 724: '▁min',\n",
       " 725: '▁surg',\n",
       " 726: '▁impro',\n",
       " 727: '▁post',\n",
       " 728: 'ix',\n",
       " 729: '▁elec',\n",
       " 730: '▁mor',\n",
       " 731: 'ound',\n",
       " 732: 'pendent',\n",
       " 733: 'val',\n",
       " 734: 'view',\n",
       " 735: 'ible',\n",
       " 736: '▁patient',\n",
       " 737: '▁gener',\n",
       " 738: '▁dist',\n",
       " 739: 'ons',\n",
       " 740: '▁disc',\n",
       " 741: '▁1.',\n",
       " 742: 'dro',\n",
       " 743: 'ural',\n",
       " 744: '▁blood',\n",
       " 745: 'min',\n",
       " 746: '▁chang',\n",
       " 747: '▁cases',\n",
       " 748: 'osph',\n",
       " 749: '▁import',\n",
       " 750: 'ement',\n",
       " 751: '▁loc',\n",
       " 752: 'tit',\n",
       " 753: '▁observed',\n",
       " 754: '▁receptor',\n",
       " 755: 'les',\n",
       " 756: 'use',\n",
       " 757: 'ucle',\n",
       " 758: 'ange',\n",
       " 759: '▁groups',\n",
       " 760: 'ung',\n",
       " 761: 'pectively',\n",
       " 762: 'ark',\n",
       " 763: '▁fir',\n",
       " 764: '▁grow',\n",
       " 765: 'ody',\n",
       " 766: 'sy',\n",
       " 767: '▁development',\n",
       " 768: 'gro',\n",
       " 769: '▁such',\n",
       " 770: 'tro',\n",
       " 771: 'ured',\n",
       " 772: '▁occ',\n",
       " 773: '▁rate',\n",
       " 774: '▁response',\n",
       " 775: '+/',\n",
       " 776: '▁tiss',\n",
       " 777: 'led',\n",
       " 778: 'iqu',\n",
       " 779: '▁demonstr',\n",
       " 780: '▁ox',\n",
       " 781: 'rough',\n",
       " 782: 'ital',\n",
       " 783: '▁role',\n",
       " 784: '▁<',\n",
       " 785: '▁cal',\n",
       " 786: 'cular',\n",
       " 787: '▁test',\n",
       " 788: '▁first',\n",
       " 789: '▁among',\n",
       " 790: 'cin',\n",
       " 791: '▁aff',\n",
       " 792: '▁fe',\n",
       " 793: 'own',\n",
       " 794: 'echn',\n",
       " 795: '▁process',\n",
       " 796: 'hy',\n",
       " 797: 'omy',\n",
       " 798: 'av',\n",
       " 799: '0%',\n",
       " 800: '▁factors',\n",
       " 801: '▁fur',\n",
       " 802: 'ulated',\n",
       " 803: '▁cyt',\n",
       " 804: '▁suggest',\n",
       " 805: '▁drug',\n",
       " 806: 'reated',\n",
       " 807: '▁care',\n",
       " 808: 'ption',\n",
       " 809: '▁addition',\n",
       " 810: '▁valu',\n",
       " 811: '▁techn',\n",
       " 812: 'rop',\n",
       " 813: '▁prim',\n",
       " 814: 'omen',\n",
       " 815: '▁molec',\n",
       " 816: '▁mut',\n",
       " 817: '▁multi',\n",
       " 818: 'trac',\n",
       " 819: 'ational',\n",
       " 820: 'vers',\n",
       " 821: 'arly',\n",
       " 822: '2)',\n",
       " 823: 'ram',\n",
       " 824: 'ha',\n",
       " 825: '▁changes',\n",
       " 826: '▁pop',\n",
       " 827: '▁further',\n",
       " 828: '▁those',\n",
       " 829: 'ane',\n",
       " 830: '▁sens',\n",
       " 831: 'tics',\n",
       " 832: 'ful',\n",
       " 833: 'ft',\n",
       " 834: 'amm',\n",
       " 835: '▁u',\n",
       " 836: '▁my',\n",
       " 837: 'dependent',\n",
       " 838: '▁19',\n",
       " 839: 'co',\n",
       " 840: '▁invol',\n",
       " 841: '▁plas',\n",
       " 842: '+/-',\n",
       " 843: 'ord',\n",
       " 844: 'ort',\n",
       " 845: '▁hyper',\n",
       " 846: '▁neu',\n",
       " 847: '▁through',\n",
       " 848: '▁numb',\n",
       " 849: 'ough',\n",
       " 850: '▁respectively',\n",
       " 851: '▁long',\n",
       " 852: '▁vir',\n",
       " 853: '▁correl',\n",
       " 854: 'its',\n",
       " 855: 'ental',\n",
       " 856: 'ov',\n",
       " 857: '▁therapy',\n",
       " 858: '▁conf',\n",
       " 859: '▁ext',\n",
       " 860: '▁repor',\n",
       " 861: 'tivity',\n",
       " 862: '▁specific',\n",
       " 863: '▁total',\n",
       " 864: '▁phys',\n",
       " 865: '▁rem',\n",
       " 866: 'tained',\n",
       " 867: 'fore',\n",
       " 868: '▁mus',\n",
       " 869: '▁predic',\n",
       " 870: '▁sol',\n",
       " 871: 'nal',\n",
       " 872: '▁cy',\n",
       " 873: '▁kn',\n",
       " 874: 'ize',\n",
       " 875: '▁increase',\n",
       " 876: 'tis',\n",
       " 877: '▁peri',\n",
       " 878: '▁aut',\n",
       " 879: '▁outc',\n",
       " 880: 'ited',\n",
       " 881: '▁hyp',\n",
       " 882: 'requ',\n",
       " 883: '▁review',\n",
       " 884: 'eth',\n",
       " 885: 'xim',\n",
       " 886: '▁indi',\n",
       " 887: '▁normal',\n",
       " 888: 'ived',\n",
       " 889: '▁12',\n",
       " 890: '▁prob',\n",
       " 891: '▁experim',\n",
       " 892: '▁children',\n",
       " 893: '▁desc',\n",
       " 894: '▁subjec',\n",
       " 895: 'ould',\n",
       " 896: 'erative',\n",
       " 897: '%)',\n",
       " 898: '▁sequ',\n",
       " 899: '▁compar',\n",
       " 900: '▁growth',\n",
       " 901: '▁radi',\n",
       " 902: '▁finding',\n",
       " 903: 'qui',\n",
       " 904: 'ses',\n",
       " 905: 'osp',\n",
       " 906: 'old',\n",
       " 907: 'gan',\n",
       " 908: 'ores',\n",
       " 909: '▁cr',\n",
       " 910: '▁comb',\n",
       " 911: '▁main',\n",
       " 912: 'ths',\n",
       " 913: '▁sym',\n",
       " 914: '▁mg',\n",
       " 915: 'ian',\n",
       " 916: '▁potential',\n",
       " 917: 'urrent',\n",
       " 918: '▁important',\n",
       " 919: '▁simil',\n",
       " 920: '▁sm',\n",
       " 921: 'ek',\n",
       " 922: '▁memb',\n",
       " 923: '▁tri',\n",
       " 924: '▁tumor',\n",
       " 925: '▁antib',\n",
       " 926: 'pha',\n",
       " 927: '▁performed',\n",
       " 928: '▁within',\n",
       " 929: 'ock',\n",
       " 930: '▁complex',\n",
       " 931: '▁cardi',\n",
       " 932: 'omes',\n",
       " 933: '▁could',\n",
       " 934: 'ently',\n",
       " 935: 'ene',\n",
       " 936: '▁fib',\n",
       " 937: '▁type',\n",
       " 938: '▁conclusions',\n",
       " 939: 'ie',\n",
       " 940: '▁mean',\n",
       " 941: '▁case',\n",
       " 942: '▁el',\n",
       " 943: '▁stim',\n",
       " 944: '▁dna',\n",
       " 945: 'til',\n",
       " 946: '▁selec',\n",
       " 947: '▁gra',\n",
       " 948: 'hes',\n",
       " 949: '▁do',\n",
       " 950: '▁women',\n",
       " 951: '▁lower',\n",
       " 952: '▁mice',\n",
       " 953: 'rect',\n",
       " 954: 'zym',\n",
       " 955: '▁rep',\n",
       " 956: '▁number',\n",
       " 957: '▁decreas',\n",
       " 958: 'vention',\n",
       " 959: '▁cd',\n",
       " 960: '▁+/-',\n",
       " 961: 'abol',\n",
       " 962: 'ins',\n",
       " 963: 'ages',\n",
       " 964: 'ascular',\n",
       " 965: 'ality',\n",
       " 966: '▁frequ',\n",
       " 967: '▁based',\n",
       " 968: '▁chem',\n",
       " 969: '▁vit',\n",
       " 970: '-3',\n",
       " 971: 'ival',\n",
       " 972: '▁del',\n",
       " 973: 'cle',\n",
       " 974: '▁pat',\n",
       " 975: '▁flu',\n",
       " 976: 'ps',\n",
       " 977: '▁x',\n",
       " 978: 'ptom',\n",
       " 979: 'br',\n",
       " 980: 'ok',\n",
       " 981: '▁each',\n",
       " 982: '▁period',\n",
       " 983: '▁cap',\n",
       " 984: '▁less',\n",
       " 985: 'over',\n",
       " 986: 'ased',\n",
       " 987: 'arge',\n",
       " 988: '▁0.0',\n",
       " 989: 'ily',\n",
       " 990: '▁ret',\n",
       " 991: 'ues',\n",
       " 992: '▁poss',\n",
       " 993: 'are',\n",
       " 994: '▁reve',\n",
       " 995: 'arget',\n",
       " 996: 'ties',\n",
       " 997: '1.',\n",
       " 998: 'ise',\n",
       " 999: 'vious',\n",
       " ...}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_subword"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='pubmed_encode'></a>\n",
    "### Run BPE encoder in pubmed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open /backup/pubmed_archive_json/pubmed_ready.tar.gz\n",
      "Creating generator\n",
      "Open the file: pubmed_ready_00000000_to_02776362\n",
      "Returning: 2776363 articles\n",
      "save: model_bpe_50k_file_000_pubmed.p\n",
      "2776363\n",
      "Force garbage collector 0\n",
      "Open the file: pubmed_ready_02776363_to_05519968\n",
      "Returning: 2743606 articles\n",
      "save: model_bpe_50k_file_001_pubmed.p\n",
      "2743606\n",
      "Force garbage collector 0\n",
      "Open the file: pubmed_ready_05519969_to_08241071\n",
      "Returning: 2721103 articles\n",
      "save: model_bpe_50k_file_002_pubmed.p\n",
      "2721103\n",
      "Force garbage collector 0\n",
      "Open the file: pubmed_ready_08241072_to_11124313\n",
      "Returning: 2883242 articles\n",
      "save: model_bpe_50k_file_003_pubmed.p\n",
      "2883242\n",
      "Force garbage collector 0\n",
      "Open the file: pubmed_ready_11124314_to_13996815\n",
      "Returning: 2872502 articles\n",
      "save: model_bpe_50k_file_004_pubmed.p\n",
      "2872502\n",
      "Force garbage collector 0\n",
      "Open the file: pubmed_ready_13996816_to_18824354\n",
      "Returning: 4827539 articles\n",
      "save: model_bpe_50k_file_005_pubmed.p\n",
      "4827539\n",
      "Force garbage collector 0\n"
     ]
    }
   ],
   "source": [
    "if 'articles_generator' not in locals(): #create the var\n",
    "    articles_generator = ph.create_pubmed_collection_generator()\n",
    "    \n",
    "for i,articles in enumerate(articles_generator()):\n",
    "    encoded_articles = []\n",
    "    for j,article in enumerate(map(article_map, articles)):\n",
    "        encoded_articles.append(bpe_model.encode_as_ids(article))\n",
    "        if j%10000==0:\n",
    "            print(\"Article:\",j,end=\"\\r\")\n",
    "    \n",
    "    ##save\n",
    "    file_name = MODEL_NAME+\"_file_{0:03}_pubmed.p\".format(i)\n",
    "    print(\"save:\",file_name)\n",
    "    print(len(encoded_articles))\n",
    "    with open(os.path.join('/','backup','pubmed_archive_tokenized',file_name),\"wb\") as f:\n",
    "        pickle.dump(encoded_articles,f)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁loss',\n",
       " '▁of',\n",
       " '▁density',\n",
       " '-',\n",
       " 'dependent',\n",
       " '▁growth',\n",
       " '▁inhibition',\n",
       " '▁and',\n",
       " '▁dissociation',\n",
       " '▁of',\n",
       " '▁alpha',\n",
       " '-',\n",
       " 'catenin',\n",
       " '▁from',\n",
       " '▁e',\n",
       " '-',\n",
       " 'cadherin',\n",
       " '.<',\n",
       " 'tit',\n",
       " '_',\n",
       " 'sep',\n",
       " '>',\n",
       " 'normal',\n",
       " '▁human',\n",
       " '▁breast',\n",
       " '▁epithelial',\n",
       " '▁(',\n",
       " 'hbe',\n",
       " ')',\n",
       " '▁cells',\n",
       " '▁at',\n",
       " '▁early',\n",
       " '▁(9',\n",
       " 'th',\n",
       " ')',\n",
       " '▁passage',\n",
       " '▁ceased',\n",
       " '▁growth',\n",
       " '▁and',\n",
       " '▁formed',\n",
       " '▁a',\n",
       " '▁monolayer',\n",
       " '▁when',\n",
       " '▁they',\n",
       " '▁reached',\n",
       " '▁confluence',\n",
       " '.',\n",
       " '▁immunostaining',\n",
       " '▁and',\n",
       " '▁western',\n",
       " '▁blotting',\n",
       " '▁revealed',\n",
       " '▁that',\n",
       " '▁alpha',\n",
       " '-',\n",
       " '▁and',\n",
       " '▁beta',\n",
       " '-',\n",
       " 'caten',\n",
       " 'ins',\n",
       " '▁colocalized',\n",
       " '▁and',\n",
       " '▁coprecipitated',\n",
       " '▁with',\n",
       " '▁e',\n",
       " '-',\n",
       " 'cadherin',\n",
       " ',',\n",
       " '▁suggesting',\n",
       " '▁a',\n",
       " '▁complex',\n",
       " '▁formation',\n",
       " '▁of',\n",
       " '▁e',\n",
       " '-',\n",
       " 'cadherin',\n",
       " '▁with',\n",
       " '▁alpha',\n",
       " '-',\n",
       " '▁and',\n",
       " '▁beta',\n",
       " '-',\n",
       " 'caten',\n",
       " 'ins',\n",
       " '▁in',\n",
       " '▁early',\n",
       " '▁passage',\n",
       " '▁cells',\n",
       " '.',\n",
       " '▁in',\n",
       " '▁contrast',\n",
       " ',',\n",
       " '▁hbe',\n",
       " '▁cells',\n",
       " '▁at',\n",
       " '▁late',\n",
       " '▁(12',\n",
       " '-13',\n",
       " 'th',\n",
       " ')',\n",
       " '▁passage',\n",
       " '▁did',\n",
       " '▁not',\n",
       " '▁cease',\n",
       " '▁growth',\n",
       " '▁after',\n",
       " '▁confluence',\n",
       " '▁but',\n",
       " '▁stratified',\n",
       " '.',\n",
       " '▁the',\n",
       " '▁late',\n",
       " '▁passage',\n",
       " '▁cells',\n",
       " '▁exhibited',\n",
       " '▁enhanced',\n",
       " '▁colony',\n",
       " '▁forming',\n",
       " '▁ability',\n",
       " '▁in',\n",
       " '▁soft',\n",
       " '▁agar',\n",
       " '▁compared',\n",
       " '▁with',\n",
       " '▁early',\n",
       " '▁passage',\n",
       " '▁cells',\n",
       " ',',\n",
       " '▁however',\n",
       " ',',\n",
       " '▁they',\n",
       " '▁had',\n",
       " '▁a',\n",
       " '▁definite',\n",
       " '▁proliferating',\n",
       " '▁lifespan',\n",
       " '▁and',\n",
       " '▁were',\n",
       " '▁primarily',\n",
       " '▁diploid',\n",
       " '.',\n",
       " '▁in',\n",
       " '▁late',\n",
       " '▁passage',\n",
       " '▁cells',\n",
       " '▁grown',\n",
       " '▁as',\n",
       " '▁multilayers',\n",
       " ',',\n",
       " '▁alpha',\n",
       " '-',\n",
       " 'catenin',\n",
       " '▁was',\n",
       " '▁expressed',\n",
       " '▁but',\n",
       " '▁did',\n",
       " '▁not',\n",
       " '▁colocalize',\n",
       " '▁or',\n",
       " '▁coprecip',\n",
       " 'itate',\n",
       " '▁with',\n",
       " '▁e',\n",
       " '-',\n",
       " 'cadherin',\n",
       " ',',\n",
       " '▁suggesting',\n",
       " '▁its',\n",
       " '▁dissociation',\n",
       " '▁from',\n",
       " '▁e',\n",
       " '-',\n",
       " 'cadherin',\n",
       " '.',\n",
       " '▁coimmunoprecip',\n",
       " 'itation',\n",
       " '▁of',\n",
       " '▁alpha',\n",
       " '-',\n",
       " 'actinin',\n",
       " '▁with',\n",
       " '▁alpha',\n",
       " '-',\n",
       " 'catenin',\n",
       " '▁suggested',\n",
       " '▁an',\n",
       " '▁indirect',\n",
       " '▁link',\n",
       " '▁between',\n",
       " '▁the',\n",
       " '▁e',\n",
       " '-',\n",
       " 'cadherin',\n",
       " '-',\n",
       " 'beta',\n",
       " '-',\n",
       " 'catenin',\n",
       " '▁complex',\n",
       " '▁and',\n",
       " '▁alpha',\n",
       " '-',\n",
       " 'actinin',\n",
       " '▁via',\n",
       " '▁alpha',\n",
       " '-',\n",
       " 'catenin',\n",
       " '▁in',\n",
       " '▁early',\n",
       " ',',\n",
       " '▁but',\n",
       " '▁not',\n",
       " '▁in',\n",
       " '▁late',\n",
       " '▁passage',\n",
       " '▁cells',\n",
       " '.',\n",
       " '▁beta',\n",
       " '-',\n",
       " 'catenin',\n",
       " '▁in',\n",
       " '▁late',\n",
       " '▁passage',\n",
       " '▁cells',\n",
       " '▁was',\n",
       " '▁tyrosine',\n",
       " '▁phosphorylated',\n",
       " '▁and',\n",
       " '▁was',\n",
       " '▁not',\n",
       " '▁de',\n",
       " 'phosphorylated',\n",
       " '▁following',\n",
       " '▁the',\n",
       " '▁addition',\n",
       " '▁of',\n",
       " '▁inhibitors',\n",
       " '▁of',\n",
       " '▁tyrosine',\n",
       " '▁kinases',\n",
       " '.',\n",
       " '▁inhibition',\n",
       " '▁of',\n",
       " '▁de',\n",
       " 'phosphorylation',\n",
       " '▁of',\n",
       " '▁beta',\n",
       " '-',\n",
       " 'catenin',\n",
       " '▁in',\n",
       " '▁early',\n",
       " '▁passage',\n",
       " '▁cells',\n",
       " '▁by',\n",
       " '▁vanadate',\n",
       " ',',\n",
       " '▁an',\n",
       " '▁inhibitor',\n",
       " '▁of',\n",
       " '▁protein',\n",
       " '▁tyrosine',\n",
       " '▁phosphatases',\n",
       " ',',\n",
       " '▁caused',\n",
       " '▁overgrowth',\n",
       " '▁of',\n",
       " '▁cells',\n",
       " '▁beyond',\n",
       " '▁the',\n",
       " '▁saturation',\n",
       " '▁density',\n",
       " '▁and',\n",
       " '▁loss',\n",
       " '▁of',\n",
       " '▁alpha',\n",
       " '-',\n",
       " 'catenin',\n",
       " '▁from',\n",
       " '▁the',\n",
       " '▁e',\n",
       " '-',\n",
       " 'cadherin',\n",
       " '-',\n",
       " 'beta',\n",
       " '-',\n",
       " 'catenin',\n",
       " '▁complex',\n",
       " '.',\n",
       " '▁the',\n",
       " '▁results',\n",
       " '▁suggest',\n",
       " '▁that',\n",
       " '▁e',\n",
       " '-',\n",
       " 'cadherin',\n",
       " '▁requires',\n",
       " '▁its',\n",
       " '▁association',\n",
       " '▁with',\n",
       " '▁alpha',\n",
       " '-',\n",
       " 'actinin',\n",
       " '-',\n",
       " 'associated',\n",
       " '▁alpha',\n",
       " '-',\n",
       " 'catenin',\n",
       " '▁to',\n",
       " '▁maintain',\n",
       " '▁epithelial',\n",
       " '▁monolayers',\n",
       " '▁and',\n",
       " '▁accomplish',\n",
       " '▁the',\n",
       " '▁density',\n",
       " '-',\n",
       " 'dependent',\n",
       " '▁inhibition',\n",
       " '▁of',\n",
       " '▁growth',\n",
       " '.',\n",
       " '▁in',\n",
       " '▁addition',\n",
       " ',',\n",
       " '▁association',\n",
       " '▁between',\n",
       " '▁e',\n",
       " '-',\n",
       " 'cadherin',\n",
       " '▁and',\n",
       " '▁alpha',\n",
       " '-',\n",
       " 'catenin',\n",
       " '▁is',\n",
       " '▁suggested',\n",
       " '▁to',\n",
       " '▁be',\n",
       " '▁prevented',\n",
       " '▁by',\n",
       " '▁the',\n",
       " '▁presence',\n",
       " '▁of',\n",
       " '▁tyrosine',\n",
       " '▁phosphorylated',\n",
       " '▁beta',\n",
       " '-',\n",
       " 'catenin',\n",
       " '▁which',\n",
       " '▁associates',\n",
       " '▁with',\n",
       " '▁e',\n",
       " '-',\n",
       " 'cadherin',\n",
       " '.']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe_model.encode_as_pieces(article_map(articles[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
