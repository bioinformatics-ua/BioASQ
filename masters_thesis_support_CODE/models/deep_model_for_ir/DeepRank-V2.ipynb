{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from os.path import join\n",
    "import os\n",
    "os.chdir(\"/home/tiagoalmeida/bioASQ-taskb/\")\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "import gc\n",
    "import numpy as np\n",
    "import tarfile\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from bisect import bisect\n",
    "\n",
    "\n",
    "##add keras to the modules\n",
    "module_path = os.path.abspath(os.path.join('pubmed_data'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from pubmed_data import pubmed_helper as ph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepRank\n",
    "Reference PAPER :https://arxiv.org/pdf/1710.05649.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network structure\n",
    " - [General Network Configuration](#var_def)\n",
    " - [Input Network](#input_net)\n",
    " - [Measure Network](#measure_net)\n",
    " - [Aggregation Network](#aggreation_net)\n",
    " - [Final Network](#final_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load regex_full_tokens_tokenizer.p\n",
      "Load regex_full_tokens_word_embedding.p\n"
     ]
    }
   ],
   "source": [
    "#Load tokenizer and the embedding matrix\n",
    "\n",
    "MODE = \"regex_full_tokens\"\n",
    "tk = ph.load_tokenizer(mode=MODE)\n",
    "emb_dict = ph.load_embeddings(mode=MODE)\n",
    "\n",
    "assert len(tk.word_counts) == len(emb_dict)\n",
    "\n",
    "#Number of different words\n",
    "VOCAB_SIZE = len(tk.word_counts)+1\n",
    "\n",
    "#Dimension of embeddings\n",
    "EMB_DIM = emb_dict[1].shape[0]\n",
    "\n",
    "emb_matrix = np.zeros((VOCAB_SIZE, EMB_DIM))\n",
    "\n",
    "for i,vector in emb_dict.items():\n",
    "    emb_matrix[i] = vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenized stopwords\n",
    "\n",
    "biomedical_stop_words = [\"a\", \"about\", \"again\", \"all\", \"almost\", \"also\", \"although\", \"always\", \"among\", \"an\", \"and\", \"another\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"between\", \"both\", \"but\", \"by\", \"can\", \"could\", \"did\", \"do\", \"does\", \"done\", \"due\", \"during\", \"each\", \"either\", \"enough\", \"especially\", \"etc\", \"for\", \"found\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"here\", \"how\", \"however\", \"i\", \"if\", \"in\", \"into\", \"is\", \"it\", \"its\", \"itself\", \"just\", \"kg\", \"km\", \"made\", \"mainly\", \"make\", \"may\", \"mg\", \"might\", \"ml\", \"mm\", \"most\", \"mostly\", \"must\", \"nearly\", \"neither\", \"no\", \"nor\", \"obtained\", \"of\", \"often\", \"on\", \"our\", \"overall\", \"perhaps\", \"pmid\", \"quite\", \"rather\", \"really\", \"regarding\", \"seem\", \"seen\", \"several\", \"should\", \"show\", \"showed\", \"shown\", \"shows\", \"significantly\", \"since\", \"so\", \"some\", \"such\", \"than\", \"that\", \"the\", \"their\", \"theirs\", \"them\", \"then\", \"there\", \"therefore\", \"these\", \"they\", \"this\", \"those\", \"through\", \"thus\", \"to\", \"upon\", \"use\", \"used\", \"using\", \"various\", \"very\", \"was\", \"we\", \"were\", \"what\", \"when\", \"which\", \"while\", \"with\", \"within\", \"without\", \"would\"]\n",
    "biomedical_stop_words_tokens = set(tk.texts_to_sequences([biomedical_stop_words])[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='var_def'></a>\n",
    "## General Network Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow import unstack, stack\n",
    "##Test \n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import initializers, regularizers, activations\n",
    "from tensorflow.keras.initializers import Zeros, Ones, Constant\n",
    "from tensorflow.keras.layers import Dense, Lambda, Bidirectional, Dot,Masking,Reshape, Concatenate, Layer, Embedding, Input, Conv2D, GlobalMaxPooling2D, Flatten, TimeDistributed, GRU\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.activations import tanh, sigmoid\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "#Number max of term per query\n",
    "MAX_Q_TERM = 13\n",
    "\n",
    "#Number max of the snippet terms\n",
    "QUERY_CENTRIC_CONTEX = 15\n",
    "\n",
    "#Number max of passages per query term\n",
    "MAX_PASSAGES_PER_QUERY = 5\n",
    "\n",
    "#Snippet position padding value\n",
    "SNIPPET_POSITION_PADDING_VALUE = -1\n",
    "\n",
    "#Mode for the creation of the S matrix\n",
    "S_MATRIX_MODE = 0\n",
    "#S_MATRIX_DIMENSION = EMB_DIM*2+1\n",
    "\n",
    "#Train embedding weights\n",
    "EMB_TRAINABLE = False\n",
    "\n",
    "#Number of filters in CNN\n",
    "CNN_FILTERS = 100\n",
    "CNN_KERNELS = (3,3)\n",
    "\n",
    "#RNN DIM\n",
    "USE_BIDIRECTIONAL = False\n",
    "GRU_REPRESENTATION_DIM = 58\n",
    "\n",
    "ACTIVATION_FUNCTION = \"selu\"\n",
    "\n",
    "REGULARIZATION = regularizers.l2(0.0001)\n",
    "\n",
    "#Term gating network mode\n",
    "TERM_GATING_MODE =  3#2- weigt fixed per position, 1 - DRMM like term gating\n",
    "\n",
    "assert S_MATRIX_MODE in [0,1]\n",
    "assert TERM_GATING_MODE in [0,1,2,3]\n",
    "\n",
    "#MACRO STYLE\n",
    "def S_MATRIX_3D_DIMENSION():\n",
    "    if S_MATRIX_MODE==0:\n",
    "        return 1\n",
    "    elif S_MATRIX_MODE==1:\n",
    "        return EMB_DIM*2+1\n",
    "\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='input_net'></a>\n",
    "## Input Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "snippet_emb_model summary\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "snippet_token (InputLayer)   (None, 13, 5, 15)         0         \n",
      "_________________________________________________________________\n",
      "embedding_layer (Embedding)  (None, 13, 5, 15, 200)    858359000 \n",
      "_________________________________________________________________\n",
      "snippet_transpose (Lambda)   (None, 13, 5, 200, 15)    0         \n",
      "=================================================================\n",
      "Total params: 858,359,000\n",
      "Trainable params: 0\n",
      "Non-trainable params: 858,359,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "  ---- Custom Layers ----\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "class SimilarityMatrix(Layer):\n",
    "    \n",
    "    def __init__(self, query_max_term, snippet_max_term, interaction_mode=0, **kwargs):\n",
    "        \"\"\"\n",
    "        interaction mode 0: only use similarity matrix\n",
    "                    mode 1: similarity matrix + query and snippet embeddings\n",
    "        \"\"\"\n",
    "        assert interaction_mode in [0,1] #only valid modes\n",
    "        \n",
    "        self.query_max_term = query_max_term\n",
    "        self.snippet_max_term = snippet_max_term\n",
    "        self.interaction_mode = interaction_mode\n",
    "        \n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "    def call(self,x):\n",
    "        if self.interaction_mode==0:\n",
    "            #sim => dot product (None, MAX_Q_TERM, EMB_DIM) x (None, MAX_Q_TERM, MAX_PASSAGE_PER_Q, EMB_DIM, QUERY_CENTRIC_CONTEX)\n",
    "            query = K.expand_dims(x[0], axis=1) #(None, 1, MAX_Q_TERM, EMB_DIM)\n",
    "            query = K.expand_dims(query, axis=1) #(None, 1, 1, MAX_Q_TERM, EMB_DIM)\n",
    "            query = K.repeat_elements(query,x[1].shape[1],axis=1) #(None, MAX_PASSAGE_PER_Q, MAX_Q_TERM, EMB_DIM)\n",
    "            query = K.repeat_elements(query,x[1].shape[2],axis=2)\n",
    "            s_matrix = K.batch_dot(query,x[1]) #(None, MAX_PASSAGE_PER_Q, MAX_Q_TERM, #(None, MAX_PASSAGE_PER_Q, MAX_Q_TERM, EMB_DIM)\n",
    "            \n",
    "            s_matrix = K.expand_dims(s_matrix)\n",
    "            \n",
    "            return s_matrix #Add one more dimension #(None, MAX_PASSAGE_PER_Q, MAX_Q_TERM, #(None, MAX_PASSAGE_PER_Q, MAX_Q_TERM, EMB_DIM, 1)\n",
    "        elif self.interaction_mode==1:\n",
    "            raise NotImplementedError(\"interaction mode of layer SimilarityMatrix is not implemented\")\n",
    "    \"\"\"                  \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if self.interaction_mode==0:\n",
    "            return (input_shape[0][0], input_shape[0][1], self.query_max_term, self.snippet_max_term, 1)\n",
    "        elif self.interaction_mode==1:\n",
    "            return (input_shape[0][0], input_shape[0][1], self.query_max_term, self.snippet_max_term, input_shape[0][2]*input_shape[1][2]+1) \n",
    "    \"\"\"\n",
    "\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "     ---- Layers ----\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "#Embedding Layer\n",
    "embedding = Embedding(VOCAB_SIZE,EMB_DIM, name=\"embedding_layer\",weights=[emb_matrix], trainable=EMB_TRAINABLE)\n",
    "\n",
    "#S matrix ref in the paper\n",
    "similarity_matrix = SimilarityMatrix(MAX_Q_TERM, QUERY_CENTRIC_CONTEX, interaction_mode=S_MATRIX_MODE, name=\"query_snippet_similarity\")\n",
    "\n",
    "#transpose (None, QUERY_CENTRIC_CONTEX, EMB_DIM) => (None, EMB_DIM, QUERY_CENTRIC_CONTEX) \n",
    "transpose_layer = Lambda(lambda x:K.permute_dimensions(x,[0,1,2,4,3]), name=\"snippet_transpose\") \n",
    "\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    " ---- Auxiliar Models ----\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "\n",
    "#Snippet single embedding transformation\n",
    "snippet_token_input = Input(shape = (MAX_Q_TERM, MAX_PASSAGES_PER_QUERY, QUERY_CENTRIC_CONTEX,), name = \"snippet_token\")\n",
    "snippet_emb = embedding(snippet_token_input)\n",
    "snippet_emb_transpose = transpose_layer(snippet_emb)\n",
    "snippet_emb_model = Model(inputs = [snippet_token_input], outputs=[snippet_emb_transpose], name = \"snippet_emb_model\")\n",
    "print(\"\\n\\nsnippet_emb_model summary\")\n",
    "snippet_emb_model.summary()\n",
    "\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "  ---- Input Network ----\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "\n",
    "if DEBUG:\n",
    "    query_token_input = Input(shape=(MAX_Q_TERM,), name=\"query_tokens\")\n",
    "\n",
    "\n",
    "    snippets_tokens_input = Input(shape = (MAX_Q_TERM, MAX_PASSAGES_PER_QUERY, QUERY_CENTRIC_CONTEX), name = \"snippet_tokens_ipmodel\") \n",
    "    \n",
    "    query_emb = embedding(query_token_input)\n",
    "\n",
    "    snippet_emb = embedding(snippets_tokens_input)\n",
    "    snippet_emb_transpose = transpose_layer(snippet_emb)\n",
    "    \n",
    "    sim_matrix_layer = similarity_matrix([query_emb,snippet_emb_transpose])\n",
    "    \n",
    "    \n",
    "    \n",
    "    input_model = Model(inputs = [query_token_input,snippets_tokens_input], outputs=[sim_matrix_layer], name=\"input_model\")\n",
    "    print(\"\\n\\ninput_model summary\")\n",
    "    input_model.summary()\n",
    "    \n",
    "    \n",
    "    print(\"\\nOutput tensor\",sim_matrix_layer)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='measure_net'></a>\n",
    "## Measure Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"masked_conv2d/sub:0\", shape=(), dtype=float32)\n",
      "\n",
      "\n",
      "cnn_extraction_model summary\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masked_conv2d (MaskedConv2D) (None, 11, 13, 100)       1000      \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d (Global (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 1,000\n",
      "Trainable params: 1,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Tensor(\"time_distributed/masked_conv2d/sub:0\", shape=(), dtype=float32)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed (TimeDistri (None, 5, 100)            1000      \n",
      "=================================================================\n",
      "Total params: 1,000\n",
      "Trainable params: 1,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class FastMaskedConv2D(Layer):\n",
    "    \n",
    "    def __init__(self, filters, kernel_size, activation, regularizer=None, **kargs):\n",
    "        super(FastMaskedConv2D, self).__init__(**kargs)\n",
    "\n",
    "        self.activation = activations.get(activation)\n",
    "        \n",
    "        if regularizer is None or isinstance(regularizer,str):\n",
    "            self.regularizer = regularizers.get(regularizer)\n",
    "        else:\n",
    "            self.regularizer = regularizer\n",
    "        \n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.activation = activation\n",
    "\n",
    "    def build(self, input_shape):\n",
    "\n",
    "        self.conv2layer = Conv2D( filters = self.filters, kernel_size=self.kernel_size, activation=self.activation, kernel_regularizer=self.regularizer )\n",
    "        self.conv2layer.build(input_shape)\n",
    "        self._trainable_weights = self.conv2layer.trainable_weights\n",
    "        \n",
    "        self.convOutShape = self.conv2layer.compute_output_shape(input_shape)\n",
    "\n",
    "        super(FastMaskedConv2D, self).build(input_shape)\n",
    "    \n",
    "    def call(self, x):\n",
    "        \n",
    "        condition = K.all(x) #if all the values are the same\n",
    "        #print(condition)\n",
    "\n",
    "        #print(self.convOutShape)\n",
    "        #print(x)\n",
    "        zero_out = K.repeat_elements(x[:,:self.convOutShape[1],:self.convOutShape[2],:],self.convOutShape[3],axis=-1)\n",
    "        #print(zero_out)\n",
    "        \n",
    "        masked_conv = K.switch(condition, zero_out , self.conv2layer(x) )\n",
    "        \n",
    "        return masked_conv\n",
    "    \n",
    "class MaskedConv2D(Layer):\n",
    "    \n",
    "    def __init__(self, filters, kernel_size, activation, regularizer=None, **kargs):\n",
    "        super(MaskedConv2D, self).__init__(**kargs)\n",
    "\n",
    "        self.activation = activations.get(activation)\n",
    "        \n",
    "        if regularizer is None or isinstance(regularizer,str):\n",
    "            self.regularizer = regularizers.get(regularizer)\n",
    "        else:\n",
    "            self.regularizer = regularizer\n",
    "        \n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.activation = activation\n",
    "\n",
    "    def build(self, input_shape):\n",
    "\n",
    "        self.conv2dlayer = Conv2D( filters = self.filters, kernel_size=self.kernel_size, activation=self.activation, kernel_regularizer=self.regularizer )\n",
    "        self.conv2dlayer.build(input_shape)\n",
    "        self._trainable_weights = self.conv2dlayer.trainable_weights\n",
    "        \n",
    "        super(MaskedConv2D, self).build(input_shape)\n",
    "    \n",
    "    def call(self, x):\n",
    "        \n",
    "        condition = K.all(x) #if all the values are the same\n",
    "        inv_condition = (1-K.cast(condition, K.floatx()))\n",
    "        print(inv_condition)\n",
    "        feature_maps = self.conv2dlayer(x)\n",
    "        \n",
    "        return feature_maps * inv_condition\n",
    "\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    " ---- Auxiliar Models ----\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "\n",
    "#Exctrate high-level features from query and snippet interactions with CNN\n",
    "cnn_extraction_model = Sequential(name=\"cnn_extraction_model\")\n",
    "cnn_extraction_model.add(MaskedConv2D(input_shape = (MAX_Q_TERM, QUERY_CENTRIC_CONTEX, S_MATRIX_3D_DIMENSION()), filters = CNN_FILTERS, kernel_size=CNN_KERNELS, activation=ACTIVATION_FUNCTION ))\n",
    "cnn_extraction_model.add(GlobalMaxPooling2D())\n",
    "print(\"\\n\\ncnn_extraction_model summary\")\n",
    "cnn_extraction_model.summary()\n",
    "\n",
    "\n",
    "td_cnn_extraction_model = Sequential(name=\"TD_cnn_extraction_model\")\n",
    "td_cnn_extraction_model.add(TimeDistributed(cnn_extraction_model, input_shape=(MAX_PASSAGES_PER_QUERY, MAX_Q_TERM, QUERY_CENTRIC_CONTEX, S_MATRIX_3D_DIMENSION())))\n",
    "td_cnn_extraction_model.summary()\n",
    "\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "     ---- Layers ----\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "#concatenation layer over the last dimension\n",
    "concat_snippet_position = Concatenate( name = \"concat_snippet_position\")\n",
    "\n",
    "#RNN using GRU units\n",
    "if USE_BIDIRECTIONAL:\n",
    "    rnn_instance = GRU(GRU_REPRESENTATION_DIM, kernel_regularizer=REGULARIZATION, activation=ACTIVATION_FUNCTION, name=\"aggregation_snippet_by_q_term\")\n",
    "    gru = Bidirectional(rnn_instance, merge_mode=\"concat\")\n",
    "else:\n",
    "    gru = GRU(GRU_REPRESENTATION_DIM, kernel_regularizer=REGULARIZATION, activation=ACTIVATION_FUNCTION, name=\"aggregation_snippet_by_q_term\")\n",
    "    \n",
    "#add dimension Layer\n",
    "add_passage_dim = Lambda(lambda x:K.expand_dims(x,axis=1), name=\"add_passage_dim\")#Reshape(target_shape=(1,GRU_REPRESENTATION_DIM))\n",
    "\n",
    "#add last dimension Layer\n",
    "add_dim = Lambda(lambda x:K.expand_dims(x), name=\"add_dim\")\n",
    "\n",
    "#reciprocal function\n",
    "reciprocal_f = Lambda(lambda x:1/(x+2), name=\"reciprocal_function\")\n",
    "\n",
    "#concatenation layer over second dimension (passage dimension)\n",
    "concat_representation = Concatenate(axis = 1,name = \"concat_representation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='measure_net'></a>\n",
    "## Aggregation Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "  ---- Custom Layers ----\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "\n",
    "if USE_BIDIRECTIONAL:\n",
    "    snippet_rnn_rep_dim = GRU_REPRESENTATION_DIM*2\n",
    "else:\n",
    "    snippet_rnn_rep_dim = GRU_REPRESENTATION_DIM\n",
    "\n",
    "class TermGating(Layer):\n",
    "    \n",
    "    def __init__(self, vocab_size,activation=None, initializer='glorot_normal', regularizer=None):\n",
    "        super(TermGating, self).__init__()\n",
    "\n",
    "        self.activation = activations.get(activation)\n",
    "        self.initializer = initializers.get(initializer)\n",
    "        \n",
    "        if regularizer is None or isinstance(regularizer,str):\n",
    "            self.regularizer = regularizers.get(regularizer)\n",
    "        else:\n",
    "            self.regularizer = regularizer\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        #term gating W\n",
    "        self.We = self.add_variable(name = \"term_gating_We\",\n",
    "                                   shape = [self.vocab_size,1],\n",
    "                                   initializer = self.initializer,\n",
    "                                   regularizer = self.regularizer,)\n",
    "        \n",
    "        #self.ones = K.constant(np.ones((aggreation_dimension,1)))\n",
    "       \n",
    "        \"\"\" self.fully_connected_W = self.add_variable(name = \"fully_connect_We\",\n",
    "                                   shape = [self.vocab_size,1],\n",
    "                                   initializer = self.initializer,\n",
    "                                   regularizer = self.regularizer,)\n",
    "        \"\"\"\n",
    "        self.dense_score = Dense(1,kernel_regularizer = self.regularizer, activation=self.activation)\n",
    "        self.dense_score.build(input_shape[1])\n",
    "        self._trainable_weights += self.dense_score.trainable_weights\n",
    "        \n",
    "        super(TermGating, self).build(input_shape)\n",
    "    \n",
    "    def call(self, x):\n",
    "        #broadcast = self.We * self.ones\n",
    "        \n",
    "        query_token = K.cast(x[0],'int32') #(None, MAX_Q_TERM)\n",
    "        snippet_representation_per_query = x[1] #(None, MAX_Q_TERM, BI_GRU_DIM)\n",
    "        \n",
    "        query_token_onehot = K.one_hot(query_token, self.vocab_size)\n",
    "        print(query_token_onehot)\n",
    "        \n",
    "        query_vars = K.squeeze(K.dot(query_token_onehot,self.We),axis=-1)\n",
    "        print(query_vars) #(None, MAX_Q_TERM)\n",
    "        \n",
    "        query_term_prob = K.softmax(query_vars) \n",
    "        print(query_term_prob) #(None, MAX_Q_TERM)\n",
    "        \n",
    "        snippet_representation = K.expand_dims(query_term_prob) * snippet_representation_per_query\n",
    "        snippet_representation_sum = K.sum(snippet_representation, axis= 1)\n",
    "        #self.dense_score(snippet_representation_sum)\n",
    "        \n",
    "        return self.dense_score(snippet_representation_sum)\n",
    "    \n",
    "\n",
    "\n",
    "class TermGatingDRMM(Layer):\n",
    "    \n",
    "    def __init__(self, embedding_dim = EMB_DIM, activation=None, initializer='glorot_normal', regularizer=None):\n",
    "        super(TermGatingDRMM, self).__init__()\n",
    "\n",
    "        self.activation = activations.get(activation)\n",
    "        self.initializer = initializers.get(initializer)\n",
    "        \n",
    "        if regularizer is None or isinstance(regularizer,str):\n",
    "            self.regularizer = regularizers.get(regularizer)\n",
    "        else:\n",
    "            self.regularizer = regularizer\n",
    "        \n",
    "        self.emb_dim = embedding_dim\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        #term gating W\n",
    "        self.We = self.add_variable(name = \"term_gating_We\",\n",
    "                                   shape = [self.emb_dim,1],\n",
    "                                   initializer = self.initializer,\n",
    "                                   regularizer = self.regularizer,)\n",
    "        \n",
    "        #self.ones = K.constant(np.ones((aggreation_dimension,1)))\n",
    "        \n",
    "        super(TermGatingDRMM, self).build(input_shape)\n",
    "    \n",
    "    def call(self, x):\n",
    "        \n",
    "        query_embeddings = x[0] #(None, MAX_Q_TERM, EMB_SIZE)\n",
    "        snippet_representation_per_query = x[1] #(None, MAX_Q_TERM, BI_GRU_DIM)\n",
    "        \n",
    "        #compute gated weights\n",
    "        gated_logits = K.dot(query_embeddings, self.We) \n",
    "        gated_distribution = K.softmax(gated_logits)\n",
    "        \n",
    "        #apply the gated weights\n",
    "        #print(snippet_representation_per_query)\n",
    "        #print(gated_distribution)\n",
    "        \n",
    "        #normalization?\n",
    "        \n",
    "        return K.sum(K.sum(snippet_representation_per_query * gated_distribution, axis = -1),  axis = -1) # Replace with K.sum of all elements?\n",
    "\n",
    "\n",
    "\n",
    "class TermGatingDRMM_Projection(Layer):\n",
    "    \n",
    "    def __init__(self, embedding_dim = EMB_DIM, rnn_dim = snippet_rnn_rep_dim ,activation=None, initializer='glorot_normal', regularizer=None):\n",
    "        super(TermGatingDRMM_Projection, self).__init__()\n",
    "\n",
    "        self.activation = activations.get(activation)\n",
    "        self.initializer = initializers.get(initializer)\n",
    "        \n",
    "        if regularizer is None or isinstance(regularizer,str):\n",
    "            self.regularizer = regularizers.get(regularizer)\n",
    "        else:\n",
    "            self.regularizer = regularizer\n",
    "        \n",
    "        self.emb_dim = embedding_dim\n",
    "        self.rnn_dim = rnn_dim\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        #term gating W\n",
    "        self.W_query = self.add_variable(name = \"term_gating_We\",\n",
    "                                   shape = [self.emb_dim,1],\n",
    "                                   initializer = self.initializer,\n",
    "                                   regularizer = self.regularizer,)\n",
    "        \n",
    "        self.W_snippets_projection_score = self.add_variable(name = \"snippets_projection_score\",\n",
    "                                   shape = [self.rnn_dim,1],\n",
    "                                   initializer = self.initializer,\n",
    "                                   regularizer = self.regularizer,)\n",
    "    \n",
    "        #self.ones = K.constant(np.ones((aggreation_dimension,1)))\n",
    "        \n",
    "        super(TermGatingDRMM_Projection, self).build(input_shape)\n",
    "    \n",
    "    def call(self, x):\n",
    "        \n",
    "        query_embeddings = x[0] #(None, MAX_Q_TERM, EMB_SIZE)\n",
    "        snippet_representation_per_query = x[1] #(None, MAX_Q_TERM, BI_GRU_DIM)\n",
    "        \n",
    "        #compute gated weights\n",
    "        gated_logits = K.squeeze(K.dot(query_embeddings, self.W_query), axis = -1 )\n",
    "        #print(gated_logits)\n",
    "        gated_distribution = K.softmax(gated_logits)\n",
    "        #print(gated_distribution)\n",
    "        #snippet projection\n",
    "        snippets_score = K.squeeze(K.dot(snippet_representation_per_query, self.W_snippets_projection_score), axis = -1)\n",
    "        #snippets_score_activation = tanh(snippets_score)\n",
    "        \n",
    "        weighted_score = snippets_score * gated_distribution\n",
    "        \n",
    "        return K.sum(weighted_score,  axis = 1) # Replace with K.sum of all elements?\n",
    "\n",
    "    \n",
    "class TermGatingDRMM_FFN(Layer):\n",
    "    \n",
    "    def __init__(self, embedding_dim = EMB_DIM, rnn_dim = snippet_rnn_rep_dim ,activation=None, initializer='glorot_normal', regularizer=None):\n",
    "        super(TermGatingDRMM_FFN, self).__init__()\n",
    "\n",
    "        self.activation = activations.get(activation)\n",
    "        self.initializer = initializers.get(initializer)\n",
    "        \n",
    "        if regularizer is None or isinstance(regularizer,str):\n",
    "            self.regularizer = regularizers.get(regularizer)\n",
    "        else:\n",
    "            self.regularizer = regularizer\n",
    "        \n",
    "        self.emb_dim = embedding_dim\n",
    "        self.rnn_dim = rnn_dim\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        #term gating W\n",
    "        self.W_query = self.add_variable(name = \"term_gating_We\",\n",
    "                                   shape = [self.emb_dim,1],\n",
    "                                   initializer = self.initializer,\n",
    "                                   regularizer = self.regularizer,)\n",
    "        \n",
    "        self.dense_score = Dense(1,kernel_regularizer = self.regularizer, activation=self.activation)\n",
    "        \n",
    "        dense_shape = input_shape[1]\n",
    "        print(dense_shape)\n",
    "        \n",
    "        self.dense_score.build((dense_shape[0],dense_shape[2]))\n",
    "        self._trainable_weights += self.dense_score.trainable_weights\n",
    "        #self.ones = K.constant(np.ones((aggreation_dimension,1)))\n",
    "        \n",
    "        super(TermGatingDRMM_FFN, self).build(input_shape)\n",
    "    \n",
    "    def call(self, x):\n",
    "        \n",
    "        query_embeddings = x[0] #(None, MAX_Q_TERM, EMB_SIZE)\n",
    "        snippet_representation_per_query = x[1] #(None, MAX_Q_TERM, BI_GRU_DIM)\n",
    "        \n",
    "        #compute gated weights\n",
    "        gated_logits = K.squeeze(K.dot(query_embeddings, self.W_query), axis = -1 )\n",
    "        #print(gated_logits)\n",
    "        gated_distribution = K.expand_dims(K.softmax(gated_logits))\n",
    "        #print(gated_distribution)\n",
    "        #snippet projection\n",
    "        \n",
    "        weighted_score = K.sum(snippet_representation_per_query * gated_distribution,  axis = 1)\n",
    "        print(weighted_score)\n",
    "        \n",
    "        return self.dense_score(weighted_score) # Replace with K.sum of all elements?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='final_net'></a>\n",
    "## Final Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"TD_cnn_extraction_model/time_distributed/masked_conv2d/sub:0\", shape=(), dtype=float32)\n",
      "Tensor(\"TD_cnn_extraction_model_1/time_distributed/masked_conv2d/sub:0\", shape=(), dtype=float32)\n",
      "Tensor(\"TD_cnn_extraction_model_2/time_distributed/masked_conv2d/sub:0\", shape=(), dtype=float32)\n",
      "Tensor(\"TD_cnn_extraction_model_3/time_distributed/masked_conv2d/sub:0\", shape=(), dtype=float32)\n",
      "Tensor(\"TD_cnn_extraction_model_4/time_distributed/masked_conv2d/sub:0\", shape=(), dtype=float32)\n",
      "Tensor(\"TD_cnn_extraction_model_5/time_distributed/masked_conv2d/sub:0\", shape=(), dtype=float32)\n",
      "Tensor(\"TD_cnn_extraction_model_6/time_distributed/masked_conv2d/sub:0\", shape=(), dtype=float32)\n",
      "Tensor(\"TD_cnn_extraction_model_7/time_distributed/masked_conv2d/sub:0\", shape=(), dtype=float32)\n",
      "Tensor(\"TD_cnn_extraction_model_8/time_distributed/masked_conv2d/sub:0\", shape=(), dtype=float32)\n",
      "Tensor(\"TD_cnn_extraction_model_9/time_distributed/masked_conv2d/sub:0\", shape=(), dtype=float32)\n",
      "Tensor(\"TD_cnn_extraction_model_10/time_distributed/masked_conv2d/sub:0\", shape=(), dtype=float32)\n",
      "Tensor(\"TD_cnn_extraction_model_11/time_distributed/masked_conv2d/sub:0\", shape=(), dtype=float32)\n",
      "Tensor(\"TD_cnn_extraction_model_12/time_distributed/masked_conv2d/sub:0\", shape=(), dtype=float32)\n",
      "(?, 13, 58)\n",
      "Tensor(\"term_gating_drmm_ffn/Sum:0\", shape=(?, 58), dtype=float32)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "ds_query_tokens (InputLayer)    (None, 13)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ds_snippet_tokens (InputLayer)  (None, 13, 5, 15)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_layer (Embedding)     multiple             858359000   ds_query_tokens[0][0]            \n",
      "                                                                 ds_snippet_tokens[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "snippet_transpose (Lambda)      (None, 13, 5, 200, 1 0           embedding_layer[2][0]            \n",
      "__________________________________________________________________________________________________\n",
      "query_snippet_similarity (Simil (None, 13, 5, 13, 15 0           embedding_layer[1][0]            \n",
      "                                                                 snippet_transpose[1][0]          \n",
      "__________________________________________________________________________________________________\n",
      "ds_snippet_position_tokens (Inp (None, 13, 5)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "unstack_query_term (Lambda)     multiple             0           query_snippet_similarity[0][0]   \n",
      "                                                                 ds_snippet_position_tokens[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "reciprocal_function (Lambda)    (None, 5)            0           unstack_query_term[1][0]         \n",
      "                                                                 unstack_query_term[1][1]         \n",
      "                                                                 unstack_query_term[1][2]         \n",
      "                                                                 unstack_query_term[1][3]         \n",
      "                                                                 unstack_query_term[1][4]         \n",
      "                                                                 unstack_query_term[1][5]         \n",
      "                                                                 unstack_query_term[1][6]         \n",
      "                                                                 unstack_query_term[1][7]         \n",
      "                                                                 unstack_query_term[1][8]         \n",
      "                                                                 unstack_query_term[1][9]         \n",
      "                                                                 unstack_query_term[1][10]        \n",
      "                                                                 unstack_query_term[1][11]        \n",
      "                                                                 unstack_query_term[1][12]        \n",
      "__________________________________________________________________________________________________\n",
      "TD_cnn_extraction_model (Sequen (None, 5, 100)       1000        unstack_query_term[0][0]         \n",
      "                                                                 unstack_query_term[0][1]         \n",
      "                                                                 unstack_query_term[0][2]         \n",
      "                                                                 unstack_query_term[0][3]         \n",
      "                                                                 unstack_query_term[0][4]         \n",
      "                                                                 unstack_query_term[0][5]         \n",
      "                                                                 unstack_query_term[0][6]         \n",
      "                                                                 unstack_query_term[0][7]         \n",
      "                                                                 unstack_query_term[0][8]         \n",
      "                                                                 unstack_query_term[0][9]         \n",
      "                                                                 unstack_query_term[0][10]        \n",
      "                                                                 unstack_query_term[0][11]        \n",
      "                                                                 unstack_query_term[0][12]        \n",
      "__________________________________________________________________________________________________\n",
      "add_dim (Lambda)                (None, 5, 1)         0           reciprocal_function[0][0]        \n",
      "                                                                 reciprocal_function[1][0]        \n",
      "                                                                 reciprocal_function[2][0]        \n",
      "                                                                 reciprocal_function[3][0]        \n",
      "                                                                 reciprocal_function[4][0]        \n",
      "                                                                 reciprocal_function[5][0]        \n",
      "                                                                 reciprocal_function[6][0]        \n",
      "                                                                 reciprocal_function[7][0]        \n",
      "                                                                 reciprocal_function[8][0]        \n",
      "                                                                 reciprocal_function[9][0]        \n",
      "                                                                 reciprocal_function[10][0]       \n",
      "                                                                 reciprocal_function[11][0]       \n",
      "                                                                 reciprocal_function[12][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concat_snippet_position (Concat (None, 5, 101)       0           TD_cnn_extraction_model[1][0]    \n",
      "                                                                 add_dim[0][0]                    \n",
      "                                                                 TD_cnn_extraction_model[2][0]    \n",
      "                                                                 add_dim[1][0]                    \n",
      "                                                                 TD_cnn_extraction_model[3][0]    \n",
      "                                                                 add_dim[2][0]                    \n",
      "                                                                 TD_cnn_extraction_model[4][0]    \n",
      "                                                                 add_dim[3][0]                    \n",
      "                                                                 TD_cnn_extraction_model[5][0]    \n",
      "                                                                 add_dim[4][0]                    \n",
      "                                                                 TD_cnn_extraction_model[6][0]    \n",
      "                                                                 add_dim[5][0]                    \n",
      "                                                                 TD_cnn_extraction_model[7][0]    \n",
      "                                                                 add_dim[6][0]                    \n",
      "                                                                 TD_cnn_extraction_model[8][0]    \n",
      "                                                                 add_dim[7][0]                    \n",
      "                                                                 TD_cnn_extraction_model[9][0]    \n",
      "                                                                 add_dim[8][0]                    \n",
      "                                                                 TD_cnn_extraction_model[10][0]   \n",
      "                                                                 add_dim[9][0]                    \n",
      "                                                                 TD_cnn_extraction_model[11][0]   \n",
      "                                                                 add_dim[10][0]                   \n",
      "                                                                 TD_cnn_extraction_model[12][0]   \n",
      "                                                                 add_dim[11][0]                   \n",
      "                                                                 TD_cnn_extraction_model[13][0]   \n",
      "                                                                 add_dim[12][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "aggregation_snippet_by_q_term ( (None, 58)           27840       concat_snippet_position[0][0]    \n",
      "                                                                 concat_snippet_position[1][0]    \n",
      "                                                                 concat_snippet_position[2][0]    \n",
      "                                                                 concat_snippet_position[3][0]    \n",
      "                                                                 concat_snippet_position[4][0]    \n",
      "                                                                 concat_snippet_position[5][0]    \n",
      "                                                                 concat_snippet_position[6][0]    \n",
      "                                                                 concat_snippet_position[7][0]    \n",
      "                                                                 concat_snippet_position[8][0]    \n",
      "                                                                 concat_snippet_position[9][0]    \n",
      "                                                                 concat_snippet_position[10][0]   \n",
      "                                                                 concat_snippet_position[11][0]   \n",
      "                                                                 concat_snippet_position[12][0]   \n",
      "__________________________________________________________________________________________________\n",
      "add_passage_dim (Lambda)        (None, 1, 58)        0           aggregation_snippet_by_q_term[0][\n",
      "                                                                 aggregation_snippet_by_q_term[1][\n",
      "                                                                 aggregation_snippet_by_q_term[2][\n",
      "                                                                 aggregation_snippet_by_q_term[3][\n",
      "                                                                 aggregation_snippet_by_q_term[4][\n",
      "                                                                 aggregation_snippet_by_q_term[5][\n",
      "                                                                 aggregation_snippet_by_q_term[6][\n",
      "                                                                 aggregation_snippet_by_q_term[7][\n",
      "                                                                 aggregation_snippet_by_q_term[8][\n",
      "                                                                 aggregation_snippet_by_q_term[9][\n",
      "                                                                 aggregation_snippet_by_q_term[10]\n",
      "                                                                 aggregation_snippet_by_q_term[11]\n",
      "                                                                 aggregation_snippet_by_q_term[12]\n",
      "__________________________________________________________________________________________________\n",
      "concat_representation (Concaten (None, 13, 58)       0           add_passage_dim[0][0]            \n",
      "                                                                 add_passage_dim[1][0]            \n",
      "                                                                 add_passage_dim[2][0]            \n",
      "                                                                 add_passage_dim[3][0]            \n",
      "                                                                 add_passage_dim[4][0]            \n",
      "                                                                 add_passage_dim[5][0]            \n",
      "                                                                 add_passage_dim[6][0]            \n",
      "                                                                 add_passage_dim[7][0]            \n",
      "                                                                 add_passage_dim[8][0]            \n",
      "                                                                 add_passage_dim[9][0]            \n",
      "                                                                 add_passage_dim[10][0]           \n",
      "                                                                 add_passage_dim[11][0]           \n",
      "                                                                 add_passage_dim[12][0]           \n",
      "__________________________________________________________________________________________________\n",
      "term_gating_drmm_ffn (TermGatin (None, 1)            259         embedding_layer[1][0]            \n",
      "                                                                 concat_representation[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 858,388,099\n",
      "Trainable params: 29,099\n",
      "Non-trainable params: 858,359,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "  ---- Final Network ----\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "query_token_input = Input(shape=(MAX_Q_TERM,), name=\"ds_query_tokens\")\n",
    "doc_score_snippet_input = Input(shape = (MAX_Q_TERM,MAX_PASSAGES_PER_QUERY,QUERY_CENTRIC_CONTEX), name = \"ds_snippet_tokens\")\n",
    "doc_score_snippet_position_input = Input(shape = (MAX_Q_TERM,MAX_PASSAGES_PER_QUERY), name = \"ds_snippet_position_tokens\")\n",
    "\n",
    "\n",
    "unstack_by_q_term = Lambda(lambda x:unstack(x,axis=1), name=\"unstack_query_term\")\n",
    "\n",
    "#doc_score_snippet_by_q_term = unstack_by_q_term(doc_score_snippet_input)\n",
    "#doc_score_snippet_position_by_q_term = unstack_by_q_term(doc_score_snippet_position_input)\n",
    "\n",
    "#INPUT in token format\n",
    "#query_token_input = Input(shape=(MAX_Q_TERM,), name=\"query_tokens\")\n",
    "#snippets_tokens_input = [Input(shape = (MAX_PASSAGES_PER_QUERY,QUERY_CENTRIC_CONTEX), name = \"snippet_tokens_\"+str(q)) for q in range(MAX_Q_TERM)]\n",
    "#inputs_contex_position = [Input(shape = (MAX_PASSAGES_PER_QUERY,), name = \"q_context_position_\"+str(q)) for q in range(MAX_Q_TERM)]\n",
    "\n",
    "query_emb = embedding(query_token_input)\n",
    "\n",
    "doc_score_snippet_emb = embedding(doc_score_snippet_input)\n",
    "doc_score_snippet_emb_transpose = transpose_layer(doc_score_snippet_emb)\n",
    "\n",
    "query_snippets_s_matrix = similarity_matrix([query_emb,doc_score_snippet_emb_transpose])\n",
    "\n",
    "list_of_s_matrix_by_q_term = unstack_by_q_term(query_snippets_s_matrix)\n",
    "list_of_snippet_postion_by_q_term = unstack_by_q_term(doc_score_snippet_position_input)\n",
    "\n",
    "relevance_representation = []\n",
    "for i in range(MAX_Q_TERM):\n",
    "    \n",
    "    snippet_relative_position = reciprocal_f(list_of_snippet_postion_by_q_term[i])\n",
    "    \n",
    "    local_relevance = td_cnn_extraction_model(list_of_s_matrix_by_q_term[i])\n",
    "    \n",
    "    local_relevance_position = concat_snippet_position([local_relevance,add_dim(snippet_relative_position)])\n",
    "    \n",
    "    relevance_representation.append(add_passage_dim(gru(local_relevance_position)))\n",
    "\n",
    "concat_relevance = concat_representation(relevance_representation)\n",
    "\n",
    "if TERM_GATING_MODE==0:\n",
    "    term_gating = TermGating(vocab_size=VOCAB_SIZE, activation=ACTIVATION_FUNCTION)\n",
    "    document_score = term_gating([query_token_input,concat_relevance])\n",
    "    \n",
    "elif TERM_GATING_MODE==1:\n",
    "    term_gating = TermGatingDRMM()\n",
    "    document_score = term_gating([query_emb,concat_relevance])\n",
    "\n",
    "elif TERM_GATING_MODE==2:\n",
    "    term_gating = TermGatingDRMM_Projection()\n",
    "    document_score = term_gating([query_emb,concat_relevance])\n",
    "\n",
    "elif TERM_GATING_MODE==3:\n",
    "    term_gating = TermGatingDRMM_FFN(activation=ACTIVATION_FUNCTION, regularizer=REGULARIZATION)\n",
    "    document_score = term_gating([query_emb,concat_relevance])\n",
    "\n",
    "document_score_model = Model(inputs = [query_token_input, doc_score_snippet_input, doc_score_snippet_position_input], outputs = [document_score], name=\"query_document_score\")\n",
    "document_score_model.summary()      \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINAL Trainable arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"query_document_score/TD_cnn_extraction_model/time_distributed/masked_conv2d/sub:0\", shape=(), dtype=float32)\n",
      "Tensor(\"query_document_score/TD_cnn_extraction_model_1/time_distributed/masked_conv2d/sub:0\", shape=(), dtype=float32)\n",
      "Tensor(\"query_document_score/TD_cnn_extraction_model_2/time_distributed/masked_conv2d/sub:0\", shape=(), dtype=float32)\n",
      "Tensor(\"query_document_score/TD_cnn_extraction_model_3/time_distributed/masked_conv2d/sub:0\", shape=(), dtype=float32)\n",
      "Tensor(\"query_document_score/TD_cnn_extraction_model_4/time_distributed/masked_conv2d/sub:0\", shape=(), dtype=float32)\n",
      "Tensor(\"query_document_score/TD_cnn_extraction_model_5/time_distributed/masked_conv2d/sub:0\", shape=(), dtype=float32)\n",
      "Tensor(\"query_document_score/TD_cnn_extraction_model_6/time_distributed/masked_conv2d/sub:0\", shape=(), dtype=float32)\n",
      "Tensor(\"query_document_score/TD_cnn_extraction_model_7/time_distributed/masked_conv2d/sub:0\", shape=(), dtype=float32)\n",
      "Tensor(\"query_document_score/TD_cnn_extraction_model_8/time_distributed/masked_conv2d/sub:0\", shape=(), dtype=float32)\n",
      "Tensor(\"query_document_score/TD_cnn_extraction_model_9/time_distributed/masked_conv2d/sub:0\", shape=(), dtype=float32)\n",
      "Tensor(\"query_document_score/TD_cnn_extraction_model_10/time_distributed/masked_conv2d/sub:0\", shape=(), dtype=float32)\n",
      "Tensor(\"query_document_score/TD_cnn_extraction_model_11/time_distributed/masked_conv2d/sub:0\", shape=(), dtype=float32)\n",
      "Tensor(\"query_document_score/TD_cnn_extraction_model_12/time_distributed/masked_conv2d/sub:0\", shape=(), dtype=float32)\n",
      "Tensor(\"query_document_score/term_gating_drmm_ffn/Sum:0\", shape=(?, 58), dtype=float32)\n",
      "Tensor(\"query_document_score_1/TD_cnn_extraction_model/time_distributed/masked_conv2d/sub:0\", shape=(), dtype=float32)\n",
      "Tensor(\"query_document_score_1/TD_cnn_extraction_model_1/time_distributed/masked_conv2d/sub:0\", shape=(), dtype=float32)\n",
      "Tensor(\"query_document_score_1/TD_cnn_extraction_model_2/time_distributed/masked_conv2d/sub:0\", shape=(), dtype=float32)\n",
      "Tensor(\"query_document_score_1/TD_cnn_extraction_model_3/time_distributed/masked_conv2d/sub:0\", shape=(), dtype=float32)\n",
      "Tensor(\"query_document_score_1/TD_cnn_extraction_model_4/time_distributed/masked_conv2d/sub:0\", shape=(), dtype=float32)\n",
      "Tensor(\"query_document_score_1/TD_cnn_extraction_model_5/time_distributed/masked_conv2d/sub:0\", shape=(), dtype=float32)\n",
      "Tensor(\"query_document_score_1/TD_cnn_extraction_model_6/time_distributed/masked_conv2d/sub:0\", shape=(), dtype=float32)\n",
      "Tensor(\"query_document_score_1/TD_cnn_extraction_model_7/time_distributed/masked_conv2d/sub:0\", shape=(), dtype=float32)\n",
      "Tensor(\"query_document_score_1/TD_cnn_extraction_model_8/time_distributed/masked_conv2d/sub:0\", shape=(), dtype=float32)\n",
      "Tensor(\"query_document_score_1/TD_cnn_extraction_model_9/time_distributed/masked_conv2d/sub:0\", shape=(), dtype=float32)\n",
      "Tensor(\"query_document_score_1/TD_cnn_extraction_model_10/time_distributed/masked_conv2d/sub:0\", shape=(), dtype=float32)\n",
      "Tensor(\"query_document_score_1/TD_cnn_extraction_model_11/time_distributed/masked_conv2d/sub:0\", shape=(), dtype=float32)\n",
      "Tensor(\"query_document_score_1/TD_cnn_extraction_model_12/time_distributed/masked_conv2d/sub:0\", shape=(), dtype=float32)\n",
      "Tensor(\"query_document_score_1/term_gating_drmm_ffn/Sum:0\", shape=(?, 58), dtype=float32)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "dr_query_tokens (InputLayer)    (None, 13)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "positive_snippet_tokens (InputL (None, 13, 5, 15)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "positive_snippet_position_token (None, 13, 5)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "negative_snippet_tokens (InputL (None, 13, 5, 15)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "negative_snippet_position_token (None, 13, 5)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "query_document_score (Model)    (None, 1)            858388099   dr_query_tokens[0][0]            \n",
      "                                                                 positive_snippet_tokens[0][0]    \n",
      "                                                                 positive_snippet_position_tokens[\n",
      "                                                                 dr_query_tokens[0][0]            \n",
      "                                                                 negative_snippet_tokens[0][0]    \n",
      "                                                                 negative_snippet_position_tokens[\n",
      "==================================================================================================\n",
      "Total params: 858,388,099\n",
      "Trainable params: 29,099\n",
      "Non-trainable params: 858,359,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "query_token_input = Input(shape=(MAX_Q_TERM,), name=\"dr_query_tokens\")\n",
    "positive_snippet_input = Input(shape = (MAX_Q_TERM,MAX_PASSAGES_PER_QUERY,QUERY_CENTRIC_CONTEX), name = \"positive_snippet_tokens\")\n",
    "positive_snippet_position_input = Input(shape = (MAX_Q_TERM,MAX_PASSAGES_PER_QUERY), name = \"positive_snippet_position_tokens\")\n",
    "negative_snippet_input = Input(shape = (MAX_Q_TERM,MAX_PASSAGES_PER_QUERY,QUERY_CENTRIC_CONTEX), name = \"negative_snippet_tokens\")\n",
    "negative_snippet_position_input = Input(shape = (MAX_Q_TERM,MAX_PASSAGES_PER_QUERY), name = \"negative_snippet_position_tokens\")\n",
    "\n",
    "positive_documents_score = document_score_model([query_token_input, positive_snippet_input, positive_snippet_position_input])\n",
    "negative_documents_score = document_score_model([query_token_input, negative_snippet_input, negative_snippet_position_input])\n",
    "\n",
    "#stack_socres = stack_scores_layer([positive_documents_score,negative_documents_score])\n",
    "\n",
    "\n",
    "\n",
    "#pairwise_loss_layer = Lambda(pairwise_hinge_loss, name=\"pairwise_hinge\")\n",
    "#pairwise_loss = pairwise_loss_layer([positive_documents_score,negative_documents_score])\n",
    "\n",
    "\n",
    "\n",
    "inputs = [query_token_input, positive_snippet_input, positive_snippet_position_input, negative_snippet_input, negative_snippet_position_input]\n",
    "\n",
    "deepRank_model = Model(inputs = inputs, outputs = [positive_documents_score, negative_documents_score], name=\"deep_rank\")\n",
    "\n",
    "\n",
    "p_loss = K.mean(K.maximum(0.0, 1.0 - positive_documents_score + negative_documents_score))\n",
    "\n",
    "deepRank_model.add_loss(p_loss)\n",
    "\n",
    "deepRank_model.summary() \n",
    "#m.predict([Q, Q_t1_passage, Q_t2_passage, Q_t3_passage, Q_t1_passage_pos, Q_t2_passage_pos, Q_t3_passage_pos])\n",
    "\n",
    "#deepRank_model.compile(loss=pairwise_hinge_loss, optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "WRITE_GRAPH = False\n",
    "if WRITE_GRAPH:\n",
    "    from tensorflow.summary import FileWriter\n",
    "\n",
    "    graph = K.get_session().graph\n",
    "     # Your model implementation\n",
    "    #with graph.as_default():\n",
    "      # compile method actually creates the model in the graph.\n",
    "      #deepRank_model.compile(loss=identity_loss, optimizer='adam', metrics=['accuracy'])\n",
    "    writer = FileWriter(logdir='tensorboard/deepRank_V2', graph=graph)\n",
    "    writer.flush()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#document_score.predict([Q, Q_t1_passage, Q_t2_passage, Q_t3_passage, Q_t1_passage_pos, Q_t2_passage_pos, Q_t3_passage_pos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open /backup/results/fast_method_relevant_results/train_data_deep_models_v2.tar.gz\n"
     ]
    }
   ],
   "source": [
    "path_dl_train = \"/backup/results/fast_method_relevant_results/train_data_deep_models_v2.tar.gz\"\n",
    "\n",
    "\n",
    "\n",
    "tar = tarfile.open(path_dl_train)\n",
    "#open\n",
    "print(\"Open\",path_dl_train)\n",
    "m = tar.getmembers()[0]\n",
    "f = tar.extractfile(m)\n",
    "train_articles_collection = pickle.load(f)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARTILLY_POSITIVE_SAMPLES = 2\n",
    "NEGATIVE_SAMPLES = 3\n",
    "\n",
    "class TrainDataGenerator(object):\n",
    "    def __init__(self, article_collection, tokenizer, batch_queries_size):\n",
    "        \n",
    "        self.batch_size = batch_queries_size\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "        self.train_data = article_collection[\"bioasq_data\"]\n",
    "        self.articles = article_collection[\"collection\"]\n",
    "        self.irrelevant_pmid = article_collection[\"irrelevant_pmid\"]\n",
    "        \n",
    "        self.num_steps = len(self.train_data)//self.batch_size\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.num_steps\n",
    "    \n",
    "    def __iter__(self):\n",
    "        \n",
    "        \n",
    "        query = []\n",
    "        query_positive_doc = []\n",
    "        query_positive_doc_position = []\n",
    "        query_negative_doc = []\n",
    "        query_negative_doc_position = []\n",
    "        \n",
    "        while True:\n",
    "            \n",
    "            #stop condition\n",
    "            if len(query)>=self.batch_size:\n",
    "                #missing fill the gap for the missing query_terms\n",
    "                query = np.array(query)\n",
    "                p=np.random.permutation(query.shape[0])\n",
    "                query = query[p]\n",
    "                query_positive_doc = np.array(query_positive_doc)[p]\n",
    "                query_positive_doc_position = np.array(query_positive_doc_position)[p]\n",
    "                query_negative_doc = np.array(query_negative_doc)[p]\n",
    "                query_negative_doc_position =  np.array(query_negative_doc_position)[p]\n",
    "                \n",
    "                X = [query, query_positive_doc, query_positive_doc_position, query_negative_doc, query_negative_doc_position]\n",
    "                #Y = [np.zeros((len(query))),np.zeros((len(query)))]\n",
    "                yield X\n",
    "\n",
    "\n",
    "                #reset\n",
    "                query = []\n",
    "                query_positive_doc = []\n",
    "                query_positive_doc_position = []\n",
    "                query_negative_doc = []\n",
    "                query_negative_doc_position = []\n",
    "            \n",
    "            #select a random question\n",
    "            random_query_index = random.randint(0, len(self.train_data)-1) \n",
    "            query_data = self.train_data[random_query_index]\n",
    "            \n",
    "            #list of partilly relevant documents\n",
    "            partilly_positive_pmid_docs = query_data[\"partilly_positive_pmid\"]\n",
    "\n",
    "            tokenized_query = query_data[\"query\"][:MAX_Q_TERM]\n",
    "            \n",
    "            for j in range(PARTILLY_POSITIVE_SAMPLES+NEGATIVE_SAMPLES):\n",
    "                #select a random positive\n",
    "                random_doc_index = random.randint(0, len(query_data[\"positive_pmid\"])-1) \n",
    "                doc_pmid = query_data[\"positive_pmid\"][random_doc_index]\n",
    "\n",
    "                tokenized_positive_doc = self.articles[doc_pmid]\n",
    "                positive_snippets, positive_snippets_position = self.__snippet_interaction(tokenized_query, tokenized_positive_doc)\n",
    "                \n",
    "                if j<PARTILLY_POSITIVE_SAMPLES:\n",
    "                    #select the partilly posivite doc\n",
    "                    random_ind = bisect(query_data[\"partially_positive_cumulative_prob\"],random.random())\n",
    "                    random_negative_doc_pmid = query_data[\"partilly_positive_pmid\"][random_ind]\n",
    "                    #print(self.__get_article(random_negative_doc_pmid))\n",
    "                    tokenized_negative_doc = self.articles[random_negative_doc_pmid]\n",
    "                    negative_snippets, negative_snippets_position = self.__snippet_interaction(tokenized_query, tokenized_negative_doc)\n",
    "                else:\n",
    "                    #select a random negative\n",
    "                    random_doc_index = random.randint(0, len(self.irrelevant_pmid)-1) \n",
    "                    doc_pmid = self.irrelevant_pmid[random_doc_index]\n",
    "                    \n",
    "                    tokenized_negative_doc = self.articles[doc_pmid]\n",
    "                    negative_snippets, negative_snippets_position = self.__snippet_interaction(tokenized_query, tokenized_negative_doc)\n",
    "                \n",
    "                \n",
    "                ### add ###\n",
    "\n",
    "                #not efficient\n",
    "                query.append(tokenized_query)\n",
    "\n",
    "                #positive doc\n",
    "                query_positive_doc.append(positive_snippets)\n",
    "                query_positive_doc_position.append(positive_snippets_position)\n",
    "\n",
    "                #negative doc\n",
    "                query_negative_doc.append(negative_snippets)\n",
    "                query_negative_doc_position.append(negative_snippets_position)\n",
    "            \n",
    "\n",
    "            \n",
    "    def __snippet_interaction(self, tokenized_query, tokenized_doc, snippet_length=QUERY_CENTRIC_CONTEX):\n",
    "        \n",
    "        snippets = []\n",
    "        snippets_position = [] \n",
    "\n",
    "        half_size = snippet_length//2\n",
    "        \n",
    "        #O(n^2) complexity, probably can do better with better data struct TODO see if is worthit\n",
    "        for query_token in tokenized_query:\n",
    "            \n",
    "            snippets_per_token = []\n",
    "            snippets_per_token_position = []\n",
    "            \n",
    "            if query_token != 0: #jump padded token\n",
    "            \n",
    "                for i,doc_token in enumerate(tokenized_doc):\n",
    "\n",
    "                    if doc_token==query_token:\n",
    "\n",
    "                        lower_index = i-half_size\n",
    "                        lower_index = max(0,lower_index)\n",
    "\n",
    "                        higher_index = i+half_size\n",
    "                        higher_index = min(len(tokenized_doc),higher_index)\n",
    "\n",
    "                        snippets_per_token.append(tokenized_doc[lower_index:higher_index])\n",
    "                        snippets_per_token_position.append(i)\n",
    "            \n",
    "            if len(snippets_per_token)==0:\n",
    "                snippets.append(np.zeros((MAX_PASSAGES_PER_QUERY,QUERY_CENTRIC_CONTEX), dtype=np.int32))\n",
    "                snippets_position.append(np.zeros((MAX_PASSAGES_PER_QUERY), dtype=np.int32)+SNIPPET_POSITION_PADDING_VALUE)\n",
    "                continue\n",
    "                \n",
    "            max_snippets_len = min(MAX_PASSAGES_PER_QUERY, len(snippets_per_token))\n",
    "            \n",
    "            ### snippets in matrix format\n",
    "            #pad\n",
    "            snippets_per_token = pad_sequences(snippets_per_token, maxlen = QUERY_CENTRIC_CONTEX, padding=\"post\")\n",
    "            #fill the gaps\n",
    "            _temp = np.zeros((MAX_PASSAGES_PER_QUERY,QUERY_CENTRIC_CONTEX), dtype=np.int32)\n",
    "            _temp[:max_snippets_len] = snippets_per_token[:max_snippets_len]\n",
    "            snippets.append(_temp)\n",
    "            \n",
    "            ### snippets_position in matrix format\n",
    "            #pad\n",
    "            snippets_per_token_position = pad_sequences([snippets_per_token_position], maxlen = MAX_PASSAGES_PER_QUERY, padding=\"post\", value=SNIPPET_POSITION_PADDING_VALUE)[0]\n",
    "            snippets_position.append(snippets_per_token_position)\n",
    "            \n",
    "        return snippets, snippets_position\n",
    "            \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "            \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test (validation) data generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open /backup/results/fast_method_relevant_results/test_data_deep_models_v2.tar.gz\n"
     ]
    }
   ],
   "source": [
    "path_dl_test = \"/backup/results/fast_method_relevant_results/test_data_deep_models_v2.tar.gz\"\n",
    "\n",
    "\n",
    "\n",
    "tar = tarfile.open(path_dl_test)\n",
    "#open\n",
    "print(\"Open\",path_dl_test)\n",
    "m = tar.getmembers()[0]\n",
    "f = tar.extractfile(m)\n",
    "test_articles_collection = pickle.load(f)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TestDataGenerator(object):\n",
    "    def __init__(self, article_collection, tokenizer):\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "        self.test_data = article_collection[\"bioasq_data\"] \n",
    "        self.articles = article_collection[\"collection\"]\n",
    "        \n",
    "        self.num_steps = len(self.test_data)\n",
    "        \n",
    "    \n",
    "    def __get_article(self, pmid):\n",
    "        return self.article_map(self.articles[pmid])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.num_steps\n",
    "    \n",
    "    def __iter__(self):\n",
    "        \n",
    "        \n",
    "        query = []\n",
    "        query_doc = []\n",
    "        query_doc_position = []\n",
    "        \n",
    "\n",
    "        for query_data in self.test_data:\n",
    "\n",
    "            #tokenized_query = self.tokenizer.texts_to_sequences([query_data[\"query\"]])[0]\n",
    "            tokenized_query = query_data[\"query\"][:MAX_Q_TERM]\n",
    "            #manualy remove the stopwords\n",
    "            #tokenized_query = [ token for token in tokenized_query if token not in biomedical_stop_words_tokens]\n",
    "\n",
    "            #tokenized_query = pad_sequences([tokenized_query], maxlen = MAX_Q_TERM, padding=\"post\")[0]\n",
    "\n",
    "            for doc_pmid in query_data[\"documents\"]:\n",
    "                #positive\n",
    "\n",
    "                tokenized_doc = self.articles[doc_pmid]\n",
    "                doc_snippets, doc_snippets_position = self.__snippet_interaction(tokenized_query, tokenized_doc)\n",
    "\n",
    "                ### add ###\n",
    "\n",
    "                query.append(tokenized_query)\n",
    "\n",
    "                #positive doc\n",
    "                query_doc.append(doc_snippets)\n",
    "                query_doc_position.append(doc_snippets_position)\n",
    "\n",
    "\n",
    "            #missing fill the gap for the missing query_terms\n",
    "\n",
    "            X = [np.array(query), np.array(query_doc), np.array(query_doc_position)]\n",
    "\n",
    "            yield X\n",
    "\n",
    "            #reset\n",
    "            query = []\n",
    "            query_doc = []\n",
    "            query_doc_position = []\n",
    "\n",
    "                \n",
    "    def __snippet_interaction(self, tokenized_query, tokenized_doc, snippet_length=QUERY_CENTRIC_CONTEX):\n",
    "        \n",
    "        snippets = []\n",
    "        snippets_position = [] \n",
    "\n",
    "        half_size = snippet_length//2\n",
    "        \n",
    "        #O(n^2) complexity, probably can do better with better data struct TODO see if is worthit\n",
    "        for query_token in tokenized_query:\n",
    "            \n",
    "            snippets_per_token = []\n",
    "            snippets_per_token_position = []\n",
    "            \n",
    "            if query_token != 0: #jump padded token\n",
    "                \n",
    "                for i,doc_token in enumerate(tokenized_doc):\n",
    "\n",
    "                    if doc_token==query_token:\n",
    "\n",
    "                        lower_index = i-half_size\n",
    "                        lower_index = max(0,lower_index)\n",
    "\n",
    "                        higher_index = i+half_size\n",
    "                        higher_index = min(len(tokenized_doc),higher_index)\n",
    "\n",
    "                        snippets_per_token.append(tokenized_doc[lower_index:higher_index])\n",
    "                        snippets_per_token_position.append(i)\n",
    "\n",
    "            if len(snippets_per_token)==0:\n",
    "                snippets.append(np.zeros((MAX_PASSAGES_PER_QUERY,QUERY_CENTRIC_CONTEX), dtype=np.int32))\n",
    "                snippets_position.append(np.zeros((MAX_PASSAGES_PER_QUERY), dtype=np.int32)+SNIPPET_POSITION_PADDING_VALUE)\n",
    "                continue\n",
    "                \n",
    "            max_snippets_len = min(MAX_PASSAGES_PER_QUERY, len(snippets_per_token))\n",
    "            \n",
    "            ### snippets in matrix format\n",
    "            #pad\n",
    "            snippets_per_token = pad_sequences(snippets_per_token, maxlen = QUERY_CENTRIC_CONTEX, padding=\"post\")\n",
    "            #fill the gaps\n",
    "            _temp = np.zeros((MAX_PASSAGES_PER_QUERY,QUERY_CENTRIC_CONTEX), dtype=np.int32)\n",
    "            _temp[:max_snippets_len] = snippets_per_token[:max_snippets_len]\n",
    "            snippets.append(_temp)\n",
    "            \n",
    "            ### snippets_position in matrix format\n",
    "            #pad\n",
    "            snippets_per_token_position = pad_sequences([snippets_per_token_position], maxlen = MAX_PASSAGES_PER_QUERY, padding=\"post\",value=SNIPPET_POSITION_PADDING_VALUE)[0]\n",
    "            snippets_position.append(snippets_per_token_position)\n",
    "            \n",
    "        return snippets, snippets_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549\n",
      "82\n",
      "validation size 82 test size 549\n"
     ]
    }
   ],
   "source": [
    "validation_articles_collection = {\"bioasq_data\":[],\"collection\":test_articles_collection[\"collection\"]}\n",
    "\n",
    "_temp = test_articles_collection[\"bioasq_data\"][:]\n",
    "random.shuffle(_temp)\n",
    "print(len(_temp))\n",
    "\n",
    "validation_percentage = 0.15\n",
    "\n",
    "split_index = int(len(_temp)*validation_percentage)\n",
    "print(split_index)\n",
    "\n",
    "validation_articles_collection[\"bioasq_data\"] = _temp[:split_index]\n",
    "#test_articles_collection[\"bioasq_data\"] = _temp[split_index:]\n",
    "\n",
    "print(\"validation size\",len(validation_articles_collection[\"bioasq_data\"]),\"test size\",len(test_articles_collection[\"bioasq_data\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_test_data(data):\n",
    "    data_generator = TestDataGenerator(data, tk)\n",
    "    data_generator = iter(data_generator)\n",
    "\n",
    "    query_results = {}\n",
    "\n",
    "    for i,X in enumerate(data_generator):\n",
    "        print(\"Predict query:\",i,end=\"\\r\")\n",
    "        deep_ranking = document_score_model.predict(X)\n",
    "        deep_ranking = map(lambda x:x[0],deep_ranking.tolist())\n",
    "        bm25_results = data[\"bioasq_data\"][i][\"documents\"]\n",
    "        deep_ranking_pmid = list(zip(bm25_results,deep_ranking))\n",
    "        deep_ranking_pmid.sort(key=lambda x:-x[1])\n",
    "        query_results[data[\"bioasq_data\"][i][\"id\"]] = {\"result\":deep_ranking_pmid,\"goldstandard\":data[\"bioasq_data\"][i][\"positive_pmid\"]}\n",
    "        #print(\"save query results:\",i,end=\"\\r\")\n",
    "        \n",
    "    return query_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validate score\n",
    "\n",
    "def validation_score(deep_rank_test_query_results):\n",
    "    id_to_remove = []\n",
    "    for k,v in deep_rank_test_query_results.items():\n",
    "        if len(v[\"goldstandard\"]) == 0:\n",
    "            id_to_remove.append(k)\n",
    "\n",
    "    for k in id_to_remove:\n",
    "        del deep_rank_test_query_results[k]\n",
    "\n",
    "    deep_rank_test_query_results = list(deep_rank_test_query_results.values())\n",
    "\n",
    "    print(\"TEST set, len \",len(deep_rank_test_query_results))\n",
    "\n",
    "    expectations = list(map(lambda x:x[\"goldstandard\"],deep_rank_test_query_results))\n",
    "    predictions = list(map(lambda x:x[\"result\"],deep_rank_test_query_results))\n",
    "\n",
    "    #print(\"Recall:\",f_recall(predictions,expectations,at=1000))\n",
    "    bioasq_map = f_map(predictions,expectations,bioASQ=True)\n",
    "    print(\"MAP @10 bioASQ:\", bioasq_map)\n",
    "    print(\"MAP @25:\",f_map(predictions,expectations, bioASQ=True, at=25))\n",
    "    print(\"MAP @50:\",f_map(predictions,expectations, bioASQ=True, at=50))\n",
    "    #print(\"MAP @100:\",f_map(predictions,expectations, bioASQ=True, at=100))\n",
    "    #print(\"MAP @200:\",f_map(predictions,expectations, bioASQ=True, at=200))\n",
    "    print(\"MAP @300:\",f_map(predictions,expectations, bioASQ=True, at=300))\n",
    "\n",
    "    \n",
    "    #print(\"RECALL@10:\",f_recall(predictions,expectations, at=10))\n",
    "    #print(\"RECALL@50:\",f_recall(predictions,expectations, at=50))\n",
    "    #print(\"RECALL@100:\",f_recall(predictions,expectations, at=100))\n",
    "    return bioasq_map, predictions, expectations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Output \"query_document_score\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"query_document_score\" during training.\n",
      "WARNING:tensorflow:Output \"query_document_score\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"query_document_score\" during training.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import SGD, Adam,  Adadelta\n",
    "\n",
    "#sgd = SGD(lr=0.001)\n",
    "#adam = Adam(lr=0.001)\n",
    "adadelta = Adadelta(lr=2)\n",
    "\n",
    "deepRank_model.compile( optimizer=adadelta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 7 | loss: 0.42163152 | current max loss: 1.0128025 | current min loss: 0.413204 | time: 7.48106408119201785\n",
      "Predict query: 81\n",
      "TEST set, len  81\n",
      "MAP @10 bioASQ: 0.08793062904174014\n",
      "MAP @25: 0.11716357187951111\n",
      "MAP @50: 0.1324669905011182\n",
      "MAP @300: 0.15652130380102436\n",
      "Epoach: 0 | avg loss: 0.72418666 | max loss: 1.0128025 | min loss: 0.413204\n",
      "Epoach: 1 | avg loss: 0.3007633 | max loss: 0.3801223 | min loss: 0.2218876 0.2218876 | time: 7.418294668197632285\n",
      "Epoach: 2 | avg loss: 0.22810173 | max loss: 0.31097466 | min loss: 0.177389040.17738904 | time: 7.4302792549133335\n",
      "Epoach: 3 | avg loss: 0.20223522 | max loss: 0.22807996 | min loss: 0.182646: 0.182646 | time: 7.34643435478210457\n",
      "Epoach: 4 | avg loss: 0.22074853 | max loss: 0.28015742 | min loss: 0.18427421.18427421 | time: 7.28513860702514655\n",
      "Epoach: 5 | avg loss: 0.19933638 | max loss: 0.22317751 | min loss: 0.172938240.17293824 | time: 7.4403107166290285\n",
      "Epoach: 6 | avg loss: 0.19124734 | max loss: 0.24210061 | min loss: 0.163885060.16388506 | time: 7.5352563858032235\n",
      "Epoach: 7 | avg loss: 0.1785762 | max loss: 0.2092615 | min loss: 0.13790637 0.13790637 | time: 7.409958600997925\n",
      "Epoach: 8 | avg loss: 0.17286174 | max loss: 0.20506844 | min loss: 0.1382592 0.1382592 | time: 7.444494962692261\n",
      "Epoach: 9 | avg loss: 0.15816814 | max loss: 0.19627598 | min loss: 0.108783530.10878353 | time: 7.359687566757202\n",
      "Step: 7 | loss: 0.27901548 | current max loss: 0.27901548 | current min loss: 0.09077725 | time: 7.3581783771514894\n",
      "Predict query: 81\n",
      "TEST set, len  81\n",
      "MAP @10 bioASQ: 0.16641975308641968\n",
      "MAP @25: 0.23523284821506873\n",
      "MAP @50: 0.26669982836213735\n",
      "MAP @300: 0.3045130416151803\n",
      "\n",
      "Run for the test set\n",
      "TEST set, len  542\n",
      "MAP @10 bioASQ: 0.14144724125812683\n",
      "MAP @25: 0.20659698905967466\n",
      "MAP @50: 0.2401148168648635\n",
      "MAP @300: 0.2702166153063305\n",
      "Epoach: 10 | avg loss: 0.18208529 | max loss: 0.27901548 | min loss: 0.09077725\n",
      "Epoach: 11 | avg loss: 0.16922201 | max loss: 0.22488338 | min loss: 0.13011388.13011388 | time: 7.383108615875244\n",
      "Epoach: 12 | avg loss: 0.17158188 | max loss: 0.22660568 | min loss: 0.13192960.1319296 | time: 7.3111619949340821\n",
      "Epoach: 13 | avg loss: 0.15876241 | max loss: 0.21376495 | min loss: 0.105917744105917744 | time: 7.3402214050292973\n",
      "Epoach: 14 | avg loss: 0.14984542 | max loss: 0.18917501 | min loss: 0.092950694092950694 | time: 7.4508638381958012\n",
      "Epoach: 15 | avg loss: 0.14509764 | max loss: 0.16971871 | min loss: 0.12727050.1272705 | time: 7.5608448982238779\n",
      "Epoach: 16 | avg loss: 0.15655288 | max loss: 0.19608767 | min loss: 0.11076445.11076445 | time: 7.406575441360474\n",
      "Epoach: 17 | avg loss: 0.14784956 | max loss: 0.19140138 | min loss: 0.10885623.10885623 | time: 7.365007162094116\n",
      "Epoach: 18 | avg loss: 0.16969723 | max loss: 0.23920214 | min loss: 0.13522197.13522197 | time: 7.561670780181885\n",
      "Epoach: 19 | avg loss: 0.15417093 | max loss: 0.19754207 | min loss: 0.1254233.1254233 | time: 7.363451004028321975\n",
      "Step: 7 | loss: 0.13262242 | current max loss: 0.26634458 | current min loss: 0.119492725 | time: 7.3195600509643555\n",
      "Predict query: 81\n",
      "TEST set, len  81\n",
      "MAP @10 bioASQ: 0.18240740740740732\n",
      "MAP @25: 0.25886523587844734\n",
      "MAP @50: 0.2965834144091287\n",
      "MAP @300: 0.3363248906787104\n",
      "\n",
      "Run for the test set\n",
      "TEST set, len  542\n",
      "MAP @10 bioASQ: 0.15166710595677363\n",
      "MAP @25: 0.22460614031660248\n",
      "MAP @50: 0.2628047054840998\n",
      "MAP @300: 0.29434028163045073\n",
      "Epoach: 20 | avg loss: 0.16184951 | max loss: 0.26634458 | min loss: 0.119492725\n",
      "Epoach: 21 | avg loss: 0.14871827 | max loss: 0.17326136 | min loss: 0.13136090.1313609 | time: 7.4109566211700446\n",
      "Epoach: 22 | avg loss: 0.15821093 | max loss: 0.17958081 | min loss: 0.12542374.12542374 | time: 7.5203192234039315\n",
      "Epoach: 23 | avg loss: 0.15831694 | max loss: 0.18427949 | min loss: 0.1354121313541213 | time: 7.43720030784606974\n",
      "Epoach: 24 | avg loss: 0.14309019 | max loss: 0.19323997 | min loss: 0.114801854.114801854 | time: 7.444039344787598\n",
      "Epoach: 25 | avg loss: 0.13588247 | max loss: 0.16456632 | min loss: 0.08720431.08720431 | time: 7.42881631851196353\n",
      "Epoach: 26 | avg loss: 0.15682851 | max loss: 0.2094121 | min loss: 0.11316443.11316443 | time: 7.51820278167724675\n",
      "Epoach: 27 | avg loss: 0.12321597 | max loss: 0.166929 | min loss: 0.07227476.07227476 | time: 7.42910456657409751\n",
      "Epoach: 28 | avg loss: 0.15027516 | max loss: 0.18275848 | min loss: 0.112141795.112141795 | time: 7.3547070026397705\n",
      "Epoach: 29 | avg loss: 0.12819272 | max loss: 0.17354727 | min loss: 0.065676205065676205 | time: 7.44707632064819315\n",
      "Step: 7 | loss: 0.16915525 | current max loss: 0.19296812 | current min loss: 0.08292895 | time: 7.3944358825683595\n",
      "Predict query: 81\n",
      "TEST set, len  81\n",
      "MAP @10 bioASQ: 0.19588036449147558\n",
      "MAP @25: 0.27765424394745425\n",
      "MAP @50: 0.3130589861174422\n",
      "MAP @300: 0.3537531389994827\n",
      "\n",
      "Run for the test set\n",
      "TEST set, len  542\n",
      "MAP @10 bioASQ: 0.1606573976454049\n",
      "MAP @25: 0.2353727111504583\n",
      "MAP @50: 0.27622457122162497\n",
      "MAP @300: 0.3072960850133375\n",
      "Epoach: 30 | avg loss: 0.14657167 | max loss: 0.19296812 | min loss: 0.08292895\n",
      "Epoach: 31 | avg loss: 0.13906062 | max loss: 0.1679216 | min loss: 0.06557019.06557019 | time: 7.3983933925628667\n",
      "Epoach: 32 | avg loss: 0.13961868 | max loss: 0.16669732 | min loss: 0.09972352.09972352 | time: 7.49742674827575795\n",
      "Epoach: 33 | avg loss: 0.15096168 | max loss: 0.25826177 | min loss: 0.09273070.0927307 | time: 7.3267214298248297\n",
      "Epoach: 34 | avg loss: 0.14962843 | max loss: 0.19717002 | min loss: 0.12607512.12607512 | time: 7.6650669574737555\n",
      "Epoach: 35 | avg loss: 0.16471657 | max loss: 0.20977604 | min loss: 0.12748025.12748025 | time: 7.4574561119079595\n",
      "Epoach: 36 | avg loss: 0.13449588 | max loss: 0.16387391 | min loss: 0.11534468.11534468 | time: 7.446467638015747\n",
      "Epoach: 37 | avg loss: 0.12641527 | max loss: 0.1871911 | min loss: 0.0960959609609596 | time: 7.496244430541992655\n",
      "Epoach: 38 | avg loss: 0.13343337 | max loss: 0.17608646 | min loss: 0.094379544094379544 | time: 7.4655332565307627\n",
      "Epoach: 39 | avg loss: 0.13472804 | max loss: 0.16813587 | min loss: 0.10773859.10773859 | time: 7.277993679046631584\n",
      "Step: 7 | loss: 0.18025109 | current max loss: 0.19818994 | current min loss: 0.09452039 | time: 7.5943844318389895\n",
      "Predict query: 81\n",
      "TEST set, len  81\n",
      "MAP @10 bioASQ: 0.19088624338624333\n",
      "MAP @25: 0.27564945417218306\n",
      "MAP @50: 0.3121947368336553\n",
      "MAP @300: 0.35449394758850106\n",
      "Epoach: 40 | avg loss: 0.14995058 | max loss: 0.19818994 | min loss: 0.09452039\n",
      "Epoach: 41 | avg loss: 0.16704758 | max loss: 0.24858133 | min loss: 0.13160327.13160327 | time: 7.3934435844421395\n",
      "Epoach: 42 | avg loss: 0.13672955 | max loss: 0.21901 | min loss: 0.093695 0.093695 | time: 7.64212870597839362983\n",
      "Epoach: 43 | avg loss: 0.13280094 | max loss: 0.19217668 | min loss: 0.09256995.09256995 | time: 7.366378784179687512\n",
      "Epoach: 44 | avg loss: 0.15028164 | max loss: 0.18524778 | min loss: 0.103347525103347525 | time: 7.5074985027313231\n",
      "Epoach: 45 | avg loss: 0.14742425 | max loss: 0.16910146 | min loss: 0.12064660.1206466 | time: 7.4911179542541547\n",
      "Epoach: 46 | avg loss: 0.153241 | max loss: 0.21284711 | min loss: 0.1082914550.108291455 | time: 7.37395763397216857\n",
      "Epoach: 47 | avg loss: 0.13573654 | max loss: 0.19755945 | min loss: 0.10118657.10118657 | time: 7.3729496002197275\n",
      "Epoach: 48 | avg loss: 0.14370951 | max loss: 0.1808888 | min loss: 0.09439073.09439073 | time: 7.3411419391632084\n",
      "Epoach: 49 | avg loss: 0.13517392 | max loss: 0.17095302 | min loss: 0.111680835.111680835 | time: 7.438385009765625\n",
      "Step: 7 | loss: 0.17453626 | current max loss: 0.17611994 | current min loss: 0.0971767 | time: 7.3186571598052984\n",
      "Predict query: 81\n",
      "TEST set, len  81\n",
      "MAP @10 bioASQ: 0.19485449735449734\n",
      "MAP @25: 0.2786964335734747\n",
      "MAP @50: 0.315734500232169\n",
      "MAP @300: 0.3580784058117247\n",
      "Epoach: 50 | avg loss: 0.13930246 | max loss: 0.17611994 | min loss: 0.0971767\n",
      "Epoach: 51 | avg loss: 0.13134061 | max loss: 0.15775658 | min loss: 0.099908784099908784 | time: 7.45615148544311596\n",
      "Epoach: 52 | avg loss: 0.12862512 | max loss: 0.16456635 | min loss: 0.106603056106603056 | time: 7.4464812278747565\n",
      "Epoach: 53 | avg loss: 0.124335505 | max loss: 0.16442597 | min loss: 0.0810992608109926 | time: 7.5749611854553229\n",
      "Epoach: 54 | avg loss: 0.14767168 | max loss: 0.24464354 | min loss: 0.08301489.08301489 | time: 7.3349871635437011\n",
      "Epoach: 55 | avg loss: 0.1308203 | max loss: 0.17338878 | min loss: 0.090179380.09017938 | time: 7.4347589015960692\n",
      "Epoach: 56 | avg loss: 0.13313837 | max loss: 0.18287285 | min loss: 0.10336243.10336243 | time: 7.535491228103638\n",
      "Epoach: 57 | avg loss: 0.14385897 | max loss: 0.17893848 | min loss: 0.109338745109338745 | time: 7.49748802185058674\n",
      "Epoach: 58 | avg loss: 0.12743327 | max loss: 0.16083805 | min loss: 0.099711515099711515 | time: 7.39374017715454155\n",
      "Epoach: 59 | avg loss: 0.121436656 | max loss: 0.1488349 | min loss: 0.08731010687310106 | time: 7.48126435279846291\n",
      "Step: 7 | loss: 0.13928148 | current max loss: 0.21885386 | current min loss: 0.07502814 | time: 7.4283161163330085\n",
      "Predict query: 81\n",
      "TEST set, len  81\n",
      "MAP @10 bioASQ: 0.19938810503625318\n",
      "MAP @25: 0.2840219794857802\n",
      "MAP @50: 0.3196771221666411\n",
      "MAP @300: 0.3636189294005814\n",
      "\n",
      "Run for the test set\n",
      "TEST set, len  542\n",
      "MAP @10 bioASQ: 0.1670977566918525\n",
      "MAP @25: 0.24483207554329287\n",
      "MAP @50: 0.28408790125724537\n",
      "MAP @300: 0.3175593960259546\n",
      "Epoach: 60 | avg loss: 0.1364238 | max loss: 0.21885386 | min loss: 0.07502814\n",
      "Epoach: 61 | avg loss: 0.12868011 | max loss: 0.19587371 | min loss: 0.08524235.08524235 | time: 7.269277334213257\n",
      "Epoach: 62 | avg loss: 0.12649947 | max loss: 0.15670478 | min loss: 0.08762004.08762004 | time: 7.295098781585693\n",
      "Epoach: 63 | avg loss: 0.14023529 | max loss: 0.17046943 | min loss: 0.104450926.104450926 | time: 7.535228252410889\n",
      "Epoach: 64 | avg loss: 0.14037396 | max loss: 0.18843924 | min loss: 0.08556377.08556377 | time: 7.4645380973815924\n",
      "Epoach: 65 | avg loss: 0.13878259 | max loss: 0.17511036 | min loss: 0.06799239.06799239 | time: 7.5576560497283936\n",
      "Epoach: 66 | avg loss: 0.13198976 | max loss: 0.21155411 | min loss: 0.09009361.09009361 | time: 7.45070028305053763\n",
      "Epoach: 67 | avg loss: 0.12786543 | max loss: 0.16200887 | min loss: 0.08973763.08973763 | time: 7.513428211212158545\n",
      "Epoach: 68 | avg loss: 0.1211364 | max loss: 0.15664905 | min loss: 0.083817214.083817214 | time: 7.3429672718048151\n",
      "Epoach: 69 | avg loss: 0.14541271 | max loss: 0.1743607 | min loss: 0.10082844.10082844 | time: 7.4507658481597915\n",
      "Step: 7 | loss: 0.14793141 | current max loss: 0.17304252 | current min loss: 0.087865755 | time: 7.3971307277679442\n",
      "Predict query: 81\n",
      "TEST set, len  81\n",
      "MAP @10 bioASQ: 0.1914829512051734\n",
      "MAP @25: 0.27932461798479136\n",
      "MAP @50: 0.3160693903576082\n",
      "MAP @300: 0.36043505023395095\n",
      "Epoach: 70 | avg loss: 0.13292229 | max loss: 0.17304252 | min loss: 0.087865755\n",
      "Epoach: 71 | avg loss: 0.12011818 | max loss: 0.15138768 | min loss: 0.07985310.0798531 | time: 7.3591678142547617\n",
      "Epoach: 72 | avg loss: 0.117032915 | max loss: 0.16210292 | min loss: 0.0676752706767527 | time: 7.4197552204132085\n",
      "Epoach: 73 | avg loss: 0.11782357 | max loss: 0.1846241 | min loss: 0.075583525.075583525 | time: 7.42206048965454195\n",
      "Epoach: 74 | avg loss: 0.13312805 | max loss: 0.21919048 | min loss: 0.10610750.1061075 | time: 7.4633564949035645158\n",
      "Epoach: 75 | avg loss: 0.12370795 | max loss: 0.16434352 | min loss: 0.081916675081916675 | time: 7.42926335334777867\n",
      "Epoach: 76 | avg loss: 0.12145658 | max loss: 0.16367362 | min loss: 0.09269317.09269317 | time: 7.336113691329956625\n",
      "Epoach: 77 | avg loss: 0.1184739 | max loss: 0.15618102 | min loss: 0.0637087 0.0637087 | time: 7.56661868095397955\n",
      "Epoach: 78 | avg loss: 0.14601423 | max loss: 0.21503699 | min loss: 0.09939931.09939931 | time: 7.2942223548889165\n",
      "Epoach: 79 | avg loss: 0.1329649 | max loss: 0.16286123 | min loss: 0.102979660.10297966 | time: 7.346451282501221\n",
      "Step: 7 | loss: 0.17808537 | current max loss: 0.18744782 | current min loss: 0.07272847 | time: 7.4908964633941651\n",
      "Predict query: 81\n",
      "TEST set, len  81\n",
      "MAP @10 bioASQ: 0.1992210464432686\n",
      "MAP @25: 0.2870827340655194\n",
      "MAP @50: 0.32349850972680927\n",
      "MAP @300: 0.36867999201859014\n",
      "Epoach: 80 | avg loss: 0.13496608 | max loss: 0.18744782 | min loss: 0.07272847\n",
      "Epoach: 81 | avg loss: 0.13864037 | max loss: 0.15992633 | min loss: 0.11769605.11769605 | time: 7.50633907318115223\n",
      "Epoach: 82 | avg loss: 0.10898409 | max loss: 0.17097946 | min loss: 0.05858547.05858547 | time: 7.4814574718475342\n",
      "Epoach: 83 | avg loss: 0.12247092 | max loss: 0.18444778 | min loss: 0.09370288.09370288 | time: 7.464424371719368\n",
      "Epoach: 84 | avg loss: 0.12906668 | max loss: 0.17775048 | min loss: 0.09308662.09308662 | time: 7.3958961963653564\n",
      "Epoach: 85 | avg loss: 0.123249725 | max loss: 0.14077553 | min loss: 0.0952359.0952359 | time: 7.5875954627990726\n",
      "Epoach: 86 | avg loss: 0.1272538 | max loss: 0.15268514 | min loss: 0.094845860.09484586 | time: 7.4888334274291993\n",
      "Epoach: 87 | avg loss: 0.12541781 | max loss: 0.20199825 | min loss: 0.082859956082859956 | time: 7.4346206188201989\n",
      "Epoach: 88 | avg loss: 0.121277824 | max loss: 0.1472865 | min loss: 0.0957547609575476 | time: 7.5210957527160645078\n",
      "Epoach: 89 | avg loss: 0.13702896 | max loss: 0.16453774 | min loss: 0.11084237.11084237 | time: 7.529172182083135\n",
      "Step: 7 | loss: 0.102583826 | current max loss: 0.19159612 | current min loss: 0.10174407 | time: 7.428887605667114\n",
      "Predict query: 81\n",
      "TEST set, len  81\n",
      "MAP @10 bioASQ: 0.19785959239662934\n",
      "MAP @25: 0.28361312484443824\n",
      "MAP @50: 0.32219888677748154\n",
      "MAP @300: 0.3668979890165713\n",
      "Epoach: 90 | avg loss: 0.12869492 | max loss: 0.19159612 | min loss: 0.10174407\n",
      "Epoach: 91 | avg loss: 0.12879178 | max loss: 0.15288332 | min loss: 0.10679846.10679846 | time: 7.41136527061462438\n",
      "Epoach: 92 | avg loss: 0.13637853 | max loss: 0.16966227 | min loss: 0.09992558.09992558 | time: 7.456502914428711\n",
      "Epoach: 93 | avg loss: 0.121318266 | max loss: 0.18331191 | min loss: 0.089615546089615546 | time: 7.614032506942749\n",
      "Epoach: 94 | avg loss: 0.15208808 | max loss: 0.1839125 | min loss: 0.12832507.12832507 | time: 7.3864052295684814\n",
      "Epoach: 95 | avg loss: 0.1276151 | max loss: 0.13994119 | min loss: 0.109979390.10997939 | time: 7.337748765945435\n",
      "Epoach: 96 | avg loss: 0.13762885 | max loss: 0.16396329 | min loss: 0.095467344095467344 | time: 7.35573554039001506\n",
      "Epoach: 97 | avg loss: 0.12592906 | max loss: 0.15954912 | min loss: 0.08360587.08360587 | time: 7.627601146697998\n",
      "Epoach: 98 | avg loss: 0.13945681 | max loss: 0.17983204 | min loss: 0.09593960.0959396 | time: 7.3411154747009288763\n",
      "Epoach: 99 | avg loss: 0.12427157 | max loss: 0.15455678 | min loss: 0.095783845.095783845 | time: 7.466186285018921\n",
      "Step: 7 | loss: 0.12732472 | current max loss: 0.15204105 | current min loss: 0.08904675 | time: 7.513699293136597205\n",
      "Predict query: 81\n",
      "TEST set, len  81\n",
      "MAP @10 bioASQ: 0.19644473838918278\n",
      "MAP @25: 0.2828218009924998\n",
      "MAP @50: 0.3259653908110942\n",
      "MAP @300: 0.36837686833757766\n",
      "Epoach: 100 | avg loss: 0.12169506 | max loss: 0.15204105 | min loss: 0.08904675\n",
      "Epoach: 101 | avg loss: 0.12880817 | max loss: 0.17681003 | min loss: 0.1011667410116674 | time: 7.42886519432067914\n",
      "Epoach: 102 | avg loss: 0.12559983 | max loss: 0.15403748 | min loss: 0.1032843810328438 | time: 7.43558740615844777\n",
      "Epoach: 103 | avg loss: 0.12637883 | max loss: 0.16484424 | min loss: 0.070559577055957 | time: 7.44412088394165795\n",
      "Epoach: 104 | avg loss: 0.12614772 | max loss: 0.18130171 | min loss: 0.06781510678151 | time: 7.4560525417327886545\n",
      "Epoach: 105 | avg loss: 0.13488746 | max loss: 0.17311308 | min loss: 0.0855233.0855233 | time: 7.512195587158203312\n",
      "Epoach: 106 | avg loss: 0.11266335 | max loss: 0.1585195 | min loss: 0.094496869449686 | time: 7.431437015533447518\n",
      "Epoach: 107 | avg loss: 0.12511349 | max loss: 0.16066755 | min loss: 0.0918146309181463 | time: 7.4166688919067384\n",
      "Epoach: 108 | avg loss: 0.123265445 | max loss: 0.16989768 | min loss: 0.06507281507281 | time: 7.54701685905456546\n",
      "Epoach: 109 | avg loss: 0.12008318 | max loss: 0.14713058 | min loss: 0.0774615407746154 | time: 7.3456311225891118\n",
      "Step: 7 | loss: 0.072251 | current max loss: 0.19220212 | current min loss: 0.072251 | time: 7.36660957336425885645\n",
      "Predict query: 81\n",
      "TEST set, len  81\n",
      "MAP @10 bioASQ: 0.1998148148148148\n",
      "MAP @25: 0.2843999102308008\n",
      "MAP @50: 0.327155587104903\n",
      "MAP @300: 0.3709409535752261\n",
      "\n",
      "Run for the test set\n",
      "TEST set, len  542\n",
      "MAP @10 bioASQ: 0.16988827388273864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP @25: 0.25088367229487196\n",
      "MAP @50: 0.2915052389366691\n",
      "MAP @300: 0.32481967236327547\n",
      "Epoach: 110 | avg loss: 0.12722869 | max loss: 0.19220212 | min loss: 0.072251\n",
      "Epoach: 111 | avg loss: 0.12760477 | max loss: 0.15367658 | min loss: 0.1029535610295356 | time: 7.535779237747192\n",
      "Epoach: 112 | avg loss: 0.13829646 | max loss: 0.19334508 | min loss: 0.083338928333892 | time: 7.4607183933258066\n",
      "Epoach: 113 | avg loss: 0.12602215 | max loss: 0.1779054 | min loss: 0.07722378577223785 | time: 7.420239448547363275\n",
      "Epoach: 114 | avg loss: 0.1304926 | max loss: 0.15311226 | min loss: 0.10587298.10587298 | time: 7.41446018218994155\n",
      "Epoach: 115 | avg loss: 0.111415654 | max loss: 0.12632619 | min loss: 0.099987849998784 | time: 7.504202127456665515\n",
      "Epoach: 116 | avg loss: 0.11676231 | max loss: 0.14691378 | min loss: 0.0913462909134629 | time: 7.5332887172698975\n",
      "Epoach: 117 | avg loss: 0.13159515 | max loss: 0.19457254 | min loss: 0.088664418866441 | time: 7.46853542327880914\n",
      "Epoach: 118 | avg loss: 0.12655573 | max loss: 0.1511983 | min loss: 0.1139199663919966 | time: 7.324047803878784571\n",
      "Epoach: 119 | avg loss: 0.117474 | max loss: 0.15481932 | min loss: 0.076956790.07695679 | time: 7.4572389125823975\n",
      "Step: 7 | loss: 0.15578118 | current max loss: 0.1757091 | current min loss: 0.09539649 | time: 7.57788419723510715\n",
      "Predict query: 81\n",
      "TEST set, len  81\n",
      "MAP @10 bioASQ: 0.19743239271017043\n",
      "MAP @25: 0.2807730298794088\n",
      "MAP @50: 0.32337466531217685\n",
      "MAP @300: 0.36704544415346385\n",
      "Epoach: 120 | avg loss: 0.13360454 | max loss: 0.1757091 | min loss: 0.09539649\n",
      "Epoach: 121 | avg loss: 0.12319031 | max loss: 0.22688058 | min loss: 0.0667430706674307 | time: 7.3579349517822276\n",
      "Epoach: 122 | avg loss: 0.10898599 | max loss: 0.16248263 | min loss: 0.04860599348605993 | time: 7.3911709785461439\n",
      "Epoach: 123 | avg loss: 0.12029533 | max loss: 0.17532478 | min loss: 0.0756365407563654 | time: 7.477759361267092\n",
      "Epoach: 124 | avg loss: 0.116336495 | max loss: 0.13454832 | min loss: 0.09188431591884315 | time: 7.507017374038696\n",
      "Step: 5 | loss: 0.08226722 | current max loss: 0.14988461 | current min loss: 0.08226722 | time: 7.50306820869445824\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoach: 137 | avg loss: 0.11781638 | max loss: 0.18325949 | min loss: 0.0741306607413066 | time: 7.9190533161163339\n",
      "Epoach: 138 | avg loss: 0.10979208 | max loss: 0.1368751 | min loss: 0.087055478705547 | time: 7.47947096824646835\n",
      "Epoach: 139 | avg loss: 0.123299286 | max loss: 0.16598232 | min loss: 0.074036187403618 | time: 7.625479459762573\n",
      "Step: 7 | loss: 0.117197834 | current max loss: 0.16009413 | current min loss: 0.07554485 | time: 7.55523538589477559\n",
      "Predict query: 81\n",
      "TEST set, len  81\n",
      "MAP @10 bioASQ: 0.20241622574955903\n",
      "MAP @25: 0.2878344504012011\n",
      "MAP @50: 0.33081567172967496\n",
      "MAP @300: 0.372562782095853\n",
      "\n",
      "Run for the test set\n",
      "TEST set, len  542\n",
      "MAP @10 bioASQ: 0.17293255432554308\n",
      "MAP @25: 0.2517318248342732\n",
      "MAP @50: 0.2918353484815372\n",
      "MAP @300: 0.32549681272835895\n",
      "Epoach: 140 | avg loss: 0.1230351 | max loss: 0.16009413 | min loss: 0.07554485\n",
      "Epoach: 141 | avg loss: 0.10535562 | max loss: 0.1272618 | min loss: 0.0673611.0673611 | time: 7.6040494441986088\n",
      "Epoach: 142 | avg loss: 0.11372854 | max loss: 0.18816155 | min loss: 0.07298834672988346 | time: 7.40345835685736565\n",
      "Epoach: 143 | avg loss: 0.1275131 | max loss: 0.15383983 | min loss: 0.098161 0.098161 | time: 7.3510198593139655414\n",
      "Epoach: 144 | avg loss: 0.12284945 | max loss: 0.1586827 | min loss: 0.0891503808915038 | time: 7.48424482345581055585\n",
      "Epoach: 145 | avg loss: 0.1287975 | max loss: 0.16232844 | min loss: 0.08920541.08920541 | time: 7.493237733840942\n",
      "Epoach: 146 | avg loss: 0.14251792 | max loss: 0.17527127 | min loss: 0.10498939504989395 | time: 7.5797631740570077\n",
      "Epoach: 147 | avg loss: 0.1197502 | max loss: 0.16390927 | min loss: 0.085808374.085808374 | time: 7.526686429977417\n",
      "Epoach: 148 | avg loss: 0.12923324 | max loss: 0.1872765 | min loss: 0.0926913109269131 | time: 7.5354728698730475\n",
      "Epoach: 149 | avg loss: 0.11526482 | max loss: 0.15257391 | min loss: 0.091288719128871 | time: 7.479449033737183526\n",
      "Step: 7 | loss: 0.12050393 | current max loss: 0.18745756 | current min loss: 0.085605845 | time: 7.5668859481811525\n",
      "Predict query: 81\n",
      "TEST set, len  81\n",
      "MAP @10 bioASQ: 0.1943239271017048\n",
      "MAP @25: 0.27651716938159104\n",
      "MAP @50: 0.31709068148389874\n",
      "MAP @300: 0.3616947325657043\n",
      "Epoach: 150 | avg loss: 0.11755484 | max loss: 0.18745756 | min loss: 0.085605845\n",
      "Epoach: 151 | avg loss: 0.11774506 | max loss: 0.14769907 | min loss: 0.0916808.0916808 | time: 7.443736314773565852\n",
      "Epoach: 152 | avg loss: 0.12912512 | max loss: 0.15649894 | min loss: 0.09171992591719925 | time: 7.53927588462829635\n",
      "Epoach: 153 | avg loss: 0.11579323 | max loss: 0.12904224 | min loss: 0.0912840709128407 | time: 7.5837216377258349\n",
      "Epoach: 154 | avg loss: 0.13317811 | max loss: 0.17968303 | min loss: 0.09662665496626654 | time: 7.31967043876647957\n",
      "Epoach: 155 | avg loss: 0.13125426 | max loss: 0.1678868 | min loss: 0.082386618238661 | time: 7.62951517105102518\n",
      "Epoach: 156 | avg loss: 0.13116136 | max loss: 0.1887357 | min loss: 0.07908095479080954 | time: 7.4074649810791022575\n",
      "Epoach: 157 | avg loss: 0.13674983 | max loss: 0.17097013 | min loss: 0.0991257709912577 | time: 7.40515780448913637\n",
      "Epoach: 158 | avg loss: 0.10503118 | max loss: 0.1388751 | min loss: 0.0846604308466043 | time: 7.5128347873687749524\n",
      "Epoach: 159 | avg loss: 0.12243475 | max loss: 0.14761731 | min loss: 0.08956066589560665 | time: 7.3768837451934814\n",
      "Step: 7 | loss: 0.093602575 | current max loss: 0.16706586 | current min loss: 0.093602575 | time: 7.412141561508179\n",
      "Predict query: 81\n",
      "TEST set, len  81\n",
      "MAP @10 bioASQ: 0.20196257103664506\n",
      "MAP @25: 0.28592436367179763\n",
      "MAP @50: 0.3285172193219649\n",
      "MAP @300: 0.3715789298303661\n",
      "Epoach: 160 | avg loss: 0.12963611 | max loss: 0.16706586 | min loss: 0.093602575\n",
      "Epoach: 161 | avg loss: 0.12866354 | max loss: 0.17561555 | min loss: 0.0828342508283425 | time: 7.4435508251190186\n",
      "Epoach: 162 | avg loss: 0.11540863 | max loss: 0.14533131 | min loss: 0.0853625908536259 | time: 7.5243782997131354\n",
      "Epoach: 163 | avg loss: 0.117662415 | max loss: 0.15808399 | min loss: 0.083595888359588 | time: 7.44308042526245128\n",
      "Epoach: 164 | avg loss: 0.102449 | max loss: 0.12033532 | min loss: 0.0762333350.076233335 | time: 7.503839731216431\n",
      "Epoach: 165 | avg loss: 0.13998705 | max loss: 0.17991407 | min loss: 0.105054796105054796 | time: 7.53576135635376\n",
      "Epoach: 166 | avg loss: 0.110047914 | max loss: 0.16462338 | min loss: 0.05900656859006568 | time: 7.533447504043579\n",
      "Epoach: 167 | avg loss: 0.14037295 | max loss: 0.21190526 | min loss: 0.096683726096683726 | time: 7.626581192016602\n",
      "Epoach: 168 | avg loss: 0.11466941 | max loss: 0.15629224 | min loss: 0.07374317.07374317 | time: 7.642977714538574\n",
      "Epoach: 169 | avg loss: 0.11392544 | max loss: 0.13797966 | min loss: 0.0833985708339857 | time: 7.39386224746704115\n",
      "Step: 7 | loss: 0.1513925 | current max loss: 0.15296328 | current min loss: 0.07246914 | time: 7.54608750343322755\n",
      "Predict query: 81\n",
      "TEST set, len  81\n",
      "MAP @10 bioASQ: 0.20198559670781888\n",
      "MAP @25: 0.2862893083643735\n",
      "MAP @50: 0.33002704137591177\n",
      "MAP @300: 0.37192159842858163\n",
      "Epoach: 170 | avg loss: 0.12225628 | max loss: 0.15296328 | min loss: 0.07246914\n",
      "Epoach: 171 | avg loss: 0.11566908 | max loss: 0.14007804 | min loss: 0.0732795753279575 | time: 7.368466377258301245\n",
      "Epoach: 172 | avg loss: 0.12261438 | max loss: 0.14941043 | min loss: 0.100764945100764945 | time: 7.623997211456299\n",
      "Epoach: 173 | avg loss: 0.1286308 | max loss: 0.15028337 | min loss: 0.10798607.10798607 | time: 7.5519614219665535\n",
      "Epoach: 174 | avg loss: 0.11668802 | max loss: 0.19404496 | min loss: 0.059728403728403 | time: 7.483679294586182417\n",
      "Epoach: 175 | avg loss: 0.12620711 | max loss: 0.17600888 | min loss: 0.1019283110192831 | time: 7.4738373756408696\n",
      "Epoach: 176 | avg loss: 0.10792884 | max loss: 0.13871306 | min loss: 0.0691665106916651 | time: 7.5376160144805915\n",
      "Epoach: 177 | avg loss: 0.12970181 | max loss: 0.17305455 | min loss: 0.087792866087792866 | time: 7.565942049026489\n",
      "Epoach: 178 | avg loss: 0.13328484 | max loss: 0.16642135 | min loss: 0.10352282.10352282 | time: 7.541555881500244\n",
      "Epoach: 179 | avg loss: 0.12061951 | max loss: 0.18675429 | min loss: 0.093015864093015864 | time: 7.659370422363281\n",
      "Step: 7 | loss: 0.13952179 | current max loss: 0.15902075 | current min loss: 0.078989364 | time: 7.419928312301636715\n",
      "Epoach: 194 | avg loss: 0.14448698 | max loss: 0.19605383 | min loss: 0.1050773110507731 | time: 7.4174258708953865\n",
      "Epoach: 195 | avg loss: 0.11727168 | max loss: 0.1634365 | min loss: 0.0881178608811786 | time: 7.44544577598571859\n",
      "Epoach: 196 | avg loss: 0.116354495 | max loss: 0.14702885 | min loss: 0.079686087968608 | time: 7.53380703926086413\n",
      "Epoach: 197 | avg loss: 0.10954835 | max loss: 0.14845477 | min loss: 0.0679396906793969 | time: 7.4675042629241943\n",
      "Epoach: 198 | avg loss: 0.12087681 | max loss: 0.14988439 | min loss: 0.1016409710164097 | time: 7.48007249832153354\n",
      "Epoach: 199 | avg loss: 0.12178916 | max loss: 0.15508944 | min loss: 0.09218369492183694 | time: 7.382206201553345\n",
      "Step: 7 | loss: 0.14720494 | current max loss: 0.14720494 | current min loss: 0.09976307 | time: 7.458885192871094\n",
      "Predict query: 81\n",
      "TEST set, len  81\n",
      "MAP @10 bioASQ: 0.19574025083284338\n",
      "MAP @25: 0.27775627161515065\n",
      "MAP @50: 0.32305642464455364\n",
      "MAP @300: 0.3669687720117917\n",
      "Epoach: 200 | avg loss: 0.12155159 | max loss: 0.14720494 | min loss: 0.09976307\n",
      "Epoach: 201 | avg loss: 0.10907698 | max loss: 0.15043356 | min loss: 0.07344040.0734404 | time: 7.521231412887573\n",
      "Epoach: 202 | avg loss: 0.119467564 | max loss: 0.17324662 | min loss: 0.0831220753122075 | time: 7.55423736572265678\n",
      "Epoach: 203 | avg loss: 0.12522045 | max loss: 0.20180827 | min loss: 0.0943251209432512 | time: 7.42502355575561556\n",
      "Epoach: 204 | avg loss: 0.10981925 | max loss: 0.17104132 | min loss: 0.0859494208594942 | time: 7.34872841835022188\n",
      "Epoach: 205 | avg loss: 0.11751141 | max loss: 0.13386737 | min loss: 0.0999615409996154 | time: 7.4187748432159426\n",
      "Epoach: 206 | avg loss: 0.09761827 | max loss: 0.13797173 | min loss: 0.06799779.06799779 | time: 7.451998233795166525\n",
      "Epoach: 207 | avg loss: 0.11454442 | max loss: 0.13715696 | min loss: 0.0967836809678368 | time: 7.5090062618255615\n",
      "Epoach: 208 | avg loss: 0.10963628 | max loss: 0.1548566 | min loss: 0.080892418089241 | time: 7.564640283584595258\n",
      "Epoach: 209 | avg loss: 0.11672847 | max loss: 0.15411574 | min loss: 0.0935276709352767 | time: 7.49756240844726692\n",
      "Step: 7 | loss: 0.098224446 | current max loss: 0.15664804 | current min loss: 0.095303394 | time: 7.474416732788086\n",
      "Predict query: 81\n",
      "TEST set, len  81\n",
      "MAP @10 bioASQ: 0.197661669606114\n",
      "MAP @25: 0.28122016103430914\n",
      "MAP @50: 0.32305023675309813\n",
      "MAP @300: 0.36569629269245535\n",
      "Epoach: 210 | avg loss: 0.12065748 | max loss: 0.15664804 | min loss: 0.095303394\n",
      "Epoach: 211 | avg loss: 0.10858774 | max loss: 0.13856278 | min loss: 0.0773959107739591 | time: 7.4802107810974125\n",
      "Epoach: 212 | avg loss: 0.10849108 | max loss: 0.15837704 | min loss: 0.0727869707278697 | time: 7.6955702304840095\n",
      "Epoach: 213 | avg loss: 0.11282761 | max loss: 0.21597837 | min loss: 0.04741852747418527 | time: 7.5270957946777342\n",
      "Epoach: 214 | avg loss: 0.12300282 | max loss: 0.19426613 | min loss: 0.055778085577808 | time: 7.60431814193725655\n",
      "Epoach: 215 | avg loss: 0.12761562 | max loss: 0.1607284 | min loss: 0.0963462446346244 | time: 7.401404619216919418\n",
      "Epoach: 216 | avg loss: 0.10930914 | max loss: 0.14522558 | min loss: 0.0886780.088678 | time: 7.52250909805297855448\n",
      "Epoach: 217 | avg loss: 0.13406813 | max loss: 0.16427882 | min loss: 0.1082519510825195 | time: 7.427830457687378\n",
      "Epoach: 218 | avg loss: 0.12847286 | max loss: 0.16983302 | min loss: 0.081439994081439994 | time: 7.609342575073242\n",
      "Epoach: 219 | avg loss: 0.124276474 | max loss: 0.1738269 | min loss: 0.076487477648747 | time: 7.4493124485015875\n",
      "Step: 7 | loss: 0.08062122 | current max loss: 0.11736646 | current min loss: 0.08062122 | time: 7.653313398361206237\n",
      "Predict query: 81\n",
      "TEST set, len  81\n",
      "MAP @10 bioASQ: 0.20710513423476382\n",
      "MAP @25: 0.2926827001713971\n",
      "MAP @50: 0.3326059635991245\n",
      "MAP @300: 0.3765722889710334\n",
      "\n",
      "Run for the test set\n",
      "TEST set, len  542\n",
      "MAP @10 bioASQ: 0.16920320096058084\n",
      "MAP @25: 0.24783819547892919\n",
      "MAP @50: 0.2882681558323366\n",
      "MAP @300: 0.32226453092783464\n",
      "Epoach: 220 | avg loss: 0.1009334 | max loss: 0.11736646 | min loss: 0.08062122\n",
      "Epoach: 221 | avg loss: 0.10047014 | max loss: 0.1522745 | min loss: 0.05542845355428453 | time: 7.4968562126159671536\n",
      "Epoach: 222 | avg loss: 0.11497022 | max loss: 0.13659206 | min loss: 0.0968717309687173 | time: 7.6062879562377937\n",
      "Epoach: 223 | avg loss: 0.10706116 | max loss: 0.16539715 | min loss: 0.0540616805406168 | time: 7.5579679012298583\n",
      "Epoach: 224 | avg loss: 0.13027586 | max loss: 0.17561826 | min loss: 0.0695645506956455 | time: 7.5467290878295915\n",
      "Epoach: 225 | avg loss: 0.11267774 | max loss: 0.14536878 | min loss: 0.087976374087976374 | time: 7.4287633895874022\n",
      "Epoach: 226 | avg loss: 0.12421947 | max loss: 0.1649636 | min loss: 0.08794650.0879465 | time: 7.49549818038940458\n",
      "Epoach: 227 | avg loss: 0.12187988 | max loss: 0.14453462 | min loss: 0.103735980373598 | time: 7.5770642757415776\n",
      "Epoach: 228 | avg loss: 0.10939846 | max loss: 0.13267899 | min loss: 0.0729039107290391 | time: 7.387256383895874\n",
      "Epoach: 229 | avg loss: 0.120501325 | max loss: 0.12995028 | min loss: 0.101265930126593 | time: 7.58319854736328165\n"
     ]
    }
   ],
   "source": [
    "from models.generic_model import ModelAPI, f_recall, f_map\n",
    "\n",
    "gen = TrainDataGenerator(train_articles_collection, tk, 256)\n",
    "\n",
    "gen_iter = iter(gen)\n",
    "\n",
    "loss = []\n",
    "\n",
    "for i,line in enumerate(loss):\n",
    "    \n",
    "    print(\"Epoach:\",i,\"| avg loss:\",np.mean(loss[i]),\"| max loss:\",np.max(loss[i]),\"| min loss:\",np.min(loss[i]))\n",
    "\n",
    "import time\n",
    "\n",
    "max_bio_map_val = 0.150\n",
    "max_bio_map_test = 0\n",
    "\n",
    "for epoach in range(0,230):\n",
    "    loss_per_epoach = []\n",
    "    for step in range(len(gen)):\n",
    "        X = next(gen_iter)\n",
    "        \n",
    "        start = time.time()\n",
    "        loss_per_epoach.append(deepRank_model.train_on_batch(X))\n",
    "        print(\"Step:\",step,\"| loss:\",loss_per_epoach[-1],\"| current max loss:\",np.max(loss_per_epoach),\"| current min loss:\",np.min(loss_per_epoach),\"| time:\",time.time()-start,end=\"\\r\")\n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "    if epoach%10==0:\n",
    "        print(\"\")\n",
    "        validate_query_results = validate_test_data(validation_articles_collection)\n",
    "        print(\"\")\n",
    "        bio_map_val,_,_ = validation_score(validate_query_results)\n",
    "        if bio_map_val >= max_bio_map_val:\n",
    "            max_bio_map_val = bio_map_val\n",
    "            print(\"\")\n",
    "            print(\"Run for the test set\")\n",
    "            test_query_results = validate_test_data(test_articles_collection)\n",
    "            bio_map_test,_,_ = validation_score(test_query_results)\n",
    "\n",
    "            if bio_map_test >= max_bio_map_test:\n",
    "                max_bio_map_test = bio_map_test\n",
    "                \n",
    "                #deepRank_model.save_weights(\"deep_rank_weights.h5\")\n",
    "                document_score_model.save_weights(\"deep_rank_model_v2.h5\")\n",
    "                \n",
    "    loss.append(loss_per_epoach)\n",
    "    print(\"\",end=\"\\r\")#clear the line\n",
    "    print(\"Epoach:\",epoach,\"| avg loss:\",np.mean(loss[-1]),\"| max loss:\",np.max(loss[-1]),\"| min loss:\",np.min(loss[-1]))\n",
    "#deepRank_model.fit_generator(gen_iter, steps_per_epoch=len(gen), verbose=1, epochs=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_query_results = validate_test_data(test_articles_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_save = \"/backup/results/deep_rank\"\n",
    "path_save = os.path.join(path_save, \"deep_rank_v2_17_1_test_data.p\")\n",
    "\n",
    "with open(path_save, \"wb\") as f:\n",
    "    pickle.dump(test_query_results,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PREPARE SUBMISSION\n",
    "\n",
    "\n",
    "test_bioASQ_results_results = list(map(lambda k:{\"id\":k[0],\"documents\":list(map(lambda x:\"http://www.ncbi.nlm.nih.gov/pubmed/\"+str(x[0]), k[1][\"result\"]))[:10]}, test_bioASQ_results.items()))\n",
    "_temp = []\n",
    "\n",
    "for query in bioASQ_data:\n",
    "    _jump = False\n",
    "    for r_query in test_bioASQ_results_results:\n",
    "        if query[\"id\"] == r_query[\"id\"]:\n",
    "            _jump = True\n",
    "    \n",
    "    #no match so add\n",
    "    if not _jump:\n",
    "        _temp.append({\"id\":query[\"id\"],\"documents\":[]})\n",
    "\n",
    "test_bioASQ_results_results.extend(_temp)\n",
    "\n",
    "print(len(test_bioASQ_results_results))\n",
    "assert len(test_bioASQ_results_results) == 100\n",
    "a = {\"questions\": test_bioASQ_results_results}\n",
    "with open(\"5b_phaseA_01.json\",\"w\") as f:\n",
    "    json.dump(a,f)\n",
    "    \n",
    "\n",
    "test_bioASQ_results_results[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_to_test_index = 0\n",
    "\n",
    "data_generator = TestDataGenerator(test_articles_collection, tk)\n",
    "data_generator = iter(data_generator)\n",
    "for _ in range(query_to_test_index+1):\n",
    "    X = next(data_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_ranking = document_score_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_ranking = map(lambda x:x[0],re_ranking.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_results = test_articles_collection[\"bioasq_data\"][query_to_test_index][\"documents\"]\n",
    "positive_docs = test_articles_collection[\"bioasq_data\"][query_to_test_index][\"positive_pmid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_ranking_pmid = list(zip(bm25_results,re_ranking))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_ranking_pmid.sort(key=lambda x:-x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('24794627', 5.3322014808654785),\n",
       " ('30251567', 5.313037872314453),\n",
       " ('28796422', 5.227417945861816),\n",
       " ('30114722', 5.093368053436279),\n",
       " ('29947303', 5.0901007652282715),\n",
       " ('30697454', 5.0804266929626465),\n",
       " ('30569414', 4.911670207977295),\n",
       " ('28901190', 4.814671039581299),\n",
       " ('24577791', 4.803395748138428),\n",
       " ('26907255', 4.67585563659668)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_ranking_pmid[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13502,    43,   478,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0], dtype=int32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_articles_collection[\"bioasq_data\"][query_to_test_index][\"query\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['24554704',\n",
       " '24784583',\n",
       " '24577791',\n",
       " '23197849',\n",
       " '24035588',\n",
       " '21060967',\n",
       " '25479728',\n",
       " '21755313',\n",
       " '24469711',\n",
       " '22512788',\n",
       " '24911883',\n",
       " '24794627',\n",
       " '21464439',\n",
       " '25059784']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '24794627', 5.3322014808654785), (8, '24577791', 4.803395748138428), (11, '24554704', 4.6346845626831055), (12, '23197849', 4.612618446350098), (16, '21060967', 4.446898460388184), (18, '24469711', 4.439567565917969), (19, '21755313', 4.431821823120117), (25, '22512788', 4.27816104888916), (34, '21464439', 4.063064098358154), (35, '25059784', 4.056085586547852), (38, '24784583', 4.003556728363037), (43, '25479728', 3.937878131866455), (50, '24035588', 3.7958528995513916), (343, '24911883', 2.838761806488037)]\n",
      "[(3, '23197849'), (4, '21755313'), (6, '25479728'), (7, '24784583'), (8, '24577791'), (9, '24035588'), (15, '22512788'), (17, '24911883'), (19, '21464439'), (22, '24794627'), (126, '25059784'), (134, '24554704'), (466, '21060967'), (2793, '24469711')]\n"
     ]
    }
   ],
   "source": [
    "positive_docs_ranked = []\n",
    "for i,result in enumerate(re_ranking_pmid):\n",
    "    if result[0] in set(positive_docs):\n",
    "        positive_docs_ranked.append((i,result[0],result[1]))\n",
    "        \n",
    "true_ranked = []\n",
    "for i,pmid in enumerate(bm25_results):\n",
    "    if pmid in set(positive_docs):\n",
    "        true_ranked.append((i,pmid))\n",
    "\n",
    "print(positive_docs_ranked)\n",
    "print(true_ranked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with train set, check overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_tokens = np.array([X[0][0]])\n",
    "snippet_list = np.array([X[1][0]])\n",
    "\n",
    "query_tokens = X[0][:2]\n",
    "snippet_list = X[1][:2]\n",
    "\n",
    "model_input = [query_tokens, snippet_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 15)\n",
      "(2, 15, 3, 15)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(query_tokens.shape)\n",
    "print(snippet_list.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 15, 3, 15, 15, 1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = input_model.predict(model_input)\n",
    "np.array(matrix).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 15, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix[0][4][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.squeeze(matrix[0][7][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  165, 13502,    26,    61,     8,     1,    43,     2,   478],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  363,     5,  2386,    97,  7598,   774,    32, 13502,    18,\n",
       "          15,     7, 11695,   117,    17,     0], dtype=int32)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snippet_list[0][1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.05703647,  0.19594026,  0.03365219,  0.15514491,  0.00540348,\n",
       "       -0.02335026, -0.06095085,  0.0226689 , -0.05668721,  0.01571985,\n",
       "       -0.09896637,  0.13836679,  0.02710932,  0.06420047, -0.03692323,\n",
       "        0.03899341,  0.00553868, -0.08639584, -0.05358738, -0.02609682,\n",
       "        0.06495432, -0.00129713, -0.01882407, -0.10850747, -0.02421302,\n",
       "        0.05556208,  0.00291283, -0.04882976,  0.01770345,  0.0035051 ,\n",
       "        0.07192209, -0.00432884, -0.15161929, -0.07024549, -0.04793473,\n",
       "        0.01823143,  0.10337584, -0.04076301,  0.01026187,  0.12004871,\n",
       "        0.03939956, -0.03548966, -0.10689223, -0.16337523,  0.10883316,\n",
       "        0.01135785,  0.03041399,  0.06011688, -0.09919181,  0.01741308,\n",
       "       -0.04328503, -0.00256405, -0.11370766,  0.0522779 ,  0.0702537 ,\n",
       "        0.01021139,  0.06773005,  0.01114117, -0.05878652,  0.0720681 ,\n",
       "        0.05551391,  0.08731035,  0.07339004,  0.0031227 ,  0.10792159,\n",
       "        0.12050318, -0.05851915, -0.08350374, -0.03341928,  0.12355518,\n",
       "        0.11631501,  0.09690028, -0.02127477,  0.05462002, -0.03942551,\n",
       "        0.0049153 , -0.12599072,  0.04783105, -0.00842254,  0.06550868,\n",
       "       -0.06309314, -0.04500391, -0.08562729,  0.0129618 ,  0.05385976,\n",
       "        0.004466  ,  0.0030678 ,  0.02940105, -0.01520511,  0.04611286,\n",
       "        0.03223389,  0.01480899,  0.06665637, -0.00282597, -0.14461097,\n",
       "       -0.16931795,  0.01149627,  0.09099851, -0.06041984, -0.04964583,\n",
       "        0.04263903, -0.02741712,  0.04248934, -0.04117119,  0.1337102 ,\n",
       "       -0.01596204,  0.05762576,  0.00730769,  0.06105822,  0.02038225,\n",
       "        0.06695575,  0.03489211,  0.01739459, -0.00652035, -0.05772134,\n",
       "        0.07827891,  0.03879946,  0.13483463,  0.00304335, -0.07165361,\n",
       "        0.06038161, -0.05664064, -0.10519326, -0.00272405, -0.07754581,\n",
       "        0.06773265,  0.04561247,  0.07964371, -0.07700854,  0.08914506,\n",
       "        0.17518474,  0.01715964,  0.02536894, -0.02523981, -0.10770504,\n",
       "       -0.15260579, -0.00970635,  0.02915863,  0.06111136,  0.00900377,\n",
       "        0.04059591,  0.07735578, -0.04844462,  0.14468352,  0.03376452,\n",
       "       -0.06587124,  0.08225945,  0.02598596,  0.03487838,  0.04218515,\n",
       "        0.07036549, -0.01025326, -0.02166397, -0.06253622,  0.06407471,\n",
       "       -0.123892  , -0.01470529,  0.00293271,  0.05741141, -0.0694873 ,\n",
       "       -0.11187772, -0.07452565,  0.04860114, -0.06068123, -0.03620556,\n",
       "       -0.00046228, -0.05690295, -0.04587905,  0.04772501, -0.04207376,\n",
       "       -0.04783105,  0.05724974, -0.2321706 ,  0.08884832,  0.00071572,\n",
       "        0.05809747, -0.10940351,  0.01475556,  0.01292174, -0.07808141,\n",
       "        0.02383626,  0.06215472,  0.01264787,  0.04288376,  0.06052897,\n",
       "       -0.02552988,  0.05216181,  0.0164598 , -0.03271155, -0.05829453,\n",
       "       -0.09264817,  0.16744114, -0.01112105,  0.07499924,  0.05138046,\n",
       "       -0.00072611, -0.03267605, -0.00081905, -0.02593878, -0.10709276],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_dict[13502]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\r"
     ]
    }
   ],
   "source": [
    "data_generator = TrainDataGenerator(train_articles_collection, tk, 256)\n",
    "data_generator = iter(data_generator)\n",
    "for i in range(9):\n",
    "    print(i,end=\"\\r\")\n",
    "    X,Y = next(data_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda x: len(list(filter(lambda y:y!=0,x))),X[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 988,  988,  279, 1208,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0], dtype=int32)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0][26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  1075,      2,    986,      4,      6,    248,    988,   2250,\n",
       "             44,    713,   6300,   6300,      0],\n",
       "        [  3974,      2,    986,      4,      6,    248,    988,   2250,\n",
       "             18,    713,   6300,   6300,      0],\n",
       "        [    17,     17,  46298,  59753,   9143,   2106,    988,   2250,\n",
       "             16,      6,    200,    174,      0]],\n",
       "\n",
       "       [[  1075,      2,    986,      4,      6,    248,    988,   2250,\n",
       "             44,    713,   6300,   6300,      0],\n",
       "        [  3974,      2,    986,      4,      6,    248,    988,   2250,\n",
       "             18,    713,   6300,   6300,      0],\n",
       "        [    17,     17,  46298,  59753,   9143,   2106,    988,   2250,\n",
       "             16,      6,    200,    174,      0]],\n",
       "\n",
       "       [[     2,    248,    986,      4,      1,  10169,    279,      0,\n",
       "              0,      0,      0,      0,      0],\n",
       "        [     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0],\n",
       "        [     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0]],\n",
       "\n",
       "       [[  1063,   2870,   1361,      7,      6,   6336,   1208,    544,\n",
       "          22931,    137,     27,    587,      0],\n",
       "        [     1,    102,      2,      6,    134,   6336,   1208,    544,\n",
       "          22931, 551603,    137,      8,      0],\n",
       "        [     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0]],\n",
       "\n",
       "       [[     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0],\n",
       "        [     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0],\n",
       "        [     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0]],\n",
       "\n",
       "       [[     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0],\n",
       "        [     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0],\n",
       "        [     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0]],\n",
       "\n",
       "       [[     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0],\n",
       "        [     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0],\n",
       "        [     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0]],\n",
       "\n",
       "       [[     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0],\n",
       "        [     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0],\n",
       "        [     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0]],\n",
       "\n",
       "       [[     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0],\n",
       "        [     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0],\n",
       "        [     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0]],\n",
       "\n",
       "       [[     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0],\n",
       "        [     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0],\n",
       "        [     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0]],\n",
       "\n",
       "       [[     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0],\n",
       "        [     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0],\n",
       "        [     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0]],\n",
       "\n",
       "       [[     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0],\n",
       "        [     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0],\n",
       "        [     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0]],\n",
       "\n",
       "       [[     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0],\n",
       "        [     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0],\n",
       "        [     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0]],\n",
       "\n",
       "       [[     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0],\n",
       "        [     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0],\n",
       "        [     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0]],\n",
       "\n",
       "       [[     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0],\n",
       "        [     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0],\n",
       "        [     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0]]], dtype=int32)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[3][26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos,neg = deepRank_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'bioasq_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-256-10cc45d13ac2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mquery_to_test_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdata_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTestDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_articles_collection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdata_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_to_test_index\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-219-bffc59abe895>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, article_collection, tokenizer, article_map)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marticle_collection\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"bioasq_data\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marticles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marticle_collection\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"collection\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'bioasq_data'"
     ]
    }
   ],
   "source": [
    "query_to_test_index = 1\n",
    "\n",
    "data_generator = TestDataGenerator(train_articles_collection, tk)\n",
    "data_generator = iter(data_generator)\n",
    "for _ in range(query_to_test_index+1):\n",
    "    X = next(data_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('26671317', 7.931817054748535),\n",
       " ('20975159', 7.902041435241699),\n",
       " ('20650709', 7.8478264808654785),\n",
       " ('19805301', 7.842199802398682),\n",
       " ('21731768', 7.818233013153076),\n",
       " ('24681619', 7.759010314941406),\n",
       " ('26631348', 7.714381217956543),\n",
       " ('22196114', 7.696432590484619),\n",
       " ('23817568', 7.648404598236084),\n",
       " ('26410599', 7.3919854164123535)]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_ranking = document_score_model.predict(X)\n",
    "\n",
    "bm25_results = train_articles_collection[\"test_data\"][query_to_test_index][\"documents\"]\n",
    "positive_docs = train_articles_collection[\"test_data\"][query_to_test_index][\"positive_pmid\"]\n",
    "\n",
    "re_ranking_pmid = list(zip(bm25_results,re_ranking.tolist()))\n",
    "\n",
    "re_ranking_pmid.sort(key=lambda x:-x[1])\n",
    "\n",
    "re_ranking_pmid[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kind enzyme encoded proto oncogene abl1']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['21435002',\n",
       " '20841568',\n",
       " '9500553',\n",
       " '24012954',\n",
       " '18796434',\n",
       " '23842646',\n",
       " '18528425']"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tk.sequences_to_texts([train_articles_collection[\"test_data\"][query_to_test_index][\"query\"]]))\n",
    "positive_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(5, '24012954', 5.5485920906066895), (29, '9500553', 4.8889594078063965), (87, '21435002', 4.592401504516602), (112, '23842646', 4.525805473327637), (155, '18796434', 4.400295257568359), (342, '18528425', 4.139955043792725), (2244, '20841568', 3.1609909534454346)]\n",
      "[(1, '9500553'), (29, '21435002'), (187, '24012954'), (309, '18528425'), (333, '23842646'), (610, '20841568'), (2354, '18796434')]\n"
     ]
    }
   ],
   "source": [
    "positive_docs_ranked = []\n",
    "for i,result in enumerate(re_ranking_pmid):\n",
    "    if result[0] in set(positive_docs):\n",
    "        positive_docs_ranked.append((i,result[0],result[1]))\n",
    "        \n",
    "true_ranked = []\n",
    "for i,pmid in enumerate(bm25_results):\n",
    "    if pmid in set(positive_docs):\n",
    "        true_ranked.append((i,pmid))\n",
    "\n",
    "print(positive_docs_ranked)\n",
    "print(true_ranked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
