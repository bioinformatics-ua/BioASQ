{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/home/tiagoalmeida/bioASQ-taskb/\")\n",
    "\n",
    "import json\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('pubmed_data'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from pubmed_data import pubmed_helper as ph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load train data results and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test files: ['results_test_phaseA_5b_01_00.p', 'results_test_phaseA_5b_01_01.p']\n",
      "\n",
      "Load: results_test_phaseA_5b_01_00.p\n",
      "Number of tested queries in test set: 100\n"
     ]
    }
   ],
   "source": [
    "path=\"/backup/results/bm25\"\n",
    "\n",
    "\n",
    "files = sorted(filter(lambda x: \"test_phaseA_5b_01\" in x,os.listdir(path)))\n",
    "print(\"Test files:\",files)\n",
    "bm25_test_results = []\n",
    "for file in files:\n",
    "    print(\"\\nLoad:\",file,end=\"\\r\")\n",
    "    with open(os.path.join(path,file),\"rb\") as f:\n",
    "        bm25_test_results.extend(pickle.load(f))\n",
    "\n",
    "print(\"Number of tested queries in test set:\",len(bm25_test_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST_SET\n",
      "len bioasq 100 len bm25 100\n",
      "Empty goldstandard indexes: []\n"
     ]
    }
   ],
   "source": [
    "bioASQ_data_path = \"/backup/bioASQ_test_set/process/\"\n",
    "\n",
    "\n",
    "def load_prepare_data(path, bm25_results):\n",
    "    bioASQ_data = json.load(open(path))\n",
    "    print(\"len bioasq\", len(bioASQ_data), \"len bm25\", len(bm25_results))\n",
    "    bioASQ_data = bioASQ_data[:len(bm25_results)]\n",
    "    \n",
    "    #verify the training data\n",
    "    n_doc_per_query = map(lambda x:len(x[\"documents\"]), bioASQ_data)\n",
    "    \n",
    "    empty_index = sorted([i for i, x in enumerate(n_doc_per_query) if x == 0], key=lambda x : -x)\n",
    "    print(\"Empty goldstandard indexes:\", empty_index)\n",
    "    for i in empty_index:\n",
    "        del bioASQ_data[i]\n",
    "        del bm25_results[i]\n",
    "    \n",
    "    return bioASQ_data\n",
    "\n",
    "print(\"TEST_SET\")\n",
    "path_test = os.path.join(bioASQ_data_path,\"phaseB_5b_01.json\")\n",
    "bioASQ_data_test = load_prepare_data(path_test, bm25_test_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bm25_test_results distribution [(1, 1), (2, 2), (11, 1), (28, 1), (231, 1), (814, 1), (13253, 1), (15521, 1), (23377, 1), (30233, 1), (100000, 89)]\n"
     ]
    }
   ],
   "source": [
    "#analysis\n",
    "from collections import Counter\n",
    "\n",
    "len_doc_distribution = sorted(Counter(map(lambda x : len(x), bm25_test_results)).items(), key=lambda x:x[0])\n",
    "print(\"bm25_test_results distribution\",len_doc_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST_SET\n",
      "Data recall at 100 : 0.5800245636716224\n",
      "Data recall at 1000 : 0.7680816454787041\n",
      "Data recall at 2500 : 0.8652040508511094\n",
      "Data recall at 5000 : 0.8959687028657615\n",
      "Data map at 10 : 0.0645845238095238\n"
     ]
    }
   ],
   "source": [
    "from models.generic_model import f_recall, f_map\n",
    "\n",
    "recall_at_ranges = [100,1000,2500,5000]\n",
    "CHOOSEN_RECALL = 1000\n",
    "\n",
    "def check_recall(bioasq_data, bm25_results, recall_at_ranges):\n",
    "    expectations = list(map(lambda x:x[\"documents\"],bioasq_data))\n",
    "\n",
    "    for i in recall_at_ranges:\n",
    "        print(\"Data recall at\",i,\":\",f_recall(bm25_results,expectations,at=i))\n",
    "    \n",
    "    print(\"Data map at\",10,\":\",f_map(bm25_results,expectations,bioASQ=True))\n",
    "    \n",
    "def clip_at_recall(bm25_results, max_recall):\n",
    "    data_set_unique_pmid = set()\n",
    "\n",
    "    for fast_results in bm25_results:\n",
    "        data_set_unique_pmid.update(set(map(lambda x:x[0],fast_results[:max_recall])))\n",
    "    \n",
    "    return data_set_unique_pmid\n",
    "\n",
    "\n",
    "\n",
    "print(\"TEST_SET\")\n",
    "check_recall(bioASQ_data_test, bm25_test_results, recall_at_ranges)\n",
    "\n",
    "test_data_set_unique_pmid = clip_at_recall(bm25_test_results, CHOOSEN_RECALL)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0645845238095238"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check map\n",
    "expectations = list(map(lambda x:x[\"documents\"],bioASQ_data_test))\n",
    "\n",
    "f_map(bm25_test_results, expectations, bioASQ=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load /backup/saved_models/pmid_index_mapping.p\n",
      "Open /backup/pubmed_archive_json/pubmed_ready.tar.gz\n",
      "Creating generator\n"
     ]
    }
   ],
   "source": [
    "pmid_index_map = ph.pmid_index_mapping()\n",
    "\n",
    "articles_generator = ph.create_pubmed_collection_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_set_unique_index = [ pmid_index_map[pmid] for pmid in test_data_set_unique_pmid]\n",
    "\n",
    "assert(len(test_data_set_unique_index) == len(test_data_set_unique_pmid))\n",
    "assert(len(set(test_data_set_unique_index)) == len(test_data_set_unique_pmid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open the file: pubmed_ready_00000000_to_02776362\n",
      "Returning: 2776363 articles\n",
      "Force garbage collector 0\n",
      "Open the file: pubmed_ready_02776363_to_05519968\n",
      "Returning: 2743606 articles\n",
      "Force garbage collector 0\n",
      "Open the file: pubmed_ready_05519969_to_08241071\n",
      "Returning: 2721103 articles\n",
      "Force garbage collector 0\n",
      "Open the file: pubmed_ready_08241072_to_11124313\n",
      "Returning: 2883242 articles\n",
      "Force garbage collector 0\n",
      "Open the file: pubmed_ready_11124314_to_13996815\n"
     ]
    }
   ],
   "source": [
    "articles = []\n",
    "\n",
    "for article in articles_generator():\n",
    "    articles.extend(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_relevant_articles = { pmid_index_map.inverse[i]:articles[i] for i in test_data_set_unique_index }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_deep_models = []\n",
    "\n",
    "for i,fast_results in enumerate(bm25_test_results):\n",
    "    goldstandard = bioASQ_data_test[i][\"documents\"]\n",
    "\n",
    "    positive = [ pos_doc_pmid for pos_doc_pmid in bioASQ_data_test[i][\"documents\"] if pos_doc_pmid in set(map(lambda x:x[0],fast_results[:CHOOSEN_RECALL])) ]\n",
    "\n",
    "    top_results = list(map(lambda x:x[0],fast_results[:CHOOSEN_RECALL]))\n",
    "\n",
    "    test_data_deep_models.append({\"id\":bioASQ_data_test[i][\"id\"],\"query\":bioASQ_data_test[i][\"body\"], \"documents\":top_results,\"positive_pmid\":positive,\"goldstandard\":goldstandard})\n",
    "\n",
    "test_data_deep_models = {\"bioasq_data\":test_data_deep_models, \"collection\":test_relevant_articles}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenize collection\n"
     ]
    }
   ],
   "source": [
    "#import pad_sequences\n",
    "article_map = lambda x:x[\"title\"]+\" \"+x[\"abstract\"]\n",
    "\n",
    "#load tokenizer\n",
    "MODE = \"regex_full_tokens\"\n",
    "tk = ph.load_tokenizer(mode=MODE)\n",
    "biomedical_stop_words = [\"a\", \"about\", \"again\", \"all\", \"almost\", \"also\", \"although\", \"always\", \"among\", \"an\", \"and\", \"another\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"between\", \"both\", \"but\", \"by\", \"can\", \"could\", \"did\", \"do\", \"does\", \"done\", \"due\", \"during\", \"each\", \"either\", \"enough\", \"especially\", \"etc\", \"for\", \"found\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"here\", \"how\", \"however\", \"i\", \"if\", \"in\", \"into\", \"is\", \"it\", \"its\", \"itself\", \"just\", \"kg\", \"km\", \"made\", \"mainly\", \"make\", \"may\", \"mg\", \"might\", \"ml\", \"mm\", \"most\", \"mostly\", \"must\", \"nearly\", \"neither\", \"no\", \"nor\", \"obtained\", \"of\", \"often\", \"on\", \"our\", \"overall\", \"perhaps\", \"pmid\", \"quite\", \"rather\", \"really\", \"regarding\", \"seem\", \"seen\", \"several\", \"should\", \"show\", \"showed\", \"shown\", \"shows\", \"significantly\", \"since\", \"so\", \"some\", \"such\", \"than\", \"that\", \"the\", \"their\", \"theirs\", \"them\", \"then\", \"there\", \"therefore\", \"these\", \"they\", \"this\", \"those\", \"through\", \"thus\", \"to\", \"upon\", \"use\", \"used\", \"using\", \"various\", \"very\", \"was\", \"we\", \"were\", \"what\", \"when\", \"which\", \"while\", \"with\", \"within\", \"without\", \"would\"]\n",
    "biomedical_stop_words_tokens = set(tk.texts_to_sequences([biomedical_stop_words])[0])\n",
    "\n",
    "MAX_Q_TERM = 13\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def pre_process_data(data_deep_models):\n",
    "\n",
    "    for query_data in data_deep_models[\"bioasq_data\"]:\n",
    "        tokenized_query = tk.texts_to_sequences([query_data[\"query\"]])[0]\n",
    "        tokenized_query = [ token for token in tokenized_query if token not in biomedical_stop_words_tokens]\n",
    "        tokenized_query = pad_sequences([tokenized_query], maxlen = MAX_Q_TERM, padding=\"post\")[0] #REMOVE THIS IS IN THE WRONG PLACE\n",
    "        query_data[\"query\"] = tokenized_query\n",
    "\n",
    "    print(\"tokenize collection\")    \n",
    "\n",
    "    for key,doc in data_deep_models[\"collection\"].items():\n",
    "\n",
    "        data_deep_models[\"collection\"][key] = tk.texts_to_sequences([article_map(doc)])[0]\n",
    "\n",
    "pre_process_data(test_data_deep_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Save\n",
    "path_save = \"/backup/results/fast_method_relevant_results\"\n",
    "path_save = os.path.join(path_save, \"test_phaseA_5b_01.p\")\n",
    "\n",
    "with open(path_save, \"wb\") as f:\n",
    "    pickle.dump(test_data_deep_models,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
