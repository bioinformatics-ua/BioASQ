{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"/home/tiagoalmeida/bioASQ-taskb/\")\n",
    "\n",
    "import json\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('pubmed_data'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from pubmed_data import pubmed_helper as ph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load train data results and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test files: ['results_test_0.p', 'results_test_1.p']\n",
      "\n",
      "Load: results_test_0.p\n",
      "Number of tested queries in test set: 549\n"
     ]
    }
   ],
   "source": [
    "path=\"/backup/results/bm25\"\n",
    "\n",
    "\n",
    "GROUP_TRAIN_SET = False\n",
    "GROUP_TEST_SET = True\n",
    "\n",
    "if GROUP_TRAIN_SET:\n",
    "    files = sorted(filter(lambda x: \"train\" in x,os.listdir(path)))\n",
    "    print(\"Train files:\",files)\n",
    "    bm25_train_results = []\n",
    "    for file in files:\n",
    "        print(\"\\nLoad:\",file,end=\"\\r\")\n",
    "        with open(os.path.join(path,file),\"rb\") as f:\n",
    "            bm25_train_results.extend(pickle.load(f))\n",
    "\n",
    "    print(\"Number of tested queries in train set:\",len(bm25_train_results))\n",
    "\n",
    "if GROUP_TEST_SET:\n",
    "    files = sorted(filter(lambda x: \"test\" in x,os.listdir(path)))\n",
    "    files=files[:2]\n",
    "    print(\"Test files:\",files)\n",
    "    bm25_test_results = []\n",
    "    for file in files:\n",
    "        print(\"\\nLoad:\",file,end=\"\\r\")\n",
    "        with open(os.path.join(path,file),\"rb\") as f:\n",
    "            bm25_test_results.extend(pickle.load(f))\n",
    "\n",
    "    print(\"Number of tested queries in test set:\",len(bm25_test_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST_SET\n",
      "len bioasq 549 len bm25 549\n",
      "Empty goldstandard indexes: []\n"
     ]
    }
   ],
   "source": [
    "bioASQ_data_path = \"/backup/BioASQ-training7b/\"\n",
    "\n",
    "\n",
    "def load_prepare_data(path, bm25_results):\n",
    "    bioASQ_data = json.load(open(path))\n",
    "    print(\"len bioasq\", len(bioASQ_data), \"len bm25\", len(bm25_results))\n",
    "    bioASQ_data = bioASQ_data[:len(bm25_results)]\n",
    "    \n",
    "    #verify the training data\n",
    "    n_doc_per_query = map(lambda x:len(x[\"documents\"]), bioASQ_data)\n",
    "    \n",
    "    empty_index = sorted([i for i, x in enumerate(n_doc_per_query) if x == 0], key=lambda x : -x)\n",
    "    print(\"Empty goldstandard indexes:\", empty_index)\n",
    "    for i in empty_index:\n",
    "        del bioASQ_data[i]\n",
    "        del bm25_results[i]\n",
    "    \n",
    "    return bioASQ_data\n",
    "\n",
    "if GROUP_TRAIN_SET: \n",
    "    print(\"TRAIN_SET\")\n",
    "    path_train = os.path.join(bioASQ_data_path,\"7b_train_split.json\")\n",
    "    bioASQ_data_train = load_prepare_data(path_train, bm25_train_results)\n",
    "\n",
    "if GROUP_TEST_SET:\n",
    "    print(\"TEST_SET\")\n",
    "    path_test = os.path.join(bioASQ_data_path,\"7b_test_split.json\")\n",
    "    bioASQ_data_test = load_prepare_data(path_test, bm25_test_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bm25_test_results distribution [(1, 5), (4, 2), (7, 1), (8, 1), (15, 1), (20, 1), (24, 1), (34, 1), (42, 1), (75, 1), (126, 1), (1254, 1), (4114, 1), (7902, 1), (7944, 1), (15244, 1), (18614, 1), (26376, 1), (43843, 1), (50960, 1), (89781, 1), (100000, 523)]\n"
     ]
    }
   ],
   "source": [
    "#analysis\n",
    "from collections import Counter\n",
    "\n",
    "if GROUP_TRAIN_SET: \n",
    "    len_doc_distribution = sorted(Counter(map(lambda x : len(x), bm25_train_results)).items(), key=lambda x:x[0])\n",
    "    print(\"bm25_train_results distribution\",len_doc_distribution)\n",
    "\n",
    "if GROUP_TEST_SET:  \n",
    "    len_doc_distribution = sorted(Counter(map(lambda x : len(x), bm25_test_results)).items(), key=lambda x:x[0])\n",
    "    print(\"bm25_test_results distribution\",len_doc_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST_SET\n",
      "Data recall at 10 : 0.33122603972484665\n",
      "Data recall at 50 : 0.5504357446726348\n",
      "Data recall at 100 : 0.639780257070587\n",
      "Data recall at 1000 : 0.8323096260300467\n",
      "Data recall at 2500 : 0.8746784560651255\n",
      "Data map at 10 : 0.15353167375025284\n"
     ]
    }
   ],
   "source": [
    "from models.generic_model import f_recall, f_map\n",
    "\n",
    "recall_at_ranges = [10,50,100,1000,2500]\n",
    "CHOOSEN_RECALL = 2500\n",
    "\n",
    "def check_recall(bioasq_data, bm25_results, recall_at_ranges):\n",
    "    expectations = list(map(lambda x:x[\"documents\"],bioasq_data))\n",
    "\n",
    "    for i in recall_at_ranges:\n",
    "        print(\"Data recall at\",i,\":\",f_recall(bm25_results,expectations,at=i))\n",
    "        \n",
    "    print(\"Data map at\",10,\":\",f_map(bm25_results,expectations,bioASQ=True))\n",
    "    \n",
    "def clip_at_recall(bm25_results, max_recall):\n",
    "    data_set_unique_pmid = set()\n",
    "\n",
    "    for fast_results in bm25_results:\n",
    "        data_set_unique_pmid.update(set(map(lambda x:x[0],fast_results[:max_recall])))\n",
    "    \n",
    "    return data_set_unique_pmid\n",
    "\n",
    "\n",
    "if GROUP_TRAIN_SET:\n",
    "    print(\"TRAIN_SET\")\n",
    "    check_recall(bioASQ_data_train, bm25_train_results, recall_at_ranges)\n",
    "    \n",
    "    train_data_set_unique_pmid = clip_at_recall(bm25_train_results, CHOOSEN_RECALL)\n",
    "\n",
    "if GROUP_TEST_SET: \n",
    "    print(\"TEST_SET\")\n",
    "    check_recall(bioASQ_data_test, bm25_test_results, recall_at_ranges)\n",
    "    \n",
    "    test_data_set_unique_pmid = clip_at_recall(bm25_test_results, CHOOSEN_RECALL)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load /backup/saved_models/pmid_index_mapping.p\n",
      "Open /backup/pubmed_archive_json/pubmed_ready.tar.gz\n",
      "Creating generator\n"
     ]
    }
   ],
   "source": [
    "pmid_index_map = ph.pmid_index_mapping()\n",
    "\n",
    "articles_generator = ph.create_pubmed_collection_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert pmid to articles index\n",
    "if GROUP_TRAIN_SET: \n",
    "    train_data_set_unique_index = [ pmid_index_map[pmid] for pmid in train_data_set_unique_pmid]\n",
    "    \n",
    "    assert(len(train_data_set_unique_index) == len(train_data_set_unique_pmid))\n",
    "    assert(len(set(train_data_set_unique_index)) == len(train_data_set_unique_pmid))\n",
    "    \n",
    "if GROUP_TEST_SET: \n",
    "    test_data_set_unique_index = [ pmid_index_map[pmid] for pmid in test_data_set_unique_pmid]\n",
    "    \n",
    "    assert(len(test_data_set_unique_index) == len(test_data_set_unique_pmid))\n",
    "    assert(len(set(test_data_set_unique_index)) == len(test_data_set_unique_pmid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open the file: pubmed_ready_00000000_to_02776362\n",
      "Returning: 2776363 articles\n",
      "Force garbage collector 0\n",
      "Open the file: pubmed_ready_02776363_to_05519968\n",
      "Returning: 2743606 articles\n",
      "Force garbage collector 0\n",
      "Open the file: pubmed_ready_05519969_to_08241071\n",
      "Returning: 2721103 articles\n",
      "Force garbage collector 0\n",
      "Open the file: pubmed_ready_08241072_to_11124313\n",
      "Returning: 2883242 articles\n",
      "Force garbage collector 0\n",
      "Open the file: pubmed_ready_11124314_to_13996815\n",
      "Returning: 2872502 articles\n",
      "Force garbage collector 0\n",
      "Open the file: pubmed_ready_13996816_to_18824354\n",
      "Returning: 4827539 articles\n",
      "Force garbage collector 0\n"
     ]
    }
   ],
   "source": [
    "articles = []\n",
    "\n",
    "for article in articles_generator():\n",
    "    articles.extend(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GROUP_TRAIN_SET: \n",
    "    \n",
    "    #Irrelevant documents\n",
    "    num_train_irrelevant_docs = len(train_data_set_unique_index)*2\n",
    "    set_collection_index = set(range(len(articles)))\n",
    "\n",
    "    irrelevant_index = set_collection_index-set(train_data_set_unique_index)\n",
    "\n",
    "\n",
    "    #Random selection \n",
    "    from random import sample \n",
    "    selected_irrelevant_index = sample(list(irrelevant_index), num_train_irrelevant_docs)\n",
    "    selected_irrelevant_pmid = list(map(lambda x:pmid_index_map.inverse[x], selected_irrelevant_index))\n",
    "\n",
    "    #verification\n",
    "    assert len(set(selected_irrelevant_index)-set(train_data_set_unique_index)) == len(selected_irrelevant_index)\n",
    "    \n",
    "    train_relevant_articles = { pmid_index_map.inverse[i]:articles[i] for i in train_data_set_unique_index+selected_irrelevant_index }\n",
    "\n",
    "if GROUP_TEST_SET:\n",
    "    test_relevant_articles = { pmid_index_map.inverse[i]:articles[i] for i in test_data_set_unique_index }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GROUP_TRAIN_SET: \n",
    "    train_data_deep_models = []\n",
    "        \n",
    "    for i,fast_results in enumerate(bm25_train_results):\n",
    "        \n",
    "        positive = [ pos_doc_pmid for pos_doc_pmid in bioASQ_data_train[i][\"documents\"] if pos_doc_pmid in set(map(lambda x:x[0],fast_results[:CHOOSEN_RECALL])) ]\n",
    "        \n",
    "        #CHECK THIS CONDITION\n",
    "        if len(positive)==0:\n",
    "            continue\n",
    "            \n",
    "        top_results = fast_results[:CHOOSEN_RECALL]\n",
    "    \n",
    "        partially_positive = [x for x in top_results if x[0] not in set(positive)]\n",
    "\n",
    "        #TODO change dont use the JUMP!\n",
    "        if len(partially_positive)==0:\n",
    "            continue\n",
    "\n",
    "        partially_positive_bm25_score = list(map(lambda x:x[1], partially_positive))\n",
    "        partially_positive = list(map(lambda x:x[0], partially_positive))\n",
    "        #calculate negatives probabilities\n",
    "        partially_positive_logits = np.power(1.1, np.array(partially_positive_bm25_score))\n",
    "        partially_positive_prob = (partially_positive_logits/sum(partially_positive_logits)).tolist()\n",
    "\n",
    "        #cumulative prob\n",
    "        partially_positive_logits_cdf = [partially_positive_prob[0]]\n",
    "        for k in range(1, len(partially_positive_prob)):\n",
    "            partially_positive_logits_cdf.append(partially_positive_logits_cdf[-1] + partially_positive_prob[k])\n",
    "                    \n",
    "        top_results = list(map(lambda x:x[0],top_results))\n",
    "\n",
    "        train_data_deep_models.append({\"id\":bioASQ_data_train[i][\"id\"],\"query\":bioASQ_data_train[i][\"body\"], \"documents\":top_results, \"positive_pmid\":positive ,\"partilly_positive_pmid\":partially_positive,\"partially_positive_cumulative_prob\":partially_positive_logits_cdf})\n",
    "    \n",
    "    train_data_deep_models = {\"bioasq_data\":train_data_deep_models,\"irrelevant_pmid\":selected_irrelevant_pmid, \"collection\":train_relevant_articles}\n",
    "    \n",
    "if GROUP_TEST_SET:\n",
    "    test_data_deep_models = []\n",
    "\n",
    "    for i,fast_results in enumerate(bm25_test_results):\n",
    "        goldstandard = bioASQ_data_test[i][\"documents\"]\n",
    "        \n",
    "        positive = [ pos_doc_pmid for pos_doc_pmid in bioASQ_data_test[i][\"documents\"] if pos_doc_pmid in set(map(lambda x:x[0],fast_results[:CHOOSEN_RECALL])) ]\n",
    "        \n",
    "        top_results = list(map(lambda x:x[0],fast_results[:CHOOSEN_RECALL]))\n",
    "\n",
    "        test_data_deep_models.append({\"id\":bioASQ_data_test[i][\"id\"],\"query\":bioASQ_data_test[i][\"body\"], \"documents\":top_results,\"positive_pmid\":positive,\"goldstandard\":goldstandard})\n",
    "    \n",
    "    test_data_deep_models = {\"bioasq_data\":test_data_deep_models, \"collection\":test_relevant_articles}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load regex_full_tokens_tokenizer.p\n",
      "tokenize collection\n"
     ]
    }
   ],
   "source": [
    "#import pad_sequences\n",
    "article_map = lambda x:x[\"title\"]+\" \"+x[\"abstract\"]\n",
    "#load tokenizer\n",
    "MODE = \"regex_full_tokens\"\n",
    "tk=ph.load_tokenizer(mode=MODE)\n",
    "biomedical_stop_words = [\"a\", \"about\", \"again\", \"all\", \"almost\", \"also\", \"although\", \"always\", \"among\", \"an\", \"and\", \"another\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"between\", \"both\", \"but\", \"by\", \"can\", \"could\", \"did\", \"do\", \"does\", \"done\", \"due\", \"during\", \"each\", \"either\", \"enough\", \"especially\", \"etc\", \"for\", \"found\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"here\", \"how\", \"however\", \"i\", \"if\", \"in\", \"into\", \"is\", \"it\", \"its\", \"itself\", \"just\", \"kg\", \"km\", \"made\", \"mainly\", \"make\", \"may\", \"mg\", \"might\", \"ml\", \"mm\", \"most\", \"mostly\", \"must\", \"nearly\", \"neither\", \"no\", \"nor\", \"obtained\", \"of\", \"often\", \"on\", \"our\", \"overall\", \"perhaps\", \"pmid\", \"quite\", \"rather\", \"really\", \"regarding\", \"seem\", \"seen\", \"several\", \"should\", \"show\", \"showed\", \"shown\", \"shows\", \"significantly\", \"since\", \"so\", \"some\", \"such\", \"than\", \"that\", \"the\", \"their\", \"theirs\", \"them\", \"then\", \"there\", \"therefore\", \"these\", \"they\", \"this\", \"those\", \"through\", \"thus\", \"to\", \"upon\", \"use\", \"used\", \"using\", \"various\", \"very\", \"was\", \"we\", \"were\", \"what\", \"when\", \"which\", \"while\", \"with\", \"within\", \"without\", \"would\"]\n",
    "biomedical_stop_words_tokens = set(tk.texts_to_sequences([biomedical_stop_words])[0])\n",
    "\n",
    "MAX_Q_TERM = 13\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def pre_process_data(data_deep_models):\n",
    "\n",
    "    for query_data in data_deep_models[\"bioasq_data\"]:\n",
    "        tokenized_query = tk.texts_to_sequences([query_data[\"query\"]])[0]\n",
    "        tokenized_query = [ token for token in tokenized_query if token not in biomedical_stop_words_tokens]\n",
    "        tokenized_query = pad_sequences([tokenized_query], maxlen = MAX_Q_TERM, padding=\"post\")[0] #REMOVE THIS IS IN THE WRONG PLACE\n",
    "        query_data[\"query\"] = tokenized_query\n",
    "\n",
    "    print(\"tokenize collection\")    \n",
    "\n",
    "    for key,doc in data_deep_models[\"collection\"].items():\n",
    "\n",
    "        data_deep_models[\"collection\"][key] = tk.texts_to_sequences([article_map(doc)])[0]\n",
    "\n",
    "if GROUP_TRAIN_SET:\n",
    "    pre_process_data(train_data_deep_models)\n",
    "    \n",
    "if GROUP_TEST_SET:\n",
    "    pre_process_data(test_data_deep_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GROUP_TRAIN_SET: \n",
    "\n",
    "    #Save\n",
    "    path_save = \"/backup/results/fast_method_relevant_results\"\n",
    "    path_save = os.path.join(path_save, \"train_data_deep_models_v3.p\")\n",
    "\n",
    "    with open(path_save, \"wb\") as f:\n",
    "        pickle.dump(train_data_deep_models,f)\n",
    "        \n",
    "if GROUP_TEST_SET:\n",
    "    \n",
    "    #Save\n",
    "    path_save = \"/backup/results/fast_method_relevant_results\"\n",
    "    path_save = os.path.join(path_save, \"test_data_deep_models_v3.p\")\n",
    "\n",
    "    with open(path_save, \"wb\") as f:\n",
    "        pickle.dump(test_data_deep_models,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_train_irrelevant_docs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-56c7e2ef38e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnum_train_irrelevant_docs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'num_train_irrelevant_docs' is not defined"
     ]
    }
   ],
   "source": [
    "num_train_irrelevant_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
